{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INPUT_SHAPE = (88, 80)\n",
    "WINDOW_LENGTH = 4\n",
    "ENV_NAME = 'MsPacman-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atari Processor\n",
    "class AtariProcessor(Processor):\n",
    "    \n",
    "    def process_observation(self, observation):\n",
    "        # Crop\n",
    "        img = observation[1:176:2, ::2]\n",
    "        # Convert the image to greyscale\n",
    "        img = np.dot(img[...,:3], [0.299, 0.587, 0.144])\n",
    "        # Resize\n",
    "        img = img.reshape(INPUT_SHAPE)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Actions: 9\n",
      "['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT']\n",
      "\n",
      "\n",
      "Observed Starting Position\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Starting Position\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make Environment\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "n_actions = env.action_space.n\n",
    "print(\"Number of Actions:\", n_actions)\n",
    "print(env.env.get_action_meanings())\n",
    "observation = env.reset()\n",
    "\n",
    "print(\"\\n\\nObserved Starting Position\")\n",
    "plt.imshow(observation)\n",
    "plt.show() #show initial state\n",
    "\n",
    "print(\"Preprocessed Starting Position\")\n",
    "plt.imshow(AtariProcessor.process_observation('',observation))\n",
    "plt.show() #show preprocessed initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_1 (Permute)          (None, 88, 80, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 19, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 21, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1376768   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 4617      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 1,459,369\n",
      "Trainable params: 1,459,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Using the same model that was described by Mnih et al. (2015).\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    # (width, height, channels)\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "elif K.image_dim_ordering() == 'th':\n",
    "    # (channels, width, height)\n",
    "    model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "else:\n",
    "    raise RuntimeError('Unknown image_dim_ordering.')\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(n_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_steps = 10000000\n",
    "learning_rate = 0.0002\n",
    "discount_factor = 0.99\n",
    "steps_train = 4\n",
    "start_steps = 2000\n",
    "eps_min = 0.1 #End with 0.1 epsilon (explore less)\n",
    "eps_max = 0.65 #Start with 0.65 epsilon (explore more)\n",
    "eps_decay_steps = 9500000\n",
    "batch = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Drake\\.conda\\envs\\sls\\lib\\site-packages\\rl\\util.py:79: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "processor = AtariProcessor()\n",
    "\n",
    "#DecayingEpsilon\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=eps_max, value_min=eps_min, value_test=.05,\n",
    "                              nb_steps=eps_decay_steps)\n",
    "\n",
    "dqn = DQNAgent(model=model, nb_actions=n_actions, policy=policy, memory=memory, processor=processor, nb_steps_warmup=start_steps, \n",
    "               gamma=discount_factor, target_model_update=batch,train_interval=steps_train, delta_clip=1.)\n",
    "\n",
    "dqn.compile(Adam(lr=learning_rate), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0446\n",
      "35 episodes - episode_reward: 31.829 [11.000, 58.000] - loss: 0.021 - mean_absolute_error: 0.056 - mean_q: 0.083 - mean_eps: 0.649 - ale.lives: 2.047\n",
      "\n",
      "Interval 2 (25000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0435\n",
      "37 episodes - episode_reward: 28.757 [13.000, 51.000] - loss: 0.018 - mean_absolute_error: 0.120 - mean_q: 0.174 - mean_eps: 0.648 - ale.lives: 2.059\n",
      "\n",
      "Interval 3 (50000 steps performed)\n",
      "25000/25000 [==============================] - 277s 11ms/step - reward: 0.0424\n",
      "37 episodes - episode_reward: 28.378 [14.000, 51.000] - loss: 0.017 - mean_absolute_error: 0.158 - mean_q: 0.230 - mean_eps: 0.646 - ale.lives: 2.054\n",
      "\n",
      "Interval 4 (75000 steps performed)\n",
      "25000/25000 [==============================] - 278s 11ms/step - reward: 0.0429\n",
      "36 episodes - episode_reward: 30.194 [18.000, 58.000] - loss: 0.017 - mean_absolute_error: 0.208 - mean_q: 0.295 - mean_eps: 0.645 - ale.lives: 2.067\n",
      "\n",
      "Interval 5 (100000 steps performed)\n",
      "25000/25000 [==============================] - 277s 11ms/step - reward: 0.0510\n",
      "35 episodes - episode_reward: 36.943 [17.000, 66.000] - loss: 0.019 - mean_absolute_error: 0.302 - mean_q: 0.413 - mean_eps: 0.643 - ale.lives: 2.081\n",
      "\n",
      "Interval 6 (125000 steps performed)\n",
      "25000/25000 [==============================] - 277s 11ms/step - reward: 0.0469\n",
      "35 episodes - episode_reward: 33.229 [15.000, 62.000] - loss: 0.020 - mean_absolute_error: 0.378 - mean_q: 0.504 - mean_eps: 0.642 - ale.lives: 2.023\n",
      "\n",
      "Interval 7 (150000 steps performed)\n",
      "25000/25000 [==============================] - 277s 11ms/step - reward: 0.0482\n",
      "33 episodes - episode_reward: 36.758 [18.000, 59.000] - loss: 0.021 - mean_absolute_error: 0.455 - mean_q: 0.599 - mean_eps: 0.641 - ale.lives: 1.974\n",
      "\n",
      "Interval 8 (175000 steps performed)\n",
      "25000/25000 [==============================] - 278s 11ms/step - reward: 0.0478\n",
      "34 episodes - episode_reward: 34.853 [16.000, 70.000] - loss: 0.022 - mean_absolute_error: 0.529 - mean_q: 0.688 - mean_eps: 0.639 - ale.lives: 2.096\n",
      "\n",
      "Interval 9 (200000 steps performed)\n",
      "25000/25000 [==============================] - 278s 11ms/step - reward: 0.0502\n",
      "35 episodes - episode_reward: 36.114 [20.000, 71.000] - loss: 0.025 - mean_absolute_error: 0.626 - mean_q: 0.803 - mean_eps: 0.638 - ale.lives: 2.065\n",
      "\n",
      "Interval 10 (225000 steps performed)\n",
      "25000/25000 [==============================] - 278s 11ms/step - reward: 0.0490\n",
      "32 episodes - episode_reward: 37.594 [20.000, 79.000] - loss: 0.025 - mean_absolute_error: 0.708 - mean_q: 0.898 - mean_eps: 0.636 - ale.lives: 2.062\n",
      "\n",
      "Interval 11 (250000 steps performed)\n",
      "25000/25000 [==============================] - 282s 11ms/step - reward: 0.0510\n",
      "36 episodes - episode_reward: 35.389 [24.000, 53.000] - loss: 0.027 - mean_absolute_error: 0.799 - mean_q: 1.003 - mean_eps: 0.635 - ale.lives: 2.065\n",
      "\n",
      "Interval 12 (275000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0533\n",
      "35 episodes - episode_reward: 38.114 [27.000, 63.000] - loss: 0.029 - mean_absolute_error: 0.883 - mean_q: 1.100 - mean_eps: 0.633 - ale.lives: 2.099\n",
      "\n",
      "Interval 13 (300000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0536\n",
      "35 episodes - episode_reward: 38.571 [20.000, 63.000] - loss: 0.033 - mean_absolute_error: 0.987 - mean_q: 1.220 - mean_eps: 0.632 - ale.lives: 2.098\n",
      "\n",
      "Interval 14 (325000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0524\n",
      "32 episodes - episode_reward: 40.156 [25.000, 59.000] - loss: 0.034 - mean_absolute_error: 1.056 - mean_q: 1.298 - mean_eps: 0.630 - ale.lives: 2.106\n",
      "\n",
      "Interval 15 (350000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0505\n",
      "32 episodes - episode_reward: 39.750 [24.000, 80.000] - loss: 0.036 - mean_absolute_error: 1.123 - mean_q: 1.373 - mean_eps: 0.629 - ale.lives: 2.118\n",
      "\n",
      "Interval 16 (375000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0529\n",
      "33 episodes - episode_reward: 40.152 [23.000, 87.000] - loss: 0.039 - mean_absolute_error: 1.191 - mean_q: 1.449 - mean_eps: 0.628 - ale.lives: 2.028\n",
      "\n",
      "Interval 17 (400000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0514\n",
      "36 episodes - episode_reward: 35.972 [20.000, 66.000] - loss: 0.040 - mean_absolute_error: 1.281 - mean_q: 1.553 - mean_eps: 0.626 - ale.lives: 2.075\n",
      "\n",
      "Interval 18 (425000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.05400s - reward: 0.\n",
      "33 episodes - episode_reward: 40.788 [15.000, 70.000] - loss: 0.044 - mean_absolute_error: 1.400 - mean_q: 1.690 - mean_eps: 0.625 - ale.lives: 2.066\n",
      "\n",
      "Interval 19 (450000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0505\n",
      "36 episodes - episode_reward: 35.528 [21.000, 60.000] - loss: 0.044 - mean_absolute_error: 1.515 - mean_q: 1.818 - mean_eps: 0.623 - ale.lives: 2.132\n",
      "\n",
      "Interval 20 (475000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0532\n",
      "35 episodes - episode_reward: 37.429 [24.000, 72.000] - loss: 0.047 - mean_absolute_error: 1.618 - mean_q: 1.935 - mean_eps: 0.622 - ale.lives: 2.073\n",
      "\n",
      "Interval 21 (500000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0528\n",
      "35 episodes - episode_reward: 37.771 [14.000, 63.000] - loss: 0.047 - mean_absolute_error: 1.700 - mean_q: 2.027 - mean_eps: 0.620 - ale.lives: 2.053\n",
      "\n",
      "Interval 22 (525000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0531\n",
      "34 episodes - episode_reward: 38.912 [21.000, 59.000] - loss: 0.049 - mean_absolute_error: 1.770 - mean_q: 2.107 - mean_eps: 0.619 - ale.lives: 2.115\n",
      "\n",
      "Interval 23 (550000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0532\n",
      "33 episodes - episode_reward: 40.970 [26.000, 70.000] - loss: 0.051 - mean_absolute_error: 1.873 - mean_q: 2.224 - mean_eps: 0.617 - ale.lives: 2.020\n",
      "\n",
      "Interval 24 (575000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0566\n",
      "33 episodes - episode_reward: 42.606 [25.000, 74.000] - loss: 0.052 - mean_absolute_error: 1.969 - mean_q: 2.334 - mean_eps: 0.616 - ale.lives: 2.068\n",
      "\n",
      "Interval 25 (600000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0560\n",
      "33 episodes - episode_reward: 42.667 [16.000, 93.000] - loss: 0.054 - mean_absolute_error: 2.046 - mean_q: 2.418 - mean_eps: 0.615 - ale.lives: 2.026\n",
      "\n",
      "Interval 26 (625000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0561\n",
      "33 episodes - episode_reward: 41.364 [19.000, 79.000] - loss: 0.055 - mean_absolute_error: 2.068 - mean_q: 2.443 - mean_eps: 0.613 - ale.lives: 2.066\n",
      "\n",
      "Interval 27 (650000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0555\n",
      "36 episodes - episode_reward: 39.583 [23.000, 61.000] - loss: 0.056 - mean_absolute_error: 2.116 - mean_q: 2.497 - mean_eps: 0.612 - ale.lives: 2.135\n",
      "\n",
      "Interval 28 (675000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0577\n",
      "33 episodes - episode_reward: 42.636 [25.000, 69.000] - loss: 0.058 - mean_absolute_error: 2.198 - mean_q: 2.591 - mean_eps: 0.610 - ale.lives: 2.067\n",
      "\n",
      "Interval 29 (700000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0558\n",
      "33 episodes - episode_reward: 42.152 [19.000, 74.000] - loss: 0.059 - mean_absolute_error: 2.284 - mean_q: 2.688 - mean_eps: 0.609 - ale.lives: 2.073\n",
      "\n",
      "Interval 30 (725000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0564\n",
      "36 episodes - episode_reward: 40.111 [18.000, 70.000] - loss: 0.059 - mean_absolute_error: 2.328 - mean_q: 2.737 - mean_eps: 0.607 - ale.lives: 2.083\n",
      "\n",
      "Interval 31 (750000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0567\n",
      "37 episodes - episode_reward: 38.162 [21.000, 60.000] - loss: 0.063 - mean_absolute_error: 2.437 - mean_q: 2.860 - mean_eps: 0.606 - ale.lives: 2.109\n",
      "\n",
      "Interval 32 (775000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0562\n",
      "35 episodes - episode_reward: 40.486 [21.000, 63.000] - loss: 0.064 - mean_absolute_error: 2.545 - mean_q: 2.982 - mean_eps: 0.604 - ale.lives: 2.116\n",
      "\n",
      "Interval 33 (800000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.05534s - reward: 0 - ETA: 4s - re - ETA: 3s - reward: 0 - ETA: 3s - - ETA: 2s - \n",
      "32 episodes - episode_reward: 41.969 [24.000, 66.000] - loss: 0.065 - mean_absolute_error: 2.640 - mean_q: 3.090 - mean_eps: 0.603 - ale.lives: 2.051\n",
      "\n",
      "Interval 34 (825000 steps performed)\n",
      "25000/25000 [==============================] - 285s 11ms/step - reward: 0.0559\n",
      "31 episodes - episode_reward: 45.065 [17.000, 76.000] - loss: 0.069 - mean_absolute_error: 2.698 - mean_q: 3.155 - mean_eps: 0.602 - ale.lives: 1.995\n",
      "\n",
      "Interval 35 (850000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0583\n",
      "35 episodes - episode_reward: 42.200 [17.000, 78.000] - loss: 0.068 - mean_absolute_error: 2.775 - mean_q: 3.240 - mean_eps: 0.600 - ale.lives: 2.137\n",
      "\n",
      "Interval 36 (875000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0587\n",
      "34 episodes - episode_reward: 42.618 [21.000, 70.000] - loss: 0.069 - mean_absolute_error: 2.860 - mean_q: 3.334 - mean_eps: 0.599 - ale.lives: 2.112\n",
      "\n",
      "Interval 37 (900000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0574\n",
      "32 episodes - episode_reward: 44.688 [24.000, 76.000] - loss: 0.071 - mean_absolute_error: 2.952 - mean_q: 3.438 - mean_eps: 0.597 - ale.lives: 2.107\n",
      "\n",
      "Interval 38 (925000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0574\n",
      "33 episodes - episode_reward: 43.758 [24.000, 75.000] - loss: 0.071 - mean_absolute_error: 3.037 - mean_q: 3.532 - mean_eps: 0.596 - ale.lives: 2.111\n",
      "\n",
      "Interval 39 (950000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0572\n",
      "33 episodes - episode_reward: 43.939 [21.000, 70.000] - loss: 0.072 - mean_absolute_error: 3.045 - mean_q: 3.536 - mean_eps: 0.594 - ale.lives: 2.114\n",
      "\n",
      "Interval 40 (975000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0582\n",
      "31 episodes - episode_reward: 46.323 [26.000, 77.000] - loss: 0.072 - mean_absolute_error: 3.098 - mean_q: 3.597 - mean_eps: 0.593 - ale.lives: 2.017\n",
      "\n",
      "Interval 41 (1000000 steps performed)\n",
      "25000/25000 [==============================] - ETA: 0s - reward: 0.058 - 289s 12ms/step - reward: 0.0582\n",
      "31 episodes - episode_reward: 47.161 [21.000, 86.000] - loss: 0.073 - mean_absolute_error: 3.148 - mean_q: 3.650 - mean_eps: 0.591 - ale.lives: 2.082\n",
      "\n",
      "Interval 42 (1025000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0591\n",
      "30 episodes - episode_reward: 49.967 [24.000, 82.000] - loss: 0.075 - mean_absolute_error: 3.236 - mean_q: 3.748 - mean_eps: 0.590 - ale.lives: 2.093\n",
      "\n",
      "Interval 43 (1050000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.06100s\n",
      "32 episodes - episode_reward: 47.406 [25.000, 78.000] - loss: 0.079 - mean_absolute_error: 3.305 - mean_q: 3.826 - mean_eps: 0.588 - ale.lives: 2.103\n",
      "\n",
      "Interval 44 (1075000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0557\n",
      "33 episodes - episode_reward: 42.061 [23.000, 69.000] - loss: 0.079 - mean_absolute_error: 3.327 - mean_q: 3.850 - mean_eps: 0.587 - ale.lives: 2.120\n",
      "\n",
      "Interval 45 (1100000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0608\n",
      "30 episodes - episode_reward: 49.967 [28.000, 81.000] - loss: 0.080 - mean_absolute_error: 3.432 - mean_q: 3.967 - mean_eps: 0.586 - ale.lives: 2.056\n",
      "\n",
      "Interval 46 (1125000 steps performed)\n",
      "25000/25000 [==============================] - 304s 12ms/step - reward: 0.0621\n",
      "33 episodes - episode_reward: 47.424 [20.000, 69.000] - loss: 0.082 - mean_absolute_error: 3.514 - mean_q: 4.058 - mean_eps: 0.584 - ale.lives: 2.145\n",
      "\n",
      "Interval 47 (1150000 steps performed)\n",
      "25000/25000 [==============================] - 303s 12ms/step - reward: 0.0599\n",
      "35 episodes - episode_reward: 43.600 [22.000, 86.000] - loss: 0.083 - mean_absolute_error: 3.587 - mean_q: 4.138 - mean_eps: 0.583 - ale.lives: 2.123\n",
      "\n",
      "Interval 48 (1175000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0602\n",
      "32 episodes - episode_reward: 47.031 [25.000, 71.000] - loss: 0.083 - mean_absolute_error: 3.613 - mean_q: 4.167 - mean_eps: 0.581 - ale.lives: 2.064\n",
      "\n",
      "Interval 49 (1200000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0586\n",
      "30 episodes - episode_reward: 47.900 [22.000, 76.000] - loss: 0.082 - mean_absolute_error: 3.663 - mean_q: 4.224 - mean_eps: 0.580 - ale.lives: 2.065\n",
      "\n",
      "Interval 50 (1225000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0629\n",
      "32 episodes - episode_reward: 49.500 [27.000, 89.000] - loss: 0.087 - mean_absolute_error: 3.701 - mean_q: 4.267 - mean_eps: 0.578 - ale.lives: 2.091\n",
      "\n",
      "Interval 51 (1250000 steps performed)\n",
      "25000/25000 [==============================] - 303s 12ms/step - reward: 0.0609\n",
      "29 episodes - episode_reward: 52.207 [27.000, 82.000] - loss: 0.087 - mean_absolute_error: 3.742 - mean_q: 4.315 - mean_eps: 0.577 - ale.lives: 2.086\n",
      "\n",
      "Interval 52 (1275000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.05980s - re - ETA: 0s - reward: 0.05\n",
      "35 episodes - episode_reward: 42.714 [19.000, 75.000] - loss: 0.091 - mean_absolute_error: 3.788 - mean_q: 4.368 - mean_eps: 0.575 - ale.lives: 2.134\n",
      "\n",
      "Interval 53 (1300000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.06280s - rewa\n",
      "33 episodes - episode_reward: 47.424 [23.000, 85.000] - loss: 0.089 - mean_absolute_error: 3.835 - mean_q: 4.420 - mean_eps: 0.574 - ale.lives: 2.169\n",
      "\n",
      "Interval 54 (1325000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.06330s - reward: 0.0\n",
      "34 episodes - episode_reward: 46.294 [28.000, 68.000] - loss: 0.093 - mean_absolute_error: 3.889 - mean_q: 4.482 - mean_eps: 0.573 - ale.lives: 2.109\n",
      "\n",
      "Interval 55 (1350000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.06100s - reward:\n",
      "30 episodes - episode_reward: 51.767 [28.000, 102.000] - loss: 0.093 - mean_absolute_error: 3.966 - mean_q: 4.570 - mean_eps: 0.571 - ale.lives: 2.133\n",
      "\n",
      "Interval 56 (1375000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0606\n",
      "33 episodes - episode_reward: 45.727 [21.000, 76.000] - loss: 0.095 - mean_absolute_error: 4.020 - mean_q: 4.630 - mean_eps: 0.570 - ale.lives: 2.087\n",
      "\n",
      "Interval 57 (1400000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0590\n",
      "34 episodes - episode_reward: 43.088 [17.000, 69.000] - loss: 0.096 - mean_absolute_error: 4.055 - mean_q: 4.666 - mean_eps: 0.568 - ale.lives: 2.075\n",
      "\n",
      "Interval 58 (1425000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0623\n",
      "29 episodes - episode_reward: 52.276 [22.000, 87.000] - loss: 0.094 - mean_absolute_error: 4.093 - mean_q: 4.709 - mean_eps: 0.567 - ale.lives: 2.088\n",
      "\n",
      "Interval 59 (1450000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.06120s - rew\n",
      "32 episodes - episode_reward: 49.406 [14.000, 81.000] - loss: 0.094 - mean_absolute_error: 4.158 - mean_q: 4.784 - mean_eps: 0.565 - ale.lives: 2.136\n",
      "\n",
      "Interval 60 (1475000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0627\n",
      "34 episodes - episode_reward: 45.294 [27.000, 79.000] - loss: 0.096 - mean_absolute_error: 4.241 - mean_q: 4.875 - mean_eps: 0.564 - ale.lives: 2.055\n",
      "\n",
      "Interval 61 (1500000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0642\n",
      "36 episodes - episode_reward: 45.694 [21.000, 84.000] - loss: 0.095 - mean_absolute_error: 4.305 - mean_q: 4.944 - mean_eps: 0.562 - ale.lives: 2.132\n",
      "\n",
      "Interval 62 (1525000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0618\n",
      "32 episodes - episode_reward: 47.344 [24.000, 73.000] - loss: 0.102 - mean_absolute_error: 4.333 - mean_q: 4.977 - mean_eps: 0.561 - ale.lives: 2.087\n",
      "\n",
      "Interval 63 (1550000 steps performed)\n",
      "25000/25000 [==============================] - 311s 12ms/step - reward: 0.0615\n",
      "33 episodes - episode_reward: 46.667 [25.000, 93.000] - loss: 0.102 - mean_absolute_error: 4.341 - mean_q: 4.987 - mean_eps: 0.560 - ale.lives: 2.104\n",
      "\n",
      "Interval 64 (1575000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0624\n",
      "35 episodes - episode_reward: 45.429 [12.000, 69.000] - loss: 0.101 - mean_absolute_error: 4.375 - mean_q: 5.025 - mean_eps: 0.558 - ale.lives: 2.123\n",
      "\n",
      "Interval 65 (1600000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0627\n",
      "32 episodes - episode_reward: 49.000 [24.000, 75.000] - loss: 0.103 - mean_absolute_error: 4.430 - mean_q: 5.086 - mean_eps: 0.557 - ale.lives: 2.071\n",
      "\n",
      "Interval 66 (1625000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0621\n",
      "33 episodes - episode_reward: 45.545 [17.000, 68.000] - loss: 0.104 - mean_absolute_error: 4.494 - mean_q: 5.158 - mean_eps: 0.555 - ale.lives: 2.099\n",
      "\n",
      "Interval 67 (1650000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0611\n",
      "34 episodes - episode_reward: 45.382 [25.000, 82.000] - loss: 0.105 - mean_absolute_error: 4.551 - mean_q: 5.223 - mean_eps: 0.554 - ale.lives: 2.066\n",
      "\n",
      "Interval 68 (1675000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0631\n",
      "34 episodes - episode_reward: 46.382 [18.000, 82.000] - loss: 0.105 - mean_absolute_error: 4.630 - mean_q: 5.313 - mean_eps: 0.552 - ale.lives: 2.131\n",
      "\n",
      "Interval 69 (1700000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0621\n",
      "33 episodes - episode_reward: 48.121 [29.000, 75.000] - loss: 0.110 - mean_absolute_error: 4.686 - mean_q: 5.374 - mean_eps: 0.551 - ale.lives: 2.021\n",
      "\n",
      "Interval 70 (1725000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0634\n",
      "35 episodes - episode_reward: 44.857 [21.000, 75.000] - loss: 0.110 - mean_absolute_error: 4.824 - mean_q: 5.528 - mean_eps: 0.549 - ale.lives: 2.057\n",
      "\n",
      "Interval 71 (1750000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0658\n",
      "34 episodes - episode_reward: 47.882 [20.000, 81.000] - loss: 0.113 - mean_absolute_error: 4.831 - mean_q: 5.536 - mean_eps: 0.548 - ale.lives: 2.036\n",
      "\n",
      "Interval 72 (1775000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0640\n",
      "33 episodes - episode_reward: 49.394 [20.000, 79.000] - loss: 0.114 - mean_absolute_error: 4.915 - mean_q: 5.635 - mean_eps: 0.547 - ale.lives: 2.113\n",
      "\n",
      "Interval 73 (1800000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0630\n",
      "34 episodes - episode_reward: 45.294 [18.000, 61.000] - loss: 0.114 - mean_absolute_error: 4.947 - mean_q: 5.669 - mean_eps: 0.545 - ale.lives: 2.090\n",
      "\n",
      "Interval 74 (1825000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0648\n",
      "31 episodes - episode_reward: 52.355 [25.000, 84.000] - loss: 0.115 - mean_absolute_error: 4.965 - mean_q: 5.693 - mean_eps: 0.544 - ale.lives: 2.101\n",
      "\n",
      "Interval 75 (1850000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0661\n",
      "33 episodes - episode_reward: 50.333 [25.000, 80.000] - loss: 0.118 - mean_absolute_error: 5.019 - mean_q: 5.753 - mean_eps: 0.542 - ale.lives: 2.028\n",
      "\n",
      "Interval 76 (1875000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.06440s \n",
      "29 episodes - episode_reward: 55.655 [26.000, 100.000] - loss: 0.112 - mean_absolute_error: 5.051 - mean_q: 5.787 - mean_eps: 0.541 - ale.lives: 2.100\n",
      "\n",
      "Interval 77 (1900000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0661\n",
      "31 episodes - episode_reward: 53.000 [17.000, 96.000] - loss: 0.114 - mean_absolute_error: 5.067 - mean_q: 5.806 - mean_eps: 0.539 - ale.lives: 2.114\n",
      "\n",
      "Interval 78 (1925000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.06490s - rewar\n",
      "36 episodes - episode_reward: 45.278 [25.000, 72.000] - loss: 0.115 - mean_absolute_error: 5.109 - mean_q: 5.852 - mean_eps: 0.538 - ale.lives: 2.117\n",
      "\n",
      "Interval 79 (1950000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0666\n",
      "30 episodes - episode_reward: 56.300 [34.000, 97.000] - loss: 0.111 - mean_absolute_error: 5.119 - mean_q: 5.862 - mean_eps: 0.536 - ale.lives: 2.057\n",
      "\n",
      "Interval 80 (1975000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0655\n",
      "31 episodes - episode_reward: 52.226 [18.000, 105.000] - loss: 0.119 - mean_absolute_error: 5.199 - mean_q: 5.955 - mean_eps: 0.535 - ale.lives: 2.065\n",
      "\n",
      "Interval 81 (2000000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0658\n",
      "33 episodes - episode_reward: 49.455 [18.000, 86.000] - loss: 0.116 - mean_absolute_error: 5.256 - mean_q: 6.019 - mean_eps: 0.533 - ale.lives: 2.086\n",
      "\n",
      "Interval 82 (2025000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0642\n",
      "33 episodes - episode_reward: 48.212 [18.000, 80.000] - loss: 0.117 - mean_absolute_error: 5.307 - mean_q: 6.077 - mean_eps: 0.532 - ale.lives: 2.075\n",
      "\n",
      "Interval 83 (2050000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0628\n",
      "31 episodes - episode_reward: 51.839 [27.000, 78.000] - loss: 0.119 - mean_absolute_error: 5.322 - mean_q: 6.091 - mean_eps: 0.531 - ale.lives: 2.113\n",
      "\n",
      "Interval 84 (2075000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.06500s - re\n",
      "32 episodes - episode_reward: 51.000 [22.000, 104.000] - loss: 0.122 - mean_absolute_error: 5.403 - mean_q: 6.182 - mean_eps: 0.529 - ale.lives: 2.050\n",
      "\n",
      "Interval 85 (2100000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0670\n",
      "31 episodes - episode_reward: 53.581 [21.000, 93.000] - loss: 0.117 - mean_absolute_error: 5.429 - mean_q: 6.211 - mean_eps: 0.528 - ale.lives: 2.160\n",
      "\n",
      "Interval 86 (2125000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0684\n",
      "32 episodes - episode_reward: 53.750 [19.000, 80.000] - loss: 0.116 - mean_absolute_error: 5.455 - mean_q: 6.239 - mean_eps: 0.526 - ale.lives: 2.080\n",
      "\n",
      "Interval 87 (2150000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0687\n",
      "31 episodes - episode_reward: 53.613 [20.000, 97.000] - loss: 0.119 - mean_absolute_error: 5.523 - mean_q: 6.313 - mean_eps: 0.525 - ale.lives: 2.060\n",
      "\n",
      "Interval 88 (2175000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0648\n",
      "29 episodes - episode_reward: 57.310 [35.000, 89.000] - loss: 0.116 - mean_absolute_error: 5.563 - mean_q: 6.361 - mean_eps: 0.523 - ale.lives: 2.090\n",
      "\n",
      "Interval 89 (2200000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0683\n",
      "33 episodes - episode_reward: 50.879 [17.000, 75.000] - loss: 0.118 - mean_absolute_error: 5.654 - mean_q: 6.465 - mean_eps: 0.522 - ale.lives: 2.103\n",
      "\n",
      "Interval 90 (2225000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0672\n",
      "32 episodes - episode_reward: 53.125 [28.000, 92.000] - loss: 0.118 - mean_absolute_error: 5.712 - mean_q: 6.529 - mean_eps: 0.520 - ale.lives: 2.136\n",
      "\n",
      "Interval 91 (2250000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0658\n",
      "33 episodes - episode_reward: 50.667 [20.000, 77.000] - loss: 0.119 - mean_absolute_error: 5.725 - mean_q: 6.544 - mean_eps: 0.519 - ale.lives: 2.112\n",
      "\n",
      "Interval 92 (2275000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0675\n",
      "29 episodes - episode_reward: 56.448 [24.000, 92.000] - loss: 0.119 - mean_absolute_error: 5.795 - mean_q: 6.620 - mean_eps: 0.518 - ale.lives: 2.097\n",
      "\n",
      "Interval 93 (2300000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0692\n",
      "31 episodes - episode_reward: 56.774 [34.000, 94.000] - loss: 0.120 - mean_absolute_error: 5.855 - mean_q: 6.688 - mean_eps: 0.516 - ale.lives: 2.144\n",
      "\n",
      "Interval 94 (2325000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0657\n",
      "28 episodes - episode_reward: 59.357 [21.000, 94.000] - loss: 0.122 - mean_absolute_error: 5.895 - mean_q: 6.734 - mean_eps: 0.515 - ale.lives: 2.076\n",
      "\n",
      "Interval 95 (2350000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0689\n",
      "30 episodes - episode_reward: 56.967 [22.000, 87.000] - loss: 0.125 - mean_absolute_error: 5.914 - mean_q: 6.757 - mean_eps: 0.513 - ale.lives: 2.101\n",
      "\n",
      "Interval 96 (2375000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0706\n",
      "31 episodes - episode_reward: 56.387 [29.000, 85.000] - loss: 0.120 - mean_absolute_error: 5.936 - mean_q: 6.783 - mean_eps: 0.512 - ale.lives: 2.091\n",
      "\n",
      "Interval 97 (2400000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0678\n",
      "30 episodes - episode_reward: 57.500 [22.000, 87.000] - loss: 0.118 - mean_absolute_error: 5.949 - mean_q: 6.797 - mean_eps: 0.510 - ale.lives: 2.149\n",
      "\n",
      "Interval 98 (2425000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0690\n",
      "30 episodes - episode_reward: 56.733 [27.000, 103.000] - loss: 0.120 - mean_absolute_error: 6.003 - mean_q: 6.856 - mean_eps: 0.509 - ale.lives: 2.142\n",
      "\n",
      "Interval 99 (2450000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0661\n",
      "29 episodes - episode_reward: 56.931 [31.000, 80.000] - loss: 0.123 - mean_absolute_error: 5.988 - mean_q: 6.839 - mean_eps: 0.507 - ale.lives: 2.077\n",
      "\n",
      "Interval 100 (2475000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0705\n",
      "29 episodes - episode_reward: 61.000 [32.000, 86.000] - loss: 0.122 - mean_absolute_error: 6.036 - mean_q: 6.890 - mean_eps: 0.506 - ale.lives: 2.021\n",
      "\n",
      "Interval 101 (2500000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0673\n",
      "30 episodes - episode_reward: 55.067 [18.000, 95.000] - loss: 0.123 - mean_absolute_error: 6.057 - mean_q: 6.918 - mean_eps: 0.505 - ale.lives: 2.110\n",
      "\n",
      "Interval 102 (2525000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0683\n",
      "30 episodes - episode_reward: 57.633 [34.000, 85.000] - loss: 0.123 - mean_absolute_error: 6.083 - mean_q: 6.946 - mean_eps: 0.503 - ale.lives: 2.062\n",
      "\n",
      "Interval 103 (2550000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0677\n",
      "28 episodes - episode_reward: 59.357 [42.000, 79.000] - loss: 0.126 - mean_absolute_error: 6.111 - mean_q: 6.976 - mean_eps: 0.502 - ale.lives: 2.085\n",
      "\n",
      "Interval 104 (2575000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0688\n",
      "30 episodes - episode_reward: 58.300 [32.000, 88.000] - loss: 0.124 - mean_absolute_error: 6.128 - mean_q: 6.993 - mean_eps: 0.500 - ale.lives: 2.108\n",
      "\n",
      "Interval 105 (2600000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0650\n",
      "29 episodes - episode_reward: 56.517 [29.000, 94.000] - loss: 0.123 - mean_absolute_error: 6.137 - mean_q: 7.003 - mean_eps: 0.499 - ale.lives: 2.117\n",
      "\n",
      "Interval 106 (2625000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0681\n",
      "30 episodes - episode_reward: 57.100 [32.000, 83.000] - loss: 0.122 - mean_absolute_error: 6.203 - mean_q: 7.076 - mean_eps: 0.497 - ale.lives: 2.110\n",
      "\n",
      "Interval 107 (2650000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.06682s  -\n",
      "30 episodes - episode_reward: 55.867 [24.000, 84.000] - loss: 0.117 - mean_absolute_error: 6.231 - mean_q: 7.106 - mean_eps: 0.496 - ale.lives: 2.075\n",
      "\n",
      "Interval 108 (2675000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0693\n",
      "30 episodes - episode_reward: 56.900 [25.000, 89.000] - loss: 0.120 - mean_absolute_error: 6.323 - mean_q: 7.208 - mean_eps: 0.494 - ale.lives: 2.201\n",
      "\n",
      "Interval 109 (2700000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0684\n",
      "31 episodes - episode_reward: 56.032 [30.000, 88.000] - loss: 0.121 - mean_absolute_error: 6.309 - mean_q: 7.192 - mean_eps: 0.493 - ale.lives: 2.073\n",
      "\n",
      "Interval 110 (2725000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0704\n",
      "31 episodes - episode_reward: 56.645 [26.000, 88.000] - loss: 0.117 - mean_absolute_error: 6.405 - mean_q: 7.302 - mean_eps: 0.492 - ale.lives: 2.148\n",
      "\n",
      "Interval 111 (2750000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0709\n",
      "32 episodes - episode_reward: 55.062 [20.000, 78.000] - loss: 0.120 - mean_absolute_error: 6.422 - mean_q: 7.324 - mean_eps: 0.490 - ale.lives: 2.100\n",
      "\n",
      "Interval 112 (2775000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0726\n",
      "27 episodes - episode_reward: 66.778 [23.000, 106.000] - loss: 0.119 - mean_absolute_error: 6.452 - mean_q: 7.358 - mean_eps: 0.489 - ale.lives: 2.066\n",
      "\n",
      "Interval 113 (2800000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0692\n",
      "32 episodes - episode_reward: 52.438 [14.000, 83.000] - loss: 0.118 - mean_absolute_error: 6.456 - mean_q: 7.362 - mean_eps: 0.487 - ale.lives: 2.082\n",
      "\n",
      "Interval 114 (2825000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0708\n",
      "29 episodes - episode_reward: 61.448 [18.000, 97.000] - loss: 0.121 - mean_absolute_error: 6.546 - mean_q: 7.461 - mean_eps: 0.486 - ale.lives: 2.131\n",
      "\n",
      "Interval 115 (2850000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0690\n",
      "29 episodes - episode_reward: 60.241 [24.000, 83.000] - loss: 0.122 - mean_absolute_error: 6.556 - mean_q: 7.473 - mean_eps: 0.484 - ale.lives: 2.206\n",
      "\n",
      "Interval 116 (2875000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0678\n",
      "27 episodes - episode_reward: 64.519 [29.000, 112.000] - loss: 0.120 - mean_absolute_error: 6.554 - mean_q: 7.474 - mean_eps: 0.483 - ale.lives: 2.115\n",
      "\n",
      "Interval 117 (2900000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0723\n",
      "28 episodes - episode_reward: 62.250 [27.000, 90.000] - loss: 0.116 - mean_absolute_error: 6.568 - mean_q: 7.489 - mean_eps: 0.481 - ale.lives: 2.101\n",
      "\n",
      "Interval 118 (2925000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0716\n",
      "28 episodes - episode_reward: 65.357 [32.000, 96.000] - loss: 0.117 - mean_absolute_error: 6.581 - mean_q: 7.503 - mean_eps: 0.480 - ale.lives: 2.211\n",
      "\n",
      "Interval 119 (2950000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0735\n",
      "29 episodes - episode_reward: 62.517 [29.000, 100.000] - loss: 0.116 - mean_absolute_error: 6.618 - mean_q: 7.544 - mean_eps: 0.478 - ale.lives: 2.210\n",
      "\n",
      "Interval 120 (2975000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0694\n",
      "27 episodes - episode_reward: 65.000 [38.000, 90.000] - loss: 0.115 - mean_absolute_error: 6.626 - mean_q: 7.553 - mean_eps: 0.477 - ale.lives: 2.134\n",
      "\n",
      "Interval 121 (3000000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0707\n",
      "28 episodes - episode_reward: 61.464 [25.000, 101.000] - loss: 0.116 - mean_absolute_error: 6.638 - mean_q: 7.567 - mean_eps: 0.476 - ale.lives: 2.186\n",
      "\n",
      "Interval 122 (3025000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.07421s\n",
      "31 episodes - episode_reward: 60.710 [27.000, 102.000] - loss: 0.112 - mean_absolute_error: 6.628 - mean_q: 7.557 - mean_eps: 0.474 - ale.lives: 2.197\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval 123 (3050000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0727\n",
      "30 episodes - episode_reward: 60.700 [26.000, 88.000] - loss: 0.117 - mean_absolute_error: 6.629 - mean_q: 7.556 - mean_eps: 0.473 - ale.lives: 2.163\n",
      "\n",
      "Interval 124 (3075000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0716\n",
      "27 episodes - episode_reward: 64.963 [27.000, 104.000] - loss: 0.115 - mean_absolute_error: 6.649 - mean_q: 7.579 - mean_eps: 0.471 - ale.lives: 2.136\n",
      "\n",
      "Interval 125 (3100000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0748\n",
      "28 episodes - episode_reward: 67.357 [32.000, 97.000] - loss: 0.115 - mean_absolute_error: 6.668 - mean_q: 7.599 - mean_eps: 0.470 - ale.lives: 2.261\n",
      "\n",
      "Interval 126 (3125000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0729A: 0s - rewa\n",
      "28 episodes - episode_reward: 64.929 [31.000, 93.000] - loss: 0.113 - mean_absolute_error: 6.720 - mean_q: 7.658 - mean_eps: 0.468 - ale.lives: 2.234\n",
      "\n",
      "Interval 127 (3150000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0747\n",
      "28 episodes - episode_reward: 67.107 [32.000, 94.000] - loss: 0.115 - mean_absolute_error: 6.712 - mean_q: 7.650 - mean_eps: 0.467 - ale.lives: 2.228\n",
      "\n",
      "Interval 128 (3175000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0718\n",
      "27 episodes - episode_reward: 66.444 [38.000, 89.000] - loss: 0.115 - mean_absolute_error: 6.717 - mean_q: 7.652 - mean_eps: 0.465 - ale.lives: 2.162\n",
      "\n",
      "Interval 129 (3200000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0757\n",
      "28 episodes - episode_reward: 67.464 [27.000, 93.000] - loss: 0.113 - mean_absolute_error: 6.721 - mean_q: 7.658 - mean_eps: 0.464 - ale.lives: 2.208\n",
      "\n",
      "Interval 130 (3225000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0736\n",
      "28 episodes - episode_reward: 67.821 [21.000, 94.000] - loss: 0.110 - mean_absolute_error: 6.735 - mean_q: 7.673 - mean_eps: 0.463 - ale.lives: 2.178\n",
      "\n",
      "Interval 131 (3250000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0719\n",
      "26 episodes - episode_reward: 66.846 [23.000, 97.000] - loss: 0.112 - mean_absolute_error: 6.721 - mean_q: 7.657 - mean_eps: 0.461 - ale.lives: 2.255\n",
      "\n",
      "Interval 132 (3275000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0710\n",
      "27 episodes - episode_reward: 65.407 [42.000, 87.000] - loss: 0.112 - mean_absolute_error: 6.739 - mean_q: 7.678 - mean_eps: 0.460 - ale.lives: 2.236\n",
      "\n",
      "Interval 133 (3300000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0738\n",
      "29 episodes - episode_reward: 65.276 [39.000, 102.000] - loss: 0.112 - mean_absolute_error: 6.761 - mean_q: 7.703 - mean_eps: 0.458 - ale.lives: 2.182\n",
      "\n",
      "Interval 134 (3325000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0743\n",
      "29 episodes - episode_reward: 62.655 [27.000, 86.000] - loss: 0.112 - mean_absolute_error: 6.773 - mean_q: 7.717 - mean_eps: 0.457 - ale.lives: 2.223\n",
      "\n",
      "Interval 135 (3350000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0758\n",
      "27 episodes - episode_reward: 69.778 [49.000, 97.000] - loss: 0.114 - mean_absolute_error: 6.833 - mean_q: 7.785 - mean_eps: 0.455 - ale.lives: 2.208\n",
      "\n",
      "Interval 136 (3375000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.07300s - reward: 0.073\n",
      "26 episodes - episode_reward: 71.654 [36.000, 98.000] - loss: 0.114 - mean_absolute_error: 6.849 - mean_q: 7.802 - mean_eps: 0.454 - ale.lives: 2.250\n",
      "\n",
      "Interval 137 (3400000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0711\n",
      "26 episodes - episode_reward: 68.731 [25.000, 102.000] - loss: 0.112 - mean_absolute_error: 6.880 - mean_q: 7.838 - mean_eps: 0.452 - ale.lives: 2.235\n",
      "\n",
      "Interval 138 (3425000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0744\n",
      "25 episodes - episode_reward: 73.880 [53.000, 103.000] - loss: 0.110 - mean_absolute_error: 6.916 - mean_q: 7.876 - mean_eps: 0.451 - ale.lives: 2.246\n",
      "\n",
      "Interval 139 (3450000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0724\n",
      "27 episodes - episode_reward: 66.111 [21.000, 100.000] - loss: 0.110 - mean_absolute_error: 6.885 - mean_q: 7.841 - mean_eps: 0.450 - ale.lives: 2.178\n",
      "\n",
      "Interval 140 (3475000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0738\n",
      "27 episodes - episode_reward: 69.444 [36.000, 98.000] - loss: 0.113 - mean_absolute_error: 6.906 - mean_q: 7.865 - mean_eps: 0.448 - ale.lives: 2.267\n",
      "\n",
      "Interval 141 (3500000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0735\n",
      "28 episodes - episode_reward: 65.893 [42.000, 93.000] - loss: 0.115 - mean_absolute_error: 6.972 - mean_q: 7.937 - mean_eps: 0.447 - ale.lives: 2.269\n",
      "\n",
      "Interval 142 (3525000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0770\n",
      "27 episodes - episode_reward: 69.185 [43.000, 104.000] - loss: 0.112 - mean_absolute_error: 6.996 - mean_q: 7.966 - mean_eps: 0.445 - ale.lives: 2.278\n",
      "\n",
      "Interval 143 (3550000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0751\n",
      "26 episodes - episode_reward: 72.731 [34.000, 100.000] - loss: 0.115 - mean_absolute_error: 7.013 - mean_q: 7.982 - mean_eps: 0.444 - ale.lives: 2.190\n",
      "\n",
      "Interval 144 (3575000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.07620s -\n",
      "27 episodes - episode_reward: 72.148 [41.000, 100.000] - loss: 0.117 - mean_absolute_error: 6.986 - mean_q: 7.951 - mean_eps: 0.442 - ale.lives: 2.212\n",
      "\n",
      "Interval 145 (3600000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0747\n",
      "27 episodes - episode_reward: 69.111 [40.000, 95.000] - loss: 0.111 - mean_absolute_error: 6.993 - mean_q: 7.960 - mean_eps: 0.441 - ale.lives: 2.285\n",
      "\n",
      "Interval 146 (3625000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0784\n",
      "28 episodes - episode_reward: 69.750 [42.000, 90.000] - loss: 0.115 - mean_absolute_error: 6.959 - mean_q: 7.922 - mean_eps: 0.439 - ale.lives: 2.294\n",
      "\n",
      "Interval 147 (3650000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0726\n",
      "26 episodes - episode_reward: 68.038 [22.000, 94.000] - loss: 0.112 - mean_absolute_error: 6.994 - mean_q: 7.964 - mean_eps: 0.438 - ale.lives: 2.293\n",
      "\n",
      "Interval 148 (3675000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0748\n",
      "26 episodes - episode_reward: 72.115 [47.000, 97.000] - loss: 0.116 - mean_absolute_error: 6.949 - mean_q: 7.912 - mean_eps: 0.437 - ale.lives: 2.164\n",
      "\n",
      "Interval 149 (3700000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0786\n",
      "27 episodes - episode_reward: 73.000 [41.000, 97.000] - loss: 0.115 - mean_absolute_error: 6.970 - mean_q: 7.938 - mean_eps: 0.435 - ale.lives: 2.269\n",
      "\n",
      "Interval 150 (3725000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0742\n",
      "25 episodes - episode_reward: 74.360 [50.000, 100.000] - loss: 0.111 - mean_absolute_error: 6.976 - mean_q: 7.945 - mean_eps: 0.434 - ale.lives: 2.180\n",
      "\n",
      "Interval 151 (3750000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0782\n",
      "27 episodes - episode_reward: 72.593 [30.000, 89.000] - loss: 0.114 - mean_absolute_error: 6.936 - mean_q: 7.896 - mean_eps: 0.432 - ale.lives: 2.245\n",
      "\n",
      "Interval 152 (3775000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.07541s - rewa - ETA: 0s - reward:\n",
      "25 episodes - episode_reward: 74.040 [53.000, 105.000] - loss: 0.111 - mean_absolute_error: 6.927 - mean_q: 7.886 - mean_eps: 0.431 - ale.lives: 2.201\n",
      "\n",
      "Interval 153 (3800000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0752\n",
      "25 episodes - episode_reward: 77.520 [51.000, 118.000] - loss: 0.108 - mean_absolute_error: 6.912 - mean_q: 7.869 - mean_eps: 0.429 - ale.lives: 2.249\n",
      "\n",
      "Interval 154 (3825000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0755\n",
      "27 episodes - episode_reward: 70.778 [42.000, 112.000] - loss: 0.110 - mean_absolute_error: 6.924 - mean_q: 7.882 - mean_eps: 0.428 - ale.lives: 2.230\n",
      "\n",
      "Interval 155 (3850000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0770\n",
      "27 episodes - episode_reward: 70.704 [35.000, 93.000] - loss: 0.112 - mean_absolute_error: 6.941 - mean_q: 7.899 - mean_eps: 0.426 - ale.lives: 2.227\n",
      "\n",
      "Interval 156 (3875000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0763\n",
      "27 episodes - episode_reward: 69.000 [29.000, 104.000] - loss: 0.111 - mean_absolute_error: 6.922 - mean_q: 7.878 - mean_eps: 0.425 - ale.lives: 2.208\n",
      "\n",
      "Interval 157 (3900000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0787\n",
      "28 episodes - episode_reward: 71.714 [41.000, 105.000] - loss: 0.108 - mean_absolute_error: 6.956 - mean_q: 7.918 - mean_eps: 0.423 - ale.lives: 2.267\n",
      "\n",
      "Interval 158 (3925000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0756\n",
      "26 episodes - episode_reward: 72.692 [39.000, 101.000] - loss: 0.108 - mean_absolute_error: 6.958 - mean_q: 7.917 - mean_eps: 0.422 - ale.lives: 2.235\n",
      "\n",
      "Interval 159 (3950000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0759\n",
      "25 episodes - episode_reward: 75.440 [45.000, 108.000] - loss: 0.111 - mean_absolute_error: 6.925 - mean_q: 7.882 - mean_eps: 0.421 - ale.lives: 2.225\n",
      "\n",
      "Interval 160 (3975000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0780\n",
      "26 episodes - episode_reward: 73.423 [36.000, 113.000] - loss: 0.105 - mean_absolute_error: 6.939 - mean_q: 7.896 - mean_eps: 0.419 - ale.lives: 2.241\n",
      "\n",
      "Interval 161 (4000000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0799\n",
      "29 episodes - episode_reward: 71.310 [35.000, 99.000] - loss: 0.107 - mean_absolute_error: 6.906 - mean_q: 7.858 - mean_eps: 0.418 - ale.lives: 2.264\n",
      "\n",
      "Interval 162 (4025000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0746\n",
      "25 episodes - episode_reward: 73.560 [37.000, 107.000] - loss: 0.105 - mean_absolute_error: 6.883 - mean_q: 7.833 - mean_eps: 0.416 - ale.lives: 2.222\n",
      "\n",
      "Interval 163 (4050000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0778\n",
      "28 episodes - episode_reward: 69.679 [24.000, 93.000] - loss: 0.102 - mean_absolute_error: 6.920 - mean_q: 7.872 - mean_eps: 0.415 - ale.lives: 2.188\n",
      "\n",
      "Interval 164 (4075000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0744\n",
      "25 episodes - episode_reward: 71.320 [36.000, 97.000] - loss: 0.105 - mean_absolute_error: 6.883 - mean_q: 7.831 - mean_eps: 0.413 - ale.lives: 2.195\n",
      "\n",
      "Interval 165 (4100000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0734\n",
      "27 episodes - episode_reward: 69.963 [43.000, 114.000] - loss: 0.105 - mean_absolute_error: 6.922 - mean_q: 7.877 - mean_eps: 0.412 - ale.lives: 2.125\n",
      "\n",
      "Interval 166 (4125000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0739\n",
      "28 episodes - episode_reward: 66.214 [38.000, 121.000] - loss: 0.103 - mean_absolute_error: 6.921 - mean_q: 7.874 - mean_eps: 0.410 - ale.lives: 2.205\n",
      "\n",
      "Interval 167 (4150000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0769\n",
      "26 episodes - episode_reward: 74.115 [30.000, 113.000] - loss: 0.104 - mean_absolute_error: 6.956 - mean_q: 7.913 - mean_eps: 0.409 - ale.lives: 2.276\n",
      "\n",
      "Interval 168 (4175000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0740\n",
      "28 episodes - episode_reward: 65.464 [31.000, 98.000] - loss: 0.109 - mean_absolute_error: 6.905 - mean_q: 7.856 - mean_eps: 0.408 - ale.lives: 2.153\n",
      "\n",
      "Interval 169 (4200000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0723\n",
      "28 episodes - episode_reward: 66.643 [42.000, 98.000] - loss: 0.107 - mean_absolute_error: 6.945 - mean_q: 7.901 - mean_eps: 0.406 - ale.lives: 2.248\n",
      "\n",
      "Interval 170 (4225000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0796\n",
      "27 episodes - episode_reward: 72.667 [36.000, 111.000] - loss: 0.107 - mean_absolute_error: 6.954 - mean_q: 7.911 - mean_eps: 0.405 - ale.lives: 2.204\n",
      "\n",
      "Interval 171 (4250000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0760\n",
      "28 episodes - episode_reward: 67.929 [35.000, 103.000] - loss: 0.106 - mean_absolute_error: 6.988 - mean_q: 7.949 - mean_eps: 0.403 - ale.lives: 2.243\n",
      "\n",
      "Interval 172 (4275000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0743\n",
      "24 episodes - episode_reward: 76.458 [43.000, 103.000] - loss: 0.103 - mean_absolute_error: 6.978 - mean_q: 7.938 - mean_eps: 0.402 - ale.lives: 2.228\n",
      "\n",
      "Interval 173 (4300000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0786\n",
      "26 episodes - episode_reward: 76.346 [39.000, 128.000] - loss: 0.100 - mean_absolute_error: 6.945 - mean_q: 7.900 - mean_eps: 0.400 - ale.lives: 2.242\n",
      "\n",
      "Interval 174 (4325000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0784\n",
      "27 episodes - episode_reward: 71.259 [43.000, 98.000] - loss: 0.102 - mean_absolute_error: 6.870 - mean_q: 7.815 - mean_eps: 0.399 - ale.lives: 2.273\n",
      "\n",
      "Interval 175 (4350000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0751\n",
      "26 episodes - episode_reward: 72.500 [23.000, 109.000] - loss: 0.100 - mean_absolute_error: 6.844 - mean_q: 7.786 - mean_eps: 0.397 - ale.lives: 2.237\n",
      "\n",
      "Interval 176 (4375000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0766\n",
      "25 episodes - episode_reward: 76.640 [47.000, 113.000] - loss: 0.101 - mean_absolute_error: 6.843 - mean_q: 7.784 - mean_eps: 0.396 - ale.lives: 2.205\n",
      "\n",
      "Interval 177 (4400000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0769\n",
      "25 episodes - episode_reward: 75.680 [30.000, 105.000] - loss: 0.105 - mean_absolute_error: 6.803 - mean_q: 7.736 - mean_eps: 0.395 - ale.lives: 2.214\n",
      "\n",
      "Interval 178 (4425000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0760\n",
      "27 episodes - episode_reward: 72.444 [40.000, 103.000] - loss: 0.101 - mean_absolute_error: 6.799 - mean_q: 7.734 - mean_eps: 0.393 - ale.lives: 2.295\n",
      "\n",
      "Interval 179 (4450000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0814\n",
      "27 episodes - episode_reward: 73.519 [48.000, 94.000] - loss: 0.102 - mean_absolute_error: 6.820 - mean_q: 7.756 - mean_eps: 0.392 - ale.lives: 2.219\n",
      "\n",
      "Interval 180 (4475000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0816\n",
      "26 episodes - episode_reward: 80.115 [49.000, 116.000] - loss: 0.103 - mean_absolute_error: 6.841 - mean_q: 7.780 - mean_eps: 0.390 - ale.lives: 2.218\n",
      "\n",
      "Interval 181 (4500000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0758\n",
      "25 episodes - episode_reward: 73.960 [30.000, 105.000] - loss: 0.101 - mean_absolute_error: 6.796 - mean_q: 7.728 - mean_eps: 0.389 - ale.lives: 2.190\n",
      "\n",
      "Interval 182 (4525000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0784\n",
      "27 episodes - episode_reward: 75.815 [36.000, 108.000] - loss: 0.102 - mean_absolute_error: 6.843 - mean_q: 7.783 - mean_eps: 0.387 - ale.lives: 2.257\n",
      "\n",
      "Interval 183 (4550000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0782\n",
      "27 episodes - episode_reward: 69.000 [29.000, 99.000] - loss: 0.102 - mean_absolute_error: 6.862 - mean_q: 7.805 - mean_eps: 0.386 - ale.lives: 2.230\n",
      "\n",
      "Interval 184 (4575000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0743\n",
      "27 episodes - episode_reward: 72.185 [29.000, 106.000] - loss: 0.102 - mean_absolute_error: 6.869 - mean_q: 7.812 - mean_eps: 0.384 - ale.lives: 2.230\n",
      "\n",
      "Interval 185 (4600000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0770\n",
      "24 episodes - episode_reward: 76.875 [28.000, 108.000] - loss: 0.102 - mean_absolute_error: 6.864 - mean_q: 7.806 - mean_eps: 0.383 - ale.lives: 2.194\n",
      "\n",
      "Interval 186 (4625000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0767\n",
      "25 episodes - episode_reward: 79.880 [42.000, 109.000] - loss: 0.102 - mean_absolute_error: 6.853 - mean_q: 7.795 - mean_eps: 0.382 - ale.lives: 2.243\n",
      "\n",
      "Interval 187 (4650000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0750\n",
      "26 episodes - episode_reward: 70.538 [44.000, 102.000] - loss: 0.102 - mean_absolute_error: 6.812 - mean_q: 7.749 - mean_eps: 0.380 - ale.lives: 2.172\n",
      "\n",
      "Interval 188 (4675000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0792\n",
      "28 episodes - episode_reward: 70.143 [33.000, 105.000] - loss: 0.102 - mean_absolute_error: 6.830 - mean_q: 7.770 - mean_eps: 0.379 - ale.lives: 2.186\n",
      "\n",
      "Interval 189 (4700000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0792\n",
      "27 episodes - episode_reward: 73.259 [36.000, 117.000] - loss: 0.103 - mean_absolute_error: 6.858 - mean_q: 7.803 - mean_eps: 0.377 - ale.lives: 2.144\n",
      "\n",
      "Interval 190 (4725000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0801\n",
      "27 episodes - episode_reward: 74.407 [22.000, 111.000] - loss: 0.103 - mean_absolute_error: 6.892 - mean_q: 7.842 - mean_eps: 0.376 - ale.lives: 2.261\n",
      "\n",
      "Interval 191 (4750000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0747\n",
      "27 episodes - episode_reward: 70.185 [36.000, 106.000] - loss: 0.101 - mean_absolute_error: 6.921 - mean_q: 7.875 - mean_eps: 0.374 - ale.lives: 2.254\n",
      "\n",
      "Interval 192 (4775000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0818\n",
      "28 episodes - episode_reward: 73.893 [25.000, 111.000] - loss: 0.099 - mean_absolute_error: 6.974 - mean_q: 7.934 - mean_eps: 0.373 - ale.lives: 2.211\n",
      "\n",
      "Interval 193 (4800000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0744\n",
      "24 episodes - episode_reward: 74.750 [26.000, 104.000] - loss: 0.103 - mean_absolute_error: 7.034 - mean_q: 8.001 - mean_eps: 0.371 - ale.lives: 2.186\n",
      "\n",
      "Interval 194 (4825000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0753\n",
      "27 episodes - episode_reward: 69.519 [36.000, 103.000] - loss: 0.100 - mean_absolute_error: 7.009 - mean_q: 7.972 - mean_eps: 0.370 - ale.lives: 2.207\n",
      "\n",
      "Interval 195 (4850000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0798\n",
      "27 episodes - episode_reward: 73.778 [43.000, 117.000] - loss: 0.102 - mean_absolute_error: 7.045 - mean_q: 8.015 - mean_eps: 0.368 - ale.lives: 2.194\n",
      "\n",
      "Interval 196 (4875000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.08000s - reward: \n",
      "26 episodes - episode_reward: 77.192 [38.000, 129.000] - loss: 0.104 - mean_absolute_error: 7.096 - mean_q: 8.072 - mean_eps: 0.367 - ale.lives: 2.133\n",
      "\n",
      "Interval 197 (4900000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0772\n",
      "29 episodes - episode_reward: 68.034 [33.000, 100.000] - loss: 0.102 - mean_absolute_error: 7.142 - mean_q: 8.122 - mean_eps: 0.366 - ale.lives: 2.199\n",
      "\n",
      "Interval 198 (4925000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0758\n",
      "24 episodes - episode_reward: 77.458 [33.000, 110.000] - loss: 0.108 - mean_absolute_error: 7.142 - mean_q: 8.124 - mean_eps: 0.364 - ale.lives: 2.208\n",
      "\n",
      "Interval 199 (4950000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0818\n",
      "26 episodes - episode_reward: 81.038 [52.000, 102.000] - loss: 0.102 - mean_absolute_error: 7.113 - mean_q: 8.092 - mean_eps: 0.363 - ale.lives: 2.200\n",
      "\n",
      "Interval 200 (4975000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.07980s -\n",
      "25 episodes - episode_reward: 77.280 [35.000, 109.000] - loss: 0.104 - mean_absolute_error: 7.078 - mean_q: 8.054 - mean_eps: 0.361 - ale.lives: 2.200\n",
      "\n",
      "Interval 201 (5000000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0810\n",
      "25 episodes - episode_reward: 82.280 [35.000, 120.000] - loss: 0.103 - mean_absolute_error: 7.121 - mean_q: 8.103 - mean_eps: 0.360 - ale.lives: 2.186\n",
      "\n",
      "Interval 202 (5025000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0808\n",
      "25 episodes - episode_reward: 79.240 [42.000, 109.000] - loss: 0.101 - mean_absolute_error: 7.108 - mean_q: 8.088 - mean_eps: 0.358 - ale.lives: 2.147\n",
      "\n",
      "Interval 203 (5050000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0788\n",
      "26 episodes - episode_reward: 77.038 [44.000, 114.000] - loss: 0.106 - mean_absolute_error: 7.146 - mean_q: 8.129 - mean_eps: 0.357 - ale.lives: 2.236\n",
      "\n",
      "Interval 204 (5075000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0804\n",
      "26 episodes - episode_reward: 75.385 [42.000, 103.000] - loss: 0.103 - mean_absolute_error: 7.168 - mean_q: 8.157 - mean_eps: 0.355 - ale.lives: 2.233\n",
      "\n",
      "Interval 205 (5100000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0770\n",
      "26 episodes - episode_reward: 77.269 [35.000, 126.000] - loss: 0.106 - mean_absolute_error: 7.142 - mean_q: 8.127 - mean_eps: 0.354 - ale.lives: 2.149\n",
      "\n",
      "Interval 206 (5125000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.08381s\n",
      "27 episodes - episode_reward: 74.407 [36.000, 113.000] - loss: 0.107 - mean_absolute_error: 7.149 - mean_q: 8.137 - mean_eps: 0.353 - ale.lives: 2.195\n",
      "\n",
      "Interval 207 (5150000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.08060s - rewa\n",
      "27 episodes - episode_reward: 77.259 [34.000, 101.000] - loss: 0.103 - mean_absolute_error: 7.251 - mean_q: 8.253 - mean_eps: 0.351 - ale.lives: 2.210\n",
      "\n",
      "Interval 208 (5175000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0830\n",
      "27 episodes - episode_reward: 77.519 [37.000, 113.000] - loss: 0.104 - mean_absolute_error: 7.271 - mean_q: 8.276 - mean_eps: 0.350 - ale.lives: 2.185\n",
      "\n",
      "Interval 209 (5200000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0812\n",
      "28 episodes - episode_reward: 70.500 [40.000, 117.000] - loss: 0.103 - mean_absolute_error: 7.247 - mean_q: 8.251 - mean_eps: 0.348 - ale.lives: 2.226\n",
      "\n",
      "Interval 210 (5225000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0817\n",
      "26 episodes - episode_reward: 78.846 [31.000, 109.000] - loss: 0.104 - mean_absolute_error: 7.286 - mean_q: 8.292 - mean_eps: 0.347 - ale.lives: 2.206\n",
      "\n",
      "Interval 211 (5250000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0854\n",
      "26 episodes - episode_reward: 81.385 [26.000, 102.000] - loss: 0.107 - mean_absolute_error: 7.365 - mean_q: 8.381 - mean_eps: 0.345 - ale.lives: 2.279\n",
      "\n",
      "Interval 212 (5275000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0815\n",
      "26 episodes - episode_reward: 78.577 [25.000, 113.000] - loss: 0.108 - mean_absolute_error: 7.366 - mean_q: 8.383 - mean_eps: 0.344 - ale.lives: 2.230\n",
      "\n",
      "Interval 213 (5300000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0774\n",
      "25 episodes - episode_reward: 77.240 [27.000, 104.000] - loss: 0.107 - mean_absolute_error: 7.417 - mean_q: 8.442 - mean_eps: 0.342 - ale.lives: 2.198\n",
      "\n",
      "Interval 214 (5325000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0810\n",
      "27 episodes - episode_reward: 76.333 [27.000, 102.000] - loss: 0.107 - mean_absolute_error: 7.492 - mean_q: 8.525 - mean_eps: 0.341 - ale.lives: 2.208\n",
      "\n",
      "Interval 215 (5350000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0834\n",
      "26 episodes - episode_reward: 77.923 [36.000, 107.000] - loss: 0.107 - mean_absolute_error: 7.486 - mean_q: 8.520 - mean_eps: 0.340 - ale.lives: 2.277\n",
      "\n",
      "Interval 216 (5375000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0820\n",
      "28 episodes - episode_reward: 75.143 [32.000, 120.000] - loss: 0.106 - mean_absolute_error: 7.492 - mean_q: 8.526 - mean_eps: 0.338 - ale.lives: 2.237\n",
      "\n",
      "Interval 217 (5400000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0810\n",
      "25 episodes - episode_reward: 78.600 [31.000, 111.000] - loss: 0.103 - mean_absolute_error: 7.458 - mean_q: 8.486 - mean_eps: 0.337 - ale.lives: 2.148\n",
      "\n",
      "Interval 218 (5425000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0826\n",
      "27 episodes - episode_reward: 77.667 [35.000, 110.000] - loss: 0.105 - mean_absolute_error: 7.442 - mean_q: 8.468 - mean_eps: 0.335 - ale.lives: 2.231\n",
      "\n",
      "Interval 219 (5450000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0850\n",
      "26 episodes - episode_reward: 81.615 [30.000, 120.000] - loss: 0.107 - mean_absolute_error: 7.456 - mean_q: 8.486 - mean_eps: 0.334 - ale.lives: 2.133\n",
      "\n",
      "Interval 220 (5475000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0836\n",
      "25 episodes - episode_reward: 82.840 [48.000, 105.000] - loss: 0.109 - mean_absolute_error: 7.385 - mean_q: 8.408 - mean_eps: 0.332 - ale.lives: 2.259\n",
      "\n",
      "Interval 221 (5500000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0820\n",
      "25 episodes - episode_reward: 82.480 [41.000, 117.000] - loss: 0.105 - mean_absolute_error: 7.394 - mean_q: 8.416 - mean_eps: 0.331 - ale.lives: 2.244\n",
      "\n",
      "Interval 222 (5525000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0832\n",
      "25 episodes - episode_reward: 83.400 [44.000, 113.000] - loss: 0.108 - mean_absolute_error: 7.417 - mean_q: 8.442 - mean_eps: 0.329 - ale.lives: 2.296\n",
      "\n",
      "Interval 223 (5550000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0822\n",
      "24 episodes - episode_reward: 86.417 [35.000, 117.000] - loss: 0.108 - mean_absolute_error: 7.419 - mean_q: 8.445 - mean_eps: 0.328 - ale.lives: 2.183\n",
      "\n",
      "Interval 224 (5575000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0853\n",
      "25 episodes - episode_reward: 85.360 [38.000, 124.000] - loss: 0.109 - mean_absolute_error: 7.405 - mean_q: 8.429 - mean_eps: 0.327 - ale.lives: 2.255\n",
      "\n",
      "Interval 225 (5600000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0837\n",
      "24 episodes - episode_reward: 85.042 [21.000, 115.000] - loss: 0.108 - mean_absolute_error: 7.486 - mean_q: 8.517 - mean_eps: 0.325 - ale.lives: 2.264\n",
      "\n",
      "Interval 226 (5625000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0834\n",
      "24 episodes - episode_reward: 89.417 [50.000, 120.000] - loss: 0.105 - mean_absolute_error: 7.522 - mean_q: 8.558 - mean_eps: 0.324 - ale.lives: 2.207\n",
      "\n",
      "Interval 227 (5650000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0804\n",
      "25 episodes - episode_reward: 81.960 [41.000, 114.000] - loss: 0.108 - mean_absolute_error: 7.533 - mean_q: 8.572 - mean_eps: 0.322 - ale.lives: 2.203\n",
      "\n",
      "Interval 228 (5675000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0872\n",
      "25 episodes - episode_reward: 82.720 [55.000, 106.000] - loss: 0.109 - mean_absolute_error: 7.509 - mean_q: 8.544 - mean_eps: 0.321 - ale.lives: 2.283\n",
      "\n",
      "Interval 229 (5700000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0813\n",
      "25 episodes - episode_reward: 85.040 [46.000, 115.000] - loss: 0.107 - mean_absolute_error: 7.476 - mean_q: 8.509 - mean_eps: 0.319 - ale.lives: 2.239\n",
      "\n",
      "Interval 230 (5725000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0824\n",
      "23 episodes - episode_reward: 89.783 [63.000, 118.000] - loss: 0.107 - mean_absolute_error: 7.452 - mean_q: 8.481 - mean_eps: 0.318 - ale.lives: 2.302\n",
      "\n",
      "Interval 231 (5750000 steps performed)\n",
      "25000/25000 [==============================] - 298s 12ms/step - reward: 0.0842\n",
      "25 episodes - episode_reward: 81.000 [39.000, 111.000] - loss: 0.104 - mean_absolute_error: 7.458 - mean_q: 8.485 - mean_eps: 0.316 - ale.lives: 2.207\n",
      "\n",
      "Interval 232 (5775000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0828\n",
      "25 episodes - episode_reward: 83.720 [30.000, 121.000] - loss: 0.107 - mean_absolute_error: 7.491 - mean_q: 8.525 - mean_eps: 0.315 - ale.lives: 2.098\n",
      "\n",
      "Interval 233 (5800000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0840\n",
      "27 episodes - episode_reward: 76.815 [34.000, 119.000] - loss: 0.108 - mean_absolute_error: 7.501 - mean_q: 8.537 - mean_eps: 0.313 - ale.lives: 2.233\n",
      "\n",
      "Interval 234 (5825000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0808\n",
      "25 episodes - episode_reward: 80.880 [42.000, 110.000] - loss: 0.109 - mean_absolute_error: 7.520 - mean_q: 8.559 - mean_eps: 0.312 - ale.lives: 2.239\n",
      "\n",
      "Interval 235 (5850000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0826\n",
      "25 episodes - episode_reward: 84.560 [39.000, 118.000] - loss: 0.108 - mean_absolute_error: 7.558 - mean_q: 8.601 - mean_eps: 0.311 - ale.lives: 2.251\n",
      "\n",
      "Interval 236 (5875000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0818\n",
      "25 episodes - episode_reward: 80.960 [42.000, 118.000] - loss: 0.111 - mean_absolute_error: 7.558 - mean_q: 8.602 - mean_eps: 0.309 - ale.lives: 2.199\n",
      "\n",
      "Interval 237 (5900000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0818\n",
      "25 episodes - episode_reward: 83.880 [50.000, 122.000] - loss: 0.108 - mean_absolute_error: 7.548 - mean_q: 8.589 - mean_eps: 0.308 - ale.lives: 2.266\n",
      "\n",
      "Interval 238 (5925000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0836\n",
      "26 episodes - episode_reward: 80.538 [30.000, 123.000] - loss: 0.106 - mean_absolute_error: 7.539 - mean_q: 8.579 - mean_eps: 0.306 - ale.lives: 2.314\n",
      "\n",
      "Interval 239 (5950000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.08250s - rewar\n",
      "25 episodes - episode_reward: 80.160 [23.000, 117.000] - loss: 0.108 - mean_absolute_error: 7.534 - mean_q: 8.574 - mean_eps: 0.305 - ale.lives: 2.221\n",
      "\n",
      "Interval 240 (5975000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0864\n",
      "29 episodes - episode_reward: 76.897 [30.000, 125.000] - loss: 0.104 - mean_absolute_error: 7.553 - mean_q: 8.595 - mean_eps: 0.303 - ale.lives: 2.203\n",
      "\n",
      "Interval 241 (6000000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0871\n",
      "25 episodes - episode_reward: 84.960 [40.000, 119.000] - loss: 0.107 - mean_absolute_error: 7.578 - mean_q: 8.626 - mean_eps: 0.302 - ale.lives: 2.246\n",
      "\n",
      "Interval 242 (6025000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0850\n",
      "27 episodes - episode_reward: 78.815 [30.000, 130.000] - loss: 0.107 - mean_absolute_error: 7.619 - mean_q: 8.670 - mean_eps: 0.300 - ale.lives: 2.173\n",
      "\n",
      "Interval 243 (6050000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.08400s - rewa\n",
      "24 episodes - episode_reward: 88.750 [57.000, 126.000] - loss: 0.106 - mean_absolute_error: 7.570 - mean_q: 8.616 - mean_eps: 0.299 - ale.lives: 2.208\n",
      "\n",
      "Interval 244 (6075000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.08480s - rewar\n",
      "26 episodes - episode_reward: 82.346 [43.000, 111.000] - loss: 0.104 - mean_absolute_error: 7.557 - mean_q: 8.599 - mean_eps: 0.298 - ale.lives: 2.207\n",
      "\n",
      "Interval 245 (6100000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0815\n",
      "26 episodes - episode_reward: 76.077 [34.000, 100.000] - loss: 0.104 - mean_absolute_error: 7.572 - mean_q: 8.616 - mean_eps: 0.296 - ale.lives: 2.153\n",
      "\n",
      "Interval 246 (6125000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0832\n",
      "26 episodes - episode_reward: 81.808 [38.000, 103.000] - loss: 0.105 - mean_absolute_error: 7.551 - mean_q: 8.591 - mean_eps: 0.295 - ale.lives: 2.257\n",
      "\n",
      "Interval 247 (6150000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0806\n",
      "23 episodes - episode_reward: 84.913 [22.000, 131.000] - loss: 0.103 - mean_absolute_error: 7.567 - mean_q: 8.610 - mean_eps: 0.293 - ale.lives: 2.235\n",
      "\n",
      "Interval 248 (6175000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0882\n",
      "25 episodes - episode_reward: 88.400 [50.000, 125.000] - loss: 0.106 - mean_absolute_error: 7.556 - mean_q: 8.598 - mean_eps: 0.292 - ale.lives: 2.154\n",
      "\n",
      "Interval 249 (6200000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0770\n",
      "23 episodes - episode_reward: 86.087 [39.000, 119.000] - loss: 0.106 - mean_absolute_error: 7.501 - mean_q: 8.536 - mean_eps: 0.290 - ale.lives: 2.200\n",
      "\n",
      "Interval 250 (6225000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0851\n",
      "25 episodes - episode_reward: 85.120 [34.000, 114.000] - loss: 0.106 - mean_absolute_error: 7.521 - mean_q: 8.560 - mean_eps: 0.289 - ale.lives: 2.289\n",
      "\n",
      "Interval 251 (6250000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0854\n",
      "25 episodes - episode_reward: 82.800 [42.000, 105.000] - loss: 0.106 - mean_absolute_error: 7.573 - mean_q: 8.618 - mean_eps: 0.287 - ale.lives: 2.248\n",
      "\n",
      "Interval 252 (6275000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0804\n",
      "26 episodes - episode_reward: 80.269 [40.000, 106.000] - loss: 0.106 - mean_absolute_error: 7.531 - mean_q: 8.569 - mean_eps: 0.286 - ale.lives: 2.191\n",
      "\n",
      "Interval 253 (6300000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0879\n",
      "23 episodes - episode_reward: 91.522 [44.000, 128.000] - loss: 0.106 - mean_absolute_error: 7.560 - mean_q: 8.601 - mean_eps: 0.285 - ale.lives: 2.240\n",
      "\n",
      "Interval 254 (6325000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.08880s - reward: 0.088\n",
      "26 episodes - episode_reward: 85.423 [34.000, 120.000] - loss: 0.102 - mean_absolute_error: 7.521 - mean_q: 8.559 - mean_eps: 0.283 - ale.lives: 2.253\n",
      "\n",
      "Interval 255 (6350000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0833\n",
      "23 episodes - episode_reward: 91.957 [45.000, 125.000] - loss: 0.103 - mean_absolute_error: 7.505 - mean_q: 8.539 - mean_eps: 0.282 - ale.lives: 2.217\n",
      "\n",
      "Interval 256 (6375000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0853\n",
      "25 episodes - episode_reward: 83.920 [41.000, 115.000] - loss: 0.106 - mean_absolute_error: 7.473 - mean_q: 8.502 - mean_eps: 0.280 - ale.lives: 2.244\n",
      "\n",
      "Interval 257 (6400000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0829\n",
      "23 episodes - episode_reward: 90.957 [44.000, 113.000] - loss: 0.103 - mean_absolute_error: 7.466 - mean_q: 8.494 - mean_eps: 0.279 - ale.lives: 2.161\n",
      "\n",
      "Interval 258 (6425000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0850\n",
      "26 episodes - episode_reward: 81.654 [34.000, 111.000] - loss: 0.101 - mean_absolute_error: 7.454 - mean_q: 8.479 - mean_eps: 0.277 - ale.lives: 2.269\n",
      "\n",
      "Interval 259 (6450000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0831\n",
      "25 episodes - episode_reward: 83.720 [55.000, 105.000] - loss: 0.106 - mean_absolute_error: 7.404 - mean_q: 8.422 - mean_eps: 0.276 - ale.lives: 2.266\n",
      "\n",
      "Interval 260 (6475000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.08232s - reward: 0.082 - - ETA: \n",
      "25 episodes - episode_reward: 82.320 [36.000, 116.000] - loss: 0.101 - mean_absolute_error: 7.390 - mean_q: 8.409 - mean_eps: 0.274 - ale.lives: 2.195\n",
      "\n",
      "Interval 261 (6500000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0874\n",
      "24 episodes - episode_reward: 89.417 [63.000, 122.000] - loss: 0.102 - mean_absolute_error: 7.399 - mean_q: 8.419 - mean_eps: 0.273 - ale.lives: 2.184\n",
      "\n",
      "Interval 262 (6525000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0870\n",
      "24 episodes - episode_reward: 93.667 [58.000, 120.000] - loss: 0.100 - mean_absolute_error: 7.436 - mean_q: 8.461 - mean_eps: 0.272 - ale.lives: 2.195\n",
      "\n",
      "Interval 263 (6550000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0852\n",
      "26 episodes - episode_reward: 82.346 [53.000, 112.000] - loss: 0.099 - mean_absolute_error: 7.459 - mean_q: 8.488 - mean_eps: 0.270 - ale.lives: 2.175\n",
      "\n",
      "Interval 264 (6575000 steps performed)\n",
      "25000/25000 [==============================] - ETA: 0s - reward: 0.085 - 289s 12ms/step - reward: 0.0857\n",
      "23 episodes - episode_reward: 92.435 [61.000, 119.000] - loss: 0.100 - mean_absolute_error: 7.404 - mean_q: 8.425 - mean_eps: 0.269 - ale.lives: 2.298\n",
      "\n",
      "Interval 265 (6600000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.08610s - reward: 0.\n",
      "24 episodes - episode_reward: 88.167 [38.000, 117.000] - loss: 0.100 - mean_absolute_error: 7.358 - mean_q: 8.372 - mean_eps: 0.267 - ale.lives: 2.219\n",
      "\n",
      "Interval 266 (6625000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0847\n",
      "23 episodes - episode_reward: 90.957 [46.000, 119.000] - loss: 0.101 - mean_absolute_error: 7.361 - mean_q: 8.378 - mean_eps: 0.266 - ale.lives: 2.196\n",
      "\n",
      "Interval 267 (6650000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0882\n",
      "25 episodes - episode_reward: 89.200 [45.000, 120.000] - loss: 0.100 - mean_absolute_error: 7.396 - mean_q: 8.417 - mean_eps: 0.264 - ale.lives: 2.301\n",
      "\n",
      "Interval 268 (6675000 steps performed)\n",
      "25000/25000 [==============================] - 298s 12ms/step - reward: 0.0875\n",
      "26 episodes - episode_reward: 83.615 [23.000, 118.000] - loss: 0.099 - mean_absolute_error: 7.393 - mean_q: 8.412 - mean_eps: 0.263 - ale.lives: 2.241\n",
      "\n",
      "Interval 269 (6700000 steps performed)\n",
      "25000/25000 [==============================] - 303s 12ms/step - reward: 0.0789\n",
      "25 episodes - episode_reward: 81.920 [35.000, 117.000] - loss: 0.100 - mean_absolute_error: 7.377 - mean_q: 8.394 - mean_eps: 0.261 - ale.lives: 2.197\n",
      "\n",
      "Interval 270 (6725000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0865\n",
      "25 episodes - episode_reward: 85.760 [37.000, 120.000] - loss: 0.100 - mean_absolute_error: 7.353 - mean_q: 8.369 - mean_eps: 0.260 - ale.lives: 2.261\n",
      "\n",
      "Interval 271 (6750000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0900\n",
      "25 episodes - episode_reward: 88.960 [61.000, 117.000] - loss: 0.097 - mean_absolute_error: 7.327 - mean_q: 8.340 - mean_eps: 0.258 - ale.lives: 2.278\n",
      "\n",
      "Interval 272 (6775000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0841\n",
      "27 episodes - episode_reward: 76.741 [31.000, 121.000] - loss: 0.096 - mean_absolute_error: 7.319 - mean_q: 8.330 - mean_eps: 0.257 - ale.lives: 2.304\n",
      "\n",
      "Interval 273 (6800000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 285s 11ms/step - reward: 0.0840\n",
      "26 episodes - episode_reward: 80.500 [27.000, 114.000] - loss: 0.099 - mean_absolute_error: 7.269 - mean_q: 8.271 - mean_eps: 0.256 - ale.lives: 2.205\n",
      "\n",
      "Interval 274 (6825000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0889\n",
      "26 episodes - episode_reward: 86.308 [51.000, 117.000] - loss: 0.099 - mean_absolute_error: 7.247 - mean_q: 8.249 - mean_eps: 0.254 - ale.lives: 2.287\n",
      "\n",
      "Interval 275 (6850000 steps performed)\n",
      "25000/25000 [==============================] - 287s 11ms/step - reward: 0.0803\n",
      "22 episodes - episode_reward: 89.227 [52.000, 122.000] - loss: 0.098 - mean_absolute_error: 7.224 - mean_q: 8.222 - mean_eps: 0.253 - ale.lives: 2.187\n",
      "\n",
      "Interval 276 (6875000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0870\n",
      "25 episodes - episode_reward: 91.440 [50.000, 131.000] - loss: 0.100 - mean_absolute_error: 7.280 - mean_q: 8.285 - mean_eps: 0.251 - ale.lives: 2.203\n",
      "\n",
      "Interval 277 (6900000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.08760s - reward: 0.\n",
      "24 episodes - episode_reward: 88.167 [61.000, 113.000] - loss: 0.099 - mean_absolute_error: 7.287 - mean_q: 8.295 - mean_eps: 0.250 - ale.lives: 2.224\n",
      "\n",
      "Interval 278 (6925000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0871\n",
      "25 episodes - episode_reward: 89.280 [39.000, 129.000] - loss: 0.101 - mean_absolute_error: 7.318 - mean_q: 8.330 - mean_eps: 0.248 - ale.lives: 2.150\n",
      "\n",
      "Interval 279 (6950000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0861\n",
      "24 episodes - episode_reward: 89.208 [52.000, 120.000] - loss: 0.102 - mean_absolute_error: 7.341 - mean_q: 8.355 - mean_eps: 0.247 - ale.lives: 2.192\n",
      "\n",
      "Interval 280 (6975000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0841\n",
      "25 episodes - episode_reward: 82.760 [39.000, 116.000] - loss: 0.104 - mean_absolute_error: 7.328 - mean_q: 8.339 - mean_eps: 0.245 - ale.lives: 2.203\n",
      "\n",
      "Interval 281 (7000000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0805\n",
      "26 episodes - episode_reward: 79.000 [30.000, 108.000] - loss: 0.102 - mean_absolute_error: 7.293 - mean_q: 8.298 - mean_eps: 0.244 - ale.lives: 2.237\n",
      "\n",
      "Interval 282 (7025000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0850\n",
      "23 episodes - episode_reward: 92.304 [62.000, 123.000] - loss: 0.101 - mean_absolute_error: 7.335 - mean_q: 8.346 - mean_eps: 0.243 - ale.lives: 2.206\n",
      "\n",
      "Interval 283 (7050000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.08530s - r\n",
      "23 episodes - episode_reward: 90.130 [41.000, 122.000] - loss: 0.098 - mean_absolute_error: 7.275 - mean_q: 8.280 - mean_eps: 0.241 - ale.lives: 2.235\n",
      "\n",
      "Interval 284 (7075000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0842\n",
      "24 episodes - episode_reward: 88.000 [33.000, 115.000] - loss: 0.100 - mean_absolute_error: 7.339 - mean_q: 8.352 - mean_eps: 0.240 - ale.lives: 2.195\n",
      "\n",
      "Interval 285 (7100000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0865\n",
      "26 episodes - episode_reward: 82.923 [25.000, 110.000] - loss: 0.101 - mean_absolute_error: 7.372 - mean_q: 8.389 - mean_eps: 0.238 - ale.lives: 2.258\n",
      "\n",
      "Interval 286 (7125000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0886\n",
      "24 episodes - episode_reward: 91.792 [36.000, 129.000] - loss: 0.104 - mean_absolute_error: 7.451 - mean_q: 8.478 - mean_eps: 0.237 - ale.lives: 2.248\n",
      "\n",
      "Interval 287 (7150000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0879\n",
      "22 episodes - episode_reward: 101.409 [76.000, 125.000] - loss: 0.104 - mean_absolute_error: 7.410 - mean_q: 8.433 - mean_eps: 0.235 - ale.lives: 2.213\n",
      "\n",
      "Interval 288 (7175000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.08760s - reward: 0.08\n",
      "24 episodes - episode_reward: 91.417 [64.000, 122.000] - loss: 0.105 - mean_absolute_error: 7.431 - mean_q: 8.455 - mean_eps: 0.234 - ale.lives: 2.282\n",
      "\n",
      "Interval 289 (7200000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0869\n",
      "24 episodes - episode_reward: 88.292 [60.000, 116.000] - loss: 0.101 - mean_absolute_error: 7.447 - mean_q: 8.474 - mean_eps: 0.232 - ale.lives: 2.195\n",
      "\n",
      "Interval 290 (7225000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0869\n",
      "26 episodes - episode_reward: 83.423 [40.000, 128.000] - loss: 0.103 - mean_absolute_error: 7.410 - mean_q: 8.435 - mean_eps: 0.231 - ale.lives: 2.213\n",
      "\n",
      "Interval 291 (7250000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0885\n",
      "25 episodes - episode_reward: 90.920 [32.000, 129.000] - loss: 0.104 - mean_absolute_error: 7.401 - mean_q: 8.425 - mean_eps: 0.230 - ale.lives: 2.210\n",
      "\n",
      "Interval 292 (7275000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.08740s - r\n",
      "24 episodes - episode_reward: 89.000 [50.000, 125.000] - loss: 0.107 - mean_absolute_error: 7.353 - mean_q: 8.372 - mean_eps: 0.228 - ale.lives: 2.241\n",
      "\n",
      "Interval 293 (7300000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0829\n",
      "23 episodes - episode_reward: 90.652 [41.000, 119.000] - loss: 0.106 - mean_absolute_error: 7.339 - mean_q: 8.353 - mean_eps: 0.227 - ale.lives: 2.283\n",
      "\n",
      "Interval 294 (7325000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0832\n",
      "25 episodes - episode_reward: 86.880 [45.000, 113.000] - loss: 0.103 - mean_absolute_error: 7.364 - mean_q: 8.381 - mean_eps: 0.225 - ale.lives: 2.265\n",
      "\n",
      "Interval 295 (7350000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0914\n",
      "25 episodes - episode_reward: 88.400 [50.000, 120.000] - loss: 0.105 - mean_absolute_error: 7.429 - mean_q: 8.455 - mean_eps: 0.224 - ale.lives: 2.208\n",
      "\n",
      "Interval 296 (7375000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0878\n",
      "24 episodes - episode_reward: 89.667 [41.000, 127.000] - loss: 0.102 - mean_absolute_error: 7.405 - mean_q: 8.427 - mean_eps: 0.222 - ale.lives: 2.238\n",
      "\n",
      "Interval 297 (7400000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0905\n",
      "25 episodes - episode_reward: 92.880 [47.000, 128.000] - loss: 0.103 - mean_absolute_error: 7.413 - mean_q: 8.436 - mean_eps: 0.221 - ale.lives: 2.151\n",
      "\n",
      "Interval 298 (7425000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0861\n",
      "24 episodes - episode_reward: 91.208 [50.000, 113.000] - loss: 0.102 - mean_absolute_error: 7.451 - mean_q: 8.478 - mean_eps: 0.219 - ale.lives: 2.257\n",
      "\n",
      "Interval 299 (7450000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0857\n",
      "25 episodes - episode_reward: 85.000 [34.000, 114.000] - loss: 0.102 - mean_absolute_error: 7.397 - mean_q: 8.418 - mean_eps: 0.218 - ale.lives: 2.294\n",
      "\n",
      "Interval 300 (7475000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0860\n",
      "24 episodes - episode_reward: 91.167 [41.000, 121.000] - loss: 0.102 - mean_absolute_error: 7.440 - mean_q: 8.468 - mean_eps: 0.217 - ale.lives: 2.216\n",
      "\n",
      "Interval 301 (7500000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0914\n",
      "26 episodes - episode_reward: 86.731 [22.000, 127.000] - loss: 0.101 - mean_absolute_error: 7.454 - mean_q: 8.483 - mean_eps: 0.215 - ale.lives: 2.220\n",
      "\n",
      "Interval 302 (7525000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0892\n",
      "25 episodes - episode_reward: 86.200 [31.000, 120.000] - loss: 0.103 - mean_absolute_error: 7.463 - mean_q: 8.492 - mean_eps: 0.214 - ale.lives: 2.257\n",
      "\n",
      "Interval 303 (7550000 steps performed)\n",
      "25000/25000 [==============================] - 285s 11ms/step - reward: 0.0858\n",
      "24 episodes - episode_reward: 88.458 [50.000, 121.000] - loss: 0.107 - mean_absolute_error: 7.541 - mean_q: 8.582 - mean_eps: 0.212 - ale.lives: 2.244\n",
      "\n",
      "Interval 304 (7575000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0886\n",
      "24 episodes - episode_reward: 94.667 [53.000, 127.000] - loss: 0.105 - mean_absolute_error: 7.522 - mean_q: 8.559 - mean_eps: 0.211 - ale.lives: 2.263\n",
      "\n",
      "Interval 305 (7600000 steps performed)\n",
      "25000/25000 [==============================] - 286s 11ms/step - reward: 0.0873\n",
      "25 episodes - episode_reward: 88.520 [46.000, 116.000] - loss: 0.105 - mean_absolute_error: 7.580 - mean_q: 8.626 - mean_eps: 0.209 - ale.lives: 2.226\n",
      "\n",
      "Interval 306 (7625000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0900\n",
      "24 episodes - episode_reward: 95.458 [57.000, 122.000] - loss: 0.104 - mean_absolute_error: 7.507 - mean_q: 8.544 - mean_eps: 0.208 - ale.lives: 2.247\n",
      "\n",
      "Interval 307 (7650000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0870\n",
      "25 episodes - episode_reward: 86.280 [43.000, 133.000] - loss: 0.105 - mean_absolute_error: 7.509 - mean_q: 8.547 - mean_eps: 0.206 - ale.lives: 2.164\n",
      "\n",
      "Interval 308 (7675000 steps performed)\n",
      "25000/25000 [==============================] - 304s 12ms/step - reward: 0.0874\n",
      "26 episodes - episode_reward: 82.231 [41.000, 114.000] - loss: 0.102 - mean_absolute_error: 7.471 - mean_q: 8.503 - mean_eps: 0.205 - ale.lives: 2.267\n",
      "\n",
      "Interval 309 (7700000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0910\n",
      "23 episodes - episode_reward: 97.130 [71.000, 126.000] - loss: 0.107 - mean_absolute_error: 7.529 - mean_q: 8.567 - mean_eps: 0.203 - ale.lives: 2.283\n",
      "\n",
      "Interval 310 (7725000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0922\n",
      "24 episodes - episode_reward: 96.333 [79.000, 116.000] - loss: 0.108 - mean_absolute_error: 7.532 - mean_q: 8.567 - mean_eps: 0.202 - ale.lives: 2.230\n",
      "\n",
      "Interval 311 (7750000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0877\n",
      "26 episodes - episode_reward: 85.731 [36.000, 119.000] - loss: 0.105 - mean_absolute_error: 7.522 - mean_q: 8.557 - mean_eps: 0.201 - ale.lives: 2.266\n",
      "\n",
      "Interval 312 (7775000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0888\n",
      "24 episodes - episode_reward: 92.042 [22.000, 123.000] - loss: 0.106 - mean_absolute_error: 7.604 - mean_q: 8.649 - mean_eps: 0.199 - ale.lives: 2.231\n",
      "\n",
      "Interval 313 (7800000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0857\n",
      "24 episodes - episode_reward: 90.542 [39.000, 127.000] - loss: 0.102 - mean_absolute_error: 7.613 - mean_q: 8.663 - mean_eps: 0.198 - ale.lives: 2.226\n",
      "\n",
      "Interval 314 (7825000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.08930s - rew\n",
      "25 episodes - episode_reward: 91.080 [30.000, 126.000] - loss: 0.100 - mean_absolute_error: 7.550 - mean_q: 8.589 - mean_eps: 0.196 - ale.lives: 2.235\n",
      "\n",
      "Interval 315 (7850000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0912\n",
      "24 episodes - episode_reward: 93.083 [62.000, 115.000] - loss: 0.101 - mean_absolute_error: 7.574 - mean_q: 8.616 - mean_eps: 0.195 - ale.lives: 2.270\n",
      "\n",
      "Interval 316 (7875000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0906\n",
      "25 episodes - episode_reward: 90.560 [39.000, 137.000] - loss: 0.101 - mean_absolute_error: 7.542 - mean_q: 8.580 - mean_eps: 0.193 - ale.lives: 2.271\n",
      "\n",
      "Interval 317 (7900000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0876\n",
      "25 episodes - episode_reward: 88.360 [19.000, 120.000] - loss: 0.099 - mean_absolute_error: 7.542 - mean_q: 8.581 - mean_eps: 0.192 - ale.lives: 2.240\n",
      "\n",
      "Interval 318 (7925000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0912\n",
      "25 episodes - episode_reward: 88.480 [34.000, 118.000] - loss: 0.103 - mean_absolute_error: 7.471 - mean_q: 8.503 - mean_eps: 0.190 - ale.lives: 2.276\n",
      "\n",
      "Interval 319 (7950000 steps performed)\n",
      "25000/25000 [==============================] - 308s 12ms/step - reward: 0.0926\n",
      "25 episodes - episode_reward: 93.640 [34.000, 131.000] - loss: 0.103 - mean_absolute_error: 7.494 - mean_q: 8.529 - mean_eps: 0.189 - ale.lives: 2.255\n",
      "\n",
      "Interval 320 (7975000 steps performed)\n",
      "25000/25000 [==============================] - 307s 12ms/step - reward: 0.0902\n",
      "24 episodes - episode_reward: 95.417 [49.000, 138.000] - loss: 0.099 - mean_absolute_error: 7.489 - mean_q: 8.522 - mean_eps: 0.188 - ale.lives: 2.236\n",
      "\n",
      "Interval 321 (8000000 steps performed)\n",
      "25000/25000 [==============================] - 306s 12ms/step - reward: 0.0908\n",
      "23 episodes - episode_reward: 97.783 [57.000, 127.000] - loss: 0.100 - mean_absolute_error: 7.473 - mean_q: 8.506 - mean_eps: 0.186 - ale.lives: 2.196\n",
      "\n",
      "Interval 322 (8025000 steps performed)\n",
      "25000/25000 [==============================] - 308s 12ms/step - reward: 0.0917\n",
      "24 episodes - episode_reward: 94.833 [62.000, 128.000] - loss: 0.100 - mean_absolute_error: 7.472 - mean_q: 8.504 - mean_eps: 0.185 - ale.lives: 2.290\n",
      "\n",
      "Interval 323 (8050000 steps performed)\n",
      "25000/25000 [==============================] - 306s 12ms/step - reward: 0.0941\n",
      "23 episodes - episode_reward: 102.304 [51.000, 136.000] - loss: 0.100 - mean_absolute_error: 7.544 - mean_q: 8.587 - mean_eps: 0.183 - ale.lives: 2.195\n",
      "\n",
      "Interval 324 (8075000 steps performed)\n",
      "25000/25000 [==============================] - ETA: 0s - reward: 0.095 - 301s 12ms/step - reward: 0.0958\n",
      "26 episodes - episode_reward: 90.769 [53.000, 121.000] - loss: 0.102 - mean_absolute_error: 7.560 - mean_q: 8.604 - mean_eps: 0.182 - ale.lives: 2.314\n",
      "\n",
      "Interval 325 (8100000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0918\n",
      "23 episodes - episode_reward: 101.783 [37.000, 129.000] - loss: 0.104 - mean_absolute_error: 7.586 - mean_q: 8.634 - mean_eps: 0.180 - ale.lives: 2.142\n",
      "\n",
      "Interval 326 (8125000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0998\n",
      "25 episodes - episode_reward: 98.800 [73.000, 122.000] - loss: 0.102 - mean_absolute_error: 7.586 - mean_q: 8.635 - mean_eps: 0.179 - ale.lives: 2.217\n",
      "\n",
      "Interval 327 (8150000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.09340s - reward: 0.0\n",
      "25 episodes - episode_reward: 96.800 [43.000, 135.000] - loss: 0.101 - mean_absolute_error: 7.514 - mean_q: 8.555 - mean_eps: 0.177 - ale.lives: 2.253\n",
      "\n",
      "Interval 328 (8175000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0902\n",
      "24 episodes - episode_reward: 90.833 [36.000, 123.000] - loss: 0.103 - mean_absolute_error: 7.531 - mean_q: 8.573 - mean_eps: 0.176 - ale.lives: 2.218\n",
      "\n",
      "Interval 329 (8200000 steps performed)\n",
      "25000/25000 [==============================] - 315s 13ms/step - reward: 0.0917\n",
      "25 episodes - episode_reward: 92.040 [47.000, 122.000] - loss: 0.103 - mean_absolute_error: 7.524 - mean_q: 8.567 - mean_eps: 0.175 - ale.lives: 2.223\n",
      "\n",
      "Interval 330 (8225000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0896\n",
      "25 episodes - episode_reward: 90.600 [38.000, 136.000] - loss: 0.102 - mean_absolute_error: 7.499 - mean_q: 8.540 - mean_eps: 0.173 - ale.lives: 2.206\n",
      "\n",
      "Interval 331 (8250000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0892\n",
      "25 episodes - episode_reward: 90.080 [31.000, 136.000] - loss: 0.105 - mean_absolute_error: 7.499 - mean_q: 8.540 - mean_eps: 0.172 - ale.lives: 2.156\n",
      "\n",
      "Interval 332 (8275000 steps performed)\n",
      "25000/25000 [==============================] - 284s 11ms/step - reward: 0.09370s - reward: 0.093\n",
      "24 episodes - episode_reward: 96.458 [56.000, 123.000] - loss: 0.106 - mean_absolute_error: 7.525 - mean_q: 8.570 - mean_eps: 0.170 - ale.lives: 2.276\n",
      "\n",
      "Interval 333 (8300000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 284s 11ms/step - reward: 0.0904\n",
      "22 episodes - episode_reward: 100.500 [55.000, 129.000] - loss: 0.106 - mean_absolute_error: 7.479 - mean_q: 8.518 - mean_eps: 0.169 - ale.lives: 2.166\n",
      "\n",
      "Interval 334 (8325000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.0946\n",
      "24 episodes - episode_reward: 99.500 [51.000, 128.000] - loss: 0.107 - mean_absolute_error: 7.485 - mean_q: 8.524 - mean_eps: 0.167 - ale.lives: 2.209\n",
      "\n",
      "Interval 335 (8350000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0947\n",
      "23 episodes - episode_reward: 100.957 [58.000, 134.000] - loss: 0.109 - mean_absolute_error: 7.495 - mean_q: 8.537 - mean_eps: 0.166 - ale.lives: 2.285\n",
      "\n",
      "Interval 336 (8375000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0936\n",
      "24 episodes - episode_reward: 99.625 [56.000, 134.000] - loss: 0.102 - mean_absolute_error: 7.473 - mean_q: 8.512 - mean_eps: 0.164 - ale.lives: 2.291\n",
      "\n",
      "Interval 337 (8400000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0956\n",
      "24 episodes - episode_reward: 99.208 [33.000, 131.000] - loss: 0.104 - mean_absolute_error: 7.515 - mean_q: 8.559 - mean_eps: 0.163 - ale.lives: 2.288\n",
      "\n",
      "Interval 338 (8425000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0928- ETA: 0s - re\n",
      "25 episodes - episode_reward: 92.920 [31.000, 139.000] - loss: 0.103 - mean_absolute_error: 7.517 - mean_q: 8.561 - mean_eps: 0.162 - ale.lives: 2.232\n",
      "\n",
      "Interval 339 (8450000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0855\n",
      "24 episodes - episode_reward: 92.208 [46.000, 140.000] - loss: 0.108 - mean_absolute_error: 7.537 - mean_q: 8.582 - mean_eps: 0.160 - ale.lives: 2.109\n",
      "\n",
      "Interval 340 (8475000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0916\n",
      "24 episodes - episode_reward: 94.583 [60.000, 128.000] - loss: 0.107 - mean_absolute_error: 7.484 - mean_q: 8.522 - mean_eps: 0.159 - ale.lives: 2.255\n",
      "\n",
      "Interval 341 (8500000 steps performed)\n",
      "25000/25000 [==============================] - 301s 12ms/step - reward: 0.0913\n",
      "23 episodes - episode_reward: 97.000 [44.000, 128.000] - loss: 0.106 - mean_absolute_error: 7.511 - mean_q: 8.550 - mean_eps: 0.157 - ale.lives: 2.249\n",
      "\n",
      "Interval 342 (8525000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0931\n",
      "26 episodes - episode_reward: 89.192 [45.000, 138.000] - loss: 0.106 - mean_absolute_error: 7.484 - mean_q: 8.520 - mean_eps: 0.156 - ale.lives: 2.198\n",
      "\n",
      "Interval 343 (8550000 steps performed)\n",
      "25000/25000 [==============================] - 304s 12ms/step - reward: 0.0974\n",
      "24 episodes - episode_reward: 100.375 [65.000, 128.000] - loss: 0.106 - mean_absolute_error: 7.499 - mean_q: 8.538 - mean_eps: 0.154 - ale.lives: 2.283\n",
      "\n",
      "Interval 344 (8575000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0938\n",
      "26 episodes - episode_reward: 94.308 [37.000, 129.000] - loss: 0.107 - mean_absolute_error: 7.509 - mean_q: 8.548 - mean_eps: 0.153 - ale.lives: 2.220\n",
      "\n",
      "Interval 345 (8600000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0978\n",
      "24 episodes - episode_reward: 101.125 [42.000, 131.000] - loss: 0.105 - mean_absolute_error: 7.527 - mean_q: 8.571 - mean_eps: 0.151 - ale.lives: 2.258\n",
      "\n",
      "Interval 346 (8625000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0939\n",
      "23 episodes - episode_reward: 99.087 [36.000, 137.000] - loss: 0.102 - mean_absolute_error: 7.506 - mean_q: 8.548 - mean_eps: 0.150 - ale.lives: 2.280\n",
      "\n",
      "Interval 347 (8650000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0938\n",
      "23 episodes - episode_reward: 103.391 [72.000, 140.000] - loss: 0.106 - mean_absolute_error: 7.480 - mean_q: 8.517 - mean_eps: 0.148 - ale.lives: 2.288\n",
      "\n",
      "Interval 348 (8675000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.0925\n",
      "25 episodes - episode_reward: 91.160 [51.000, 124.000] - loss: 0.109 - mean_absolute_error: 7.539 - mean_q: 8.583 - mean_eps: 0.147 - ale.lives: 2.206\n",
      "\n",
      "Interval 349 (8700000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0981\n",
      "23 episodes - episode_reward: 106.261 [42.000, 141.000] - loss: 0.106 - mean_absolute_error: 7.481 - mean_q: 8.519 - mean_eps: 0.146 - ale.lives: 2.245\n",
      "\n",
      "Interval 350 (8725000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0925\n",
      "25 episodes - episode_reward: 95.800 [50.000, 131.000] - loss: 0.103 - mean_absolute_error: 7.496 - mean_q: 8.537 - mean_eps: 0.144 - ale.lives: 2.242\n",
      "\n",
      "Interval 351 (8750000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0976\n",
      "26 episodes - episode_reward: 92.385 [35.000, 134.000] - loss: 0.104 - mean_absolute_error: 7.521 - mean_q: 8.562 - mean_eps: 0.143 - ale.lives: 2.193\n",
      "\n",
      "Interval 352 (8775000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0937\n",
      "23 episodes - episode_reward: 99.435 [63.000, 133.000] - loss: 0.099 - mean_absolute_error: 7.557 - mean_q: 8.605 - mean_eps: 0.141 - ale.lives: 2.349\n",
      "\n",
      "Interval 353 (8800000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.0954\n",
      "23 episodes - episode_reward: 105.217 [52.000, 132.000] - loss: 0.107 - mean_absolute_error: 7.571 - mean_q: 8.619 - mean_eps: 0.140 - ale.lives: 2.287\n",
      "\n",
      "Interval 354 (8825000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0891\n",
      "23 episodes - episode_reward: 99.522 [40.000, 138.000] - loss: 0.100 - mean_absolute_error: 7.544 - mean_q: 8.593 - mean_eps: 0.138 - ale.lives: 2.240\n",
      "\n",
      "Interval 355 (8850000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0988\n",
      "25 episodes - episode_reward: 97.080 [52.000, 130.000] - loss: 0.104 - mean_absolute_error: 7.546 - mean_q: 8.592 - mean_eps: 0.137 - ale.lives: 2.287\n",
      "\n",
      "Interval 356 (8875000 steps performed)\n",
      "25000/25000 [==============================] - 297s 12ms/step - reward: 0.0927\n",
      "23 episodes - episode_reward: 97.522 [41.000, 135.000] - loss: 0.104 - mean_absolute_error: 7.563 - mean_q: 8.611 - mean_eps: 0.135 - ale.lives: 2.317\n",
      "\n",
      "Interval 357 (8900000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0962\n",
      "24 episodes - episode_reward: 101.292 [44.000, 141.000] - loss: 0.104 - mean_absolute_error: 7.576 - mean_q: 8.628 - mean_eps: 0.134 - ale.lives: 2.170\n",
      "\n",
      "Interval 358 (8925000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0920\n",
      "24 episodes - episode_reward: 95.750 [34.000, 136.000] - loss: 0.105 - mean_absolute_error: 7.607 - mean_q: 8.659 - mean_eps: 0.133 - ale.lives: 2.216\n",
      "\n",
      "Interval 359 (8950000 steps performed)\n",
      "25000/25000 [==============================] - 300s 12ms/step - reward: 0.0955\n",
      "24 episodes - episode_reward: 100.667 [46.000, 125.000] - loss: 0.103 - mean_absolute_error: 7.583 - mean_q: 8.633 - mean_eps: 0.131 - ale.lives: 2.267\n",
      "\n",
      "Interval 360 (8975000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0933\n",
      "24 episodes - episode_reward: 97.667 [42.000, 128.000] - loss: 0.103 - mean_absolute_error: 7.648 - mean_q: 8.710 - mean_eps: 0.130 - ale.lives: 2.214\n",
      "\n",
      "Interval 361 (9000000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.1001\n",
      "26 episodes - episode_reward: 98.077 [47.000, 125.000] - loss: 0.109 - mean_absolute_error: 7.677 - mean_q: 8.740 - mean_eps: 0.128 - ale.lives: 2.318\n",
      "\n",
      "Interval 362 (9025000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0968\n",
      "22 episodes - episode_reward: 108.091 [58.000, 133.000] - loss: 0.108 - mean_absolute_error: 7.697 - mean_q: 8.759 - mean_eps: 0.127 - ale.lives: 2.290\n",
      "\n",
      "Interval 363 (9050000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0991\n",
      "23 episodes - episode_reward: 109.043 [68.000, 128.000] - loss: 0.101 - mean_absolute_error: 7.644 - mean_q: 8.702 - mean_eps: 0.125 - ale.lives: 2.249\n",
      "\n",
      "Interval 364 (9075000 steps performed)\n",
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0975\n",
      "22 episodes - episode_reward: 111.136 [79.000, 132.000] - loss: 0.103 - mean_absolute_error: 7.658 - mean_q: 8.719 - mean_eps: 0.124 - ale.lives: 2.204\n",
      "\n",
      "Interval 365 (9100000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0992\n",
      "24 episodes - episode_reward: 104.000 [46.000, 132.000] - loss: 0.100 - mean_absolute_error: 7.687 - mean_q: 8.750 - mean_eps: 0.122 - ale.lives: 2.339\n",
      "\n",
      "Interval 366 (9125000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0944\n",
      "22 episodes - episode_reward: 107.227 [78.000, 132.000] - loss: 0.101 - mean_absolute_error: 7.752 - mean_q: 8.826 - mean_eps: 0.121 - ale.lives: 2.264\n",
      "\n",
      "Interval 367 (9150000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.1018\n",
      "25 episodes - episode_reward: 98.480 [71.000, 129.000] - loss: 0.101 - mean_absolute_error: 7.765 - mean_q: 8.841 - mean_eps: 0.120 - ale.lives: 2.380\n",
      "\n",
      "Interval 368 (9175000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0995\n",
      "27 episodes - episode_reward: 94.852 [57.000, 123.000] - loss: 0.103 - mean_absolute_error: 7.772 - mean_q: 8.851 - mean_eps: 0.118 - ale.lives: 2.284\n",
      "\n",
      "Interval 369 (9200000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.1001\n",
      "23 episodes - episode_reward: 104.783 [69.000, 129.000] - loss: 0.102 - mean_absolute_error: 7.761 - mean_q: 8.839 - mean_eps: 0.117 - ale.lives: 2.325\n",
      "\n",
      "Interval 370 (9225000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.1007\n",
      "24 episodes - episode_reward: 106.417 [73.000, 136.000] - loss: 0.101 - mean_absolute_error: 7.785 - mean_q: 8.864 - mean_eps: 0.115 - ale.lives: 2.295\n",
      "\n",
      "Interval 371 (9250000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0990\n",
      "24 episodes - episode_reward: 105.875 [65.000, 130.000] - loss: 0.104 - mean_absolute_error: 7.807 - mean_q: 8.892 - mean_eps: 0.114 - ale.lives: 2.321\n",
      "\n",
      "Interval 372 (9275000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0997\n",
      "23 episodes - episode_reward: 102.696 [36.000, 129.000] - loss: 0.101 - mean_absolute_error: 7.872 - mean_q: 8.964 - mean_eps: 0.112 - ale.lives: 2.220\n",
      "\n",
      "Interval 373 (9300000 steps performed)\n",
      "25000/25000 [==============================] - 302s 12ms/step - reward: 0.0951\n",
      "25 episodes - episode_reward: 96.520 [60.000, 140.000] - loss: 0.100 - mean_absolute_error: 7.860 - mean_q: 8.947 - mean_eps: 0.111 - ale.lives: 2.229\n",
      "\n",
      "Interval 374 (9325000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.1010\n",
      "24 episodes - episode_reward: 105.792 [48.000, 138.000] - loss: 0.099 - mean_absolute_error: 7.933 - mean_q: 9.030 - mean_eps: 0.109 - ale.lives: 2.312\n",
      "\n",
      "Interval 375 (9350000 steps performed)\n",
      "25000/25000 [==============================] - 292s 12ms/step - reward: 0.0927\n",
      "23 episodes - episode_reward: 99.478 [49.000, 149.000] - loss: 0.103 - mean_absolute_error: 7.947 - mean_q: 9.045 - mean_eps: 0.108 - ale.lives: 2.220\n",
      "\n",
      "Interval 376 (9375000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.1002\n",
      "25 episodes - episode_reward: 103.840 [69.000, 137.000] - loss: 0.103 - mean_absolute_error: 7.937 - mean_q: 9.034 - mean_eps: 0.107 - ale.lives: 2.278\n",
      "\n",
      "Interval 377 (9400000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.1024\n",
      "23 episodes - episode_reward: 109.304 [70.000, 132.000] - loss: 0.105 - mean_absolute_error: 7.968 - mean_q: 9.069 - mean_eps: 0.105 - ale.lives: 2.196\n",
      "\n",
      "Interval 378 (9425000 steps performed)\n",
      "25000/25000 [==============================] - 293s 12ms/step - reward: 0.1005\n",
      "25 episodes - episode_reward: 102.680 [36.000, 138.000] - loss: 0.104 - mean_absolute_error: 8.015 - mean_q: 9.124 - mean_eps: 0.104 - ale.lives: 2.299\n",
      "\n",
      "Interval 379 (9450000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.09690s - reward: 0\n",
      "23 episodes - episode_reward: 103.043 [76.000, 127.000] - loss: 0.107 - mean_absolute_error: 8.069 - mean_q: 9.184 - mean_eps: 0.102 - ale.lives: 2.321\n",
      "\n",
      "Interval 380 (9475000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0994\n",
      "24 episodes - episode_reward: 100.625 [37.000, 135.000] - loss: 0.106 - mean_absolute_error: 8.078 - mean_q: 9.194 - mean_eps: 0.101 - ale.lives: 2.325\n",
      "\n",
      "Interval 381 (9500000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0996\n",
      "23 episodes - episode_reward: 109.261 [67.000, 148.000] - loss: 0.107 - mean_absolute_error: 8.050 - mean_q: 9.164 - mean_eps: 0.100 - ale.lives: 2.340\n",
      "\n",
      "Interval 382 (9525000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0982\n",
      "26 episodes - episode_reward: 94.846 [58.000, 118.000] - loss: 0.105 - mean_absolute_error: 8.077 - mean_q: 9.192 - mean_eps: 0.100 - ale.lives: 2.204\n",
      "\n",
      "Interval 383 (9550000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0971\n",
      "25 episodes - episode_reward: 99.960 [55.000, 126.000] - loss: 0.104 - mean_absolute_error: 8.036 - mean_q: 9.146 - mean_eps: 0.100 - ale.lives: 2.201\n",
      "\n",
      "Interval 384 (9575000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0956\n",
      "23 episodes - episode_reward: 104.696 [55.000, 127.000] - loss: 0.103 - mean_absolute_error: 8.077 - mean_q: 9.194 - mean_eps: 0.100 - ale.lives: 2.259\n",
      "\n",
      "Interval 385 (9600000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0992\n",
      "24 episodes - episode_reward: 100.667 [57.000, 121.000] - loss: 0.104 - mean_absolute_error: 8.072 - mean_q: 9.189 - mean_eps: 0.100 - ale.lives: 2.203\n",
      "\n",
      "Interval 386 (9625000 steps performed)\n",
      "25000/25000 [==============================] - 294s 12ms/step - reward: 0.0974\n",
      "24 episodes - episode_reward: 101.333 [50.000, 136.000] - loss: 0.103 - mean_absolute_error: 8.008 - mean_q: 9.116 - mean_eps: 0.100 - ale.lives: 2.309\n",
      "\n",
      "Interval 387 (9650000 steps performed)\n",
      "25000/25000 [==============================] - 296s 12ms/step - reward: 0.09960s - reward: 0.\n",
      "24 episodes - episode_reward: 102.417 [63.000, 135.000] - loss: 0.106 - mean_absolute_error: 8.030 - mean_q: 9.143 - mean_eps: 0.100 - ale.lives: 2.234\n",
      "\n",
      "Interval 388 (9675000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0952\n",
      "25 episodes - episode_reward: 99.200 [52.000, 128.000] - loss: 0.106 - mean_absolute_error: 8.077 - mean_q: 9.196 - mean_eps: 0.100 - ale.lives: 2.243\n",
      "\n",
      "Interval 389 (9700000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0901\n",
      "24 episodes - episode_reward: 90.625 [59.000, 136.000] - loss: 0.108 - mean_absolute_error: 8.051 - mean_q: 9.164 - mean_eps: 0.100 - ale.lives: 2.220\n",
      "\n",
      "Interval 390 (9725000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.0936\n",
      "24 episodes - episode_reward: 101.333 [30.000, 142.000] - loss: 0.109 - mean_absolute_error: 8.070 - mean_q: 9.185 - mean_eps: 0.100 - ale.lives: 2.264\n",
      "\n",
      "Interval 391 (9750000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.1028\n",
      "25 episodes - episode_reward: 100.320 [38.000, 129.000] - loss: 0.107 - mean_absolute_error: 8.065 - mean_q: 9.180 - mean_eps: 0.100 - ale.lives: 2.284\n",
      "\n",
      "Interval 392 (9775000 steps performed)\n",
      "25000/25000 [==============================] - 295s 12ms/step - reward: 0.09530s - reward: 0\n",
      "23 episodes - episode_reward: 102.130 [56.000, 135.000] - loss: 0.105 - mean_absolute_error: 8.075 - mean_q: 9.193 - mean_eps: 0.100 - ale.lives: 2.209\n",
      "\n",
      "Interval 393 (9800000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 288s 12ms/step - reward: 0.0999\n",
      "24 episodes - episode_reward: 104.375 [71.000, 144.000] - loss: 0.108 - mean_absolute_error: 8.095 - mean_q: 9.216 - mean_eps: 0.100 - ale.lives: 2.267\n",
      "\n",
      "Interval 394 (9825000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0941\n",
      "26 episodes - episode_reward: 93.846 [45.000, 128.000] - loss: 0.108 - mean_absolute_error: 8.051 - mean_q: 9.163 - mean_eps: 0.100 - ale.lives: 2.210\n",
      "\n",
      "Interval 395 (9850000 steps performed)\n",
      "25000/25000 [==============================] - 291s 12ms/step - reward: 0.09700s - reward: 0\n",
      "25 episodes - episode_reward: 94.640 [41.000, 132.000] - loss: 0.104 - mean_absolute_error: 8.066 - mean_q: 9.180 - mean_eps: 0.100 - ale.lives: 2.210\n",
      "\n",
      "Interval 396 (9875000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.09861s - reward: 0.\n",
      "24 episodes - episode_reward: 100.792 [64.000, 127.000] - loss: 0.101 - mean_absolute_error: 8.055 - mean_q: 9.169 - mean_eps: 0.100 - ale.lives: 2.248\n",
      "\n",
      "Interval 397 (9900000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0950\n",
      "26 episodes - episode_reward: 95.346 [66.000, 120.000] - loss: 0.101 - mean_absolute_error: 8.081 - mean_q: 9.195 - mean_eps: 0.100 - ale.lives: 2.213\n",
      "\n",
      "Interval 398 (9925000 steps performed)\n",
      "25000/25000 [==============================] - 290s 12ms/step - reward: 0.0989\n",
      "24 episodes - episode_reward: 99.500 [62.000, 137.000] - loss: 0.103 - mean_absolute_error: 8.077 - mean_q: 9.193 - mean_eps: 0.100 - ale.lives: 2.282\n",
      "\n",
      "Interval 399 (9950000 steps performed)\n",
      "25000/25000 [==============================] - 289s 12ms/step - reward: 0.0952\n",
      "23 episodes - episode_reward: 107.217 [71.000, 137.000] - loss: 0.098 - mean_absolute_error: 8.040 - mean_q: 9.151 - mean_eps: 0.100 - ale.lives: 2.327\n",
      "\n",
      "Interval 400 (9975000 steps performed)\n",
      "25000/25000 [==============================] - 299s 12ms/step - reward: 0.0955\n",
      "done, took 116728.570 seconds\n",
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 115.000, steps: 1088\n",
      "Episode 2: reward: 82.000, steps: 1005\n",
      "Episode 3: reward: 100.000, steps: 1212\n",
      "Episode 4: reward: 84.000, steps: 826\n",
      "Episode 5: reward: 99.000, steps: 991\n",
      "Episode 6: reward: 86.000, steps: 1141\n",
      "Episode 7: reward: 114.000, steps: 1226\n",
      "Episode 8: reward: 97.000, steps: 871\n",
      "Episode 9: reward: 90.000, steps: 852\n",
      "Episode 10: reward: 105.000, steps: 1109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2fa4cf648>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "\n",
    "weights_filename = 'dqn_{}_weights.h5f'.format(ENV_NAME)\n",
    "\n",
    "checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=500000)]\n",
    "callbacks += [FileLogger(log_filename, interval=100)]\n",
    " \n",
    "\n",
    "history = dqn.fit(env, callbacks=callbacks, nb_steps=num_steps, log_interval=batch, visualize=False)\n",
    "\n",
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights(weights_filename, overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 10 episodes.\n",
    "dqn.test(env, nb_episodes=10, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['episode_reward'])\n",
    "plt.title('DQN Performance')\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: 1420.000, steps: 1091\n",
      "Episode 2: reward: 1000.000, steps: 976\n",
      "Episode 3: reward: 1140.000, steps: 1116\n",
      "Episode 4: reward: 980.000, steps: 954\n",
      "Episode 5: reward: 1010.000, steps: 885\n",
      "Episode 6: reward: 1020.000, steps: 1101\n",
      "Episode 7: reward: 1420.000, steps: 1093\n",
      "Episode 8: reward: 1910.000, steps: 1538\n",
      "Episode 9: reward: 1150.000, steps: 969\n",
      "Episode 10: reward: 1150.000, steps: 916\n",
      "Episode 11: reward: 1080.000, steps: 1334\n",
      "Episode 12: reward: 1060.000, steps: 789\n",
      "Episode 13: reward: 1880.000, steps: 1119\n",
      "Episode 14: reward: 1210.000, steps: 1426\n",
      "Episode 15: reward: 2140.000, steps: 1131\n",
      "Episode 16: reward: 2150.000, steps: 1404\n",
      "Episode 17: reward: 1530.000, steps: 1996\n",
      "Episode 18: reward: 1190.000, steps: 890\n",
      "Episode 19: reward: 820.000, steps: 869\n",
      "Episode 20: reward: 1240.000, steps: 846\n",
      "Episode 21: reward: 1950.000, steps: 1136\n",
      "Episode 22: reward: 2040.000, steps: 1479\n",
      "Episode 23: reward: 1600.000, steps: 867\n",
      "Episode 24: reward: 930.000, steps: 880\n",
      "Episode 25: reward: 1300.000, steps: 947\n",
      "Episode 26: reward: 1370.000, steps: 1246\n",
      "Episode 27: reward: 890.000, steps: 942\n",
      "Episode 28: reward: 1000.000, steps: 1043\n",
      "Episode 29: reward: 1370.000, steps: 1078\n",
      "Episode 30: reward: 1230.000, steps: 954\n",
      "Episode 31: reward: 2470.000, steps: 1321\n",
      "Episode 32: reward: 1770.000, steps: 1285\n",
      "Episode 33: reward: 1080.000, steps: 1199\n",
      "Episode 34: reward: 1320.000, steps: 1213\n",
      "Episode 35: reward: 1400.000, steps: 1296\n",
      "Episode 36: reward: 1540.000, steps: 1071\n",
      "Episode 37: reward: 1210.000, steps: 898\n",
      "Episode 38: reward: 810.000, steps: 733\n",
      "Episode 39: reward: 3300.000, steps: 1287\n",
      "Episode 40: reward: 1260.000, steps: 995\n",
      "Episode 41: reward: 1410.000, steps: 943\n",
      "Episode 42: reward: 1260.000, steps: 1216\n",
      "Episode 43: reward: 2820.000, steps: 1400\n",
      "Episode 44: reward: 1290.000, steps: 951\n",
      "Episode 45: reward: 1700.000, steps: 929\n",
      "Episode 46: reward: 2120.000, steps: 1568\n",
      "Episode 47: reward: 890.000, steps: 939\n",
      "Episode 48: reward: 2130.000, steps: 1192\n",
      "Episode 49: reward: 1600.000, steps: 1002\n",
      "Episode 50: reward: 1380.000, steps: 1445\n",
      "Episode 51: reward: 1150.000, steps: 1328\n",
      "Episode 52: reward: 1460.000, steps: 1075\n",
      "Episode 53: reward: 880.000, steps: 1071\n",
      "Episode 54: reward: 2020.000, steps: 1586\n",
      "Episode 55: reward: 1010.000, steps: 1038\n",
      "Episode 56: reward: 1650.000, steps: 1342\n",
      "Episode 57: reward: 1150.000, steps: 1306\n",
      "Episode 58: reward: 1500.000, steps: 1041\n",
      "Episode 59: reward: 2010.000, steps: 1270\n",
      "Episode 60: reward: 1300.000, steps: 1301\n",
      "Episode 61: reward: 1430.000, steps: 1120\n",
      "Episode 62: reward: 1100.000, steps: 819\n",
      "Episode 63: reward: 1190.000, steps: 847\n",
      "Episode 64: reward: 2460.000, steps: 995\n",
      "Episode 65: reward: 1350.000, steps: 1043\n",
      "Episode 66: reward: 1430.000, steps: 1126\n",
      "Episode 67: reward: 1130.000, steps: 1115\n",
      "Episode 68: reward: 2280.000, steps: 1394\n",
      "Episode 69: reward: 1860.000, steps: 943\n",
      "Episode 70: reward: 1330.000, steps: 1031\n",
      "Episode 71: reward: 1080.000, steps: 896\n",
      "Episode 72: reward: 2100.000, steps: 1088\n",
      "Episode 73: reward: 1130.000, steps: 1157\n",
      "Episode 74: reward: 1020.000, steps: 922\n",
      "Episode 75: reward: 1930.000, steps: 1229\n",
      "Episode 76: reward: 1670.000, steps: 1023\n",
      "Episode 77: reward: 1380.000, steps: 1256\n",
      "Episode 78: reward: 1830.000, steps: 1367\n",
      "Episode 79: reward: 1750.000, steps: 1237\n",
      "Episode 80: reward: 1910.000, steps: 1191\n",
      "Episode 81: reward: 970.000, steps: 929\n",
      "Episode 82: reward: 1790.000, steps: 1190\n",
      "Episode 83: reward: 1260.000, steps: 1672\n",
      "Episode 84: reward: 830.000, steps: 948\n",
      "Episode 85: reward: 1800.000, steps: 1143\n",
      "Episode 86: reward: 890.000, steps: 933\n",
      "Episode 87: reward: 1580.000, steps: 1389\n",
      "Episode 88: reward: 1470.000, steps: 910\n",
      "Episode 89: reward: 1050.000, steps: 711\n",
      "Episode 90: reward: 1160.000, steps: 1023\n",
      "Episode 91: reward: 1390.000, steps: 1206\n",
      "Episode 92: reward: 780.000, steps: 793\n",
      "Episode 93: reward: 1540.000, steps: 1357\n",
      "Episode 94: reward: 1480.000, steps: 1152\n",
      "Episode 95: reward: 1590.000, steps: 785\n",
      "Episode 96: reward: 1090.000, steps: 865\n",
      "Episode 97: reward: 1550.000, steps: 845\n",
      "Episode 98: reward: 2350.000, steps: 1297\n",
      "Episode 99: reward: 2530.000, steps: 1087\n",
      "Episode 100: reward: 1170.000, steps: 975\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "#Atari Testing Processor (Change Reward Metric)\n",
    "class AtariProcessor_test(Processor):\n",
    "    \n",
    "    def process_observation(self, observation):\n",
    "        # Crop\n",
    "        img = observation[1:176:2, ::2]\n",
    "        # Convert the image to greyscale\n",
    "        img = np.dot(img[...,:3], [0.299, 0.587, 0.144])\n",
    "        # Resize\n",
    "        img = img.reshape(INPUT_SHAPE)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return reward\n",
    "\n",
    "weights_filename = 'dqn_{}_weights.h5f'.format(ENV_NAME)\n",
    "\n",
    "processor = AtariProcessor_test()\n",
    "dqn = DQNAgent(model=model, nb_actions=n_actions, policy=policy, memory=memory, processor=processor, nb_steps_warmup=start_steps, \n",
    "               gamma=discount_factor, target_model_update=batch,train_interval=steps_train, delta_clip=1.)\n",
    "dqn.compile(Adam(lr=learning_rate), metrics=['mae'])\n",
    "\n",
    "\n",
    "dqn.load_weights(weights_filename)\n",
    "history2 = dqn.test(env, nb_episodes=100, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9eZwkV3Xn+zsRuVdldVV1V7d6Vbek1sYiAUJiNyAwGtsY2eNFZsZgGxubYbMfz++B8Xiwn3l4vMCAbbDBGITByHjMajYLIYQkhISEhIS2bkktqVvdXXt15VK5RMSdP+69ETcib0RGZmV2d2Xf7+dTn8qKzIyMqMy8J875nYUYYzAYDAaDIQnrVB+AwWAwGE5/jLEwGAwGQ1eMsTAYDAZDV4yxMBgMBkNXjLEwGAwGQ1eMsTAYDAZDV4yxMBgGBBExIjrvVB9HEkT0QiI6SERVIrr6VB+PYeNgjIUhESJ6nIjWiKhCRCtE9D0i+h0isiKPewERfVs87gQRfZmILlTuf6lYTP828rxbiOjXEl5/PxFdR0TzRLQqFrq/JqJdAz/Z0xAi2iv+b1Xx8zgRvXMdu/wTAH/DGBtnjH1xUMdpGH2MsTCk4dWMsTKAswH8GYD/F8DH5Z1E9HwA/wHgSwB2ANgH4F4AtxLRXmU/NQCvi2yLRVyl3w7gKIBnMcYmALwQwKMAXrSeE9qATDLGxgH8CoA/IqKrenkyEWXEzbMB3N/PASj7MJyJMMbMj/mJ/QHwOIBXRLZdDsAD8HTx980APqx57tcBfELcfimAIwD+Wm4T228B8Gsxr/1pAF/pcnxTAP4dwDyAZXF7l3L/dwD8KYDvAagC+AqAzQA+A2AVwA8A7FUefyGA6wEsAXgYwC8p930SwN+J+ysAbgJwtnI/A3CeuP3TAO4Wr3EYwHuUx30VwFsj53EvgKs157dX7DejbPsBgP9b3P4NAA+Kc/+m5njeDOAggEPgRtYDsCb+F3lw4/5lcb6PAPgt5fnvAfC/xfuwCuA3+/h/flCc/yqAuwC8OLL/zwH4lPh/3g/gMuX+3QA+L97bRXCPCN3O2/wMaS041Qdgfk7vH2iMhdj+JIA3ASgBcAG8TPOYXwfwlLj9UnBjcZZYOC4Q25OMxfG4+5THbAbwn8VxlAH8K4AvKvd/RyyC5wLYBOABAAcAvAJARixUnxCPHRML26+L+54NYAHA08T9nxSL2kvEQvtBALcor6Uai5cCeAa49/5MALMQxgDALwG4XXneJWIxzGnOb6/YbwYAgXtWdQBXArhanNtF4v4/BPC9yPFcD2AaQFH3foIbvA8DKAC4VCzMV4r73gOgLV7HAlDs5f8p9vFfxXuUAfAO8Z4WlP03APwUABvA+wB8X9xnA/gRgA+I96UA4EXivsTzNj9DWgtO9QGYn9P7J7q4KNu/D+DdAHaJRelCzWOuAtASt18K4Ii4/ecA/kXcTjIWDoCrlL/fAmAF/Ir2YzHPuRTAsvL3dwC8W/n7rwB8Xfn71QDuEbd/GcDNkf39PYD/IW5/EsB1yn3j4IZyt/jbNxaa4/pfAD4gbufBr+T3i7//EhrPTNy3V+x3Bfwq+kEAbxP3fR3AG5THWuCG5GzleF4e936CX7m7AMrK/e8D8Elx+z0Avht5fur/Z8z5LAO4RNn/t5T7LgawJm4/H9xwZTT7SDxv8zOcH6NZGPplJ/iCtwwe2tiuecx28C98lP8J4FVEdEmX11hU98sY+xvG2CT4wpsFACIqEdHfE9ETRLQK4LsAJonIVvYzq9xe0/w9Lm6fDeAKIeSvENEKgP8C7g1JDivHUwX/H+yIHjgRXUFENwph/gSA3wGwRTyvCR5++a8iUeBXAPxTl//FFsbYFGPsIsbYh5Tj/aByrEvg3sdO3fFq2AFgiTFWUbY9keL5af+fIKJ3ENGDIulhBdwb2aI8/rhyuw6gILSR3QCeYIw5mtdPc96GAWOMhaFniOi54F/MWxhjNQC3AfhFzUN/CTzMEYIxtgi+4P9/XV7qBgA/3+Ux7wBwAYArGBfAXyIPs8vzdBwGcBNjbFL5GWeMvUl5zG55g4jGwUM8RzX7+mdwLWA3Y2wTuNahHtO14IboSgB1xthtfR7vb0eOt8gY+57ymKS20kcBTBNRWdm2B8BTKZ+fCBG9GDwZ4pcATAlDfwLp3pvDAPbEiOppztswYIyxMKSGiCaI6GcAXAfg04yx+8Rd7wTweiJ6GxGViWiKiP4UfOF+X8zu3g/gBeBx5zjeA+DFRPR+ItopjmFL5Dll8KvZFSKaBvA/+jw9gIvj5xPRrxJRVvw8l4jU1/spInoREeXAjd3tjDHd1XcZ/Kq9QUSXA3iteqcwDh54GKebVxHH3wF4FxE9DQCIaBMR6Yy2FnHc3wPwPiIqENEzAbwBXKweBGXwUOI8gAwR/RGAiZTPvQPAMQB/RkRj4vheKO5b13kb+sMYC0MavkJEFfAruneDL/S/Lu9kjN0C4FXgXsAx8LDA68Hj5fd17g5gjK2CaxfTcS/KGDsA4HngusiPxDHcCn5F/N/Fw/4XuPC6AK6jfKPfkxThmJ8EcI14jePgIbO88rB/BjdISwCeA+4d6PhvAP5EHPMfgYedonwKXAT/dJ/H+wVxfNeJENyPAfynHnfzK+C6yFEAXwDXZ67v53g0fBNcXzgAHt5qIDks5sMYc8H1j/PAkymOgGtKgzpvQ48QY2b4kWGwCC3i2wBeyxj75qk+nkFBRJ8EF+n/cED7ex2ANzLGzrSaEcMGxHgWhoHDGPsReHrjM0whlx4iKoF7Hx891cdiMKTBGAvDUGCM3cwY+8uYbJYzGiJ6FXgcfxY8rGUwnPaYMJTBYDAYumI8C4PBYDB0ZWTjyVu2bGF79+491YdhMBgMG4q77rprgTE2E90+ssZi7969uPPOO0/1YRgMBsOGgoie0G03YSiDwWAwdMUYC4PBYDB0xRgLg8FgMHTFGAuDwWAwdMUYC4PBYDB0xRgLg8FgMHTFGAuDwWAwdMUYC8PI8x/3H8fcauNUH4bBsKExxsIw0rgew+98+i5c94NUYxQMBkMMxlgYRhrH8+AxoOm4p/pQDIYNjTEWhpHG9XhXZcc13ZUNhvVgjIVhpHGEsWgbY2EwrAtjLAwjjSuMhON5p/hIDIaNjTEWhpHGeBYGw2AwxsIw0gSahfEsDIb1YIyFYaSR4SfpYRgMhv4wxsIw0rh+GMp4FgbDejDGwjDSOCZ11mAYCMZYGEYaX7MwYSiDYV0YY2EYaRyTOmswDARjLAwjjangNhgGgzEWhpFGehRG4DYY1ocxFoaRxmgWBsNgMMbCMNI4pijPYBgIxlgYRhrXtPswGAaCMRaGkcb3LEw2lMGwLoyxMIw0rmz3YTwLg2FdGGNhGGmkkWgbz8JgWBfGWBhGGlNnYTAMhqEZCyIqENEdRPQjIrqfiP5YbJ8mouuJ6KD4PaU8511E9AgRPUxEr1K2P4eI7hP3fYiIaFjHbRgtzDwLg2EwDNOzaAJ4OWPsEgCXAriKiJ4H4J0AbmCM7Qdwg/gbRHQxgGsAPA3AVQA+TES22NdHALwRwH7xc9UQj9swQkjPwjVhKINhXQzNWDBOVfyZFT8MwGsAXCu2XwvganH7NQCuY4w1GWOHADwC4HIi2g5ggjF2G2OMAfiU8hyDIRHTddZgGAxD1SyIyCaiewDMAbieMXY7gG2MsWMAIH5vFQ/fCeCw8vQjYttOcTu6Xfd6bySiO4nozvn5+cGejGFDIj0KI3AbDOtjqMaCMeYyxi4FsAvcS3h6wsN1OgRL2K57vY8yxi5jjF02MzPT+wEbRg7jWRgMg+GkZEMxxlYAfAdca5gVoSWI33PiYUcA7FaetgvAUbF9l2a7wdAVtTcUj2IaDIZ+GGY21AwRTYrbRQCvAPAQgC8DeL142OsBfEnc/jKAa4goT0T7wIXsO0SoqkJEzxNZUK9TnmMwJKJ6FKaZoMHQP5kh7ns7gGtFRpMF4HOMsX8notsAfI6I3gDgSQC/CACMsfuJ6HMAHgDgAHgzY8wV+3oTgE8CKAL4uvgxGLriKgbCcRmydsKDDQZDLEMzFoyxewE8S7N9EcCVMc95L4D3arbfCSBJ7zAYtKjeRNvzUISxFgZDP5gKbsNIo7YmNyK3wdA/xlgYRhonFIYy6bMGQ78YY2EYadxQGMp4FgZDvxhjYRhpjGdhMAwGYywMI43aE8qkzhoM/WOMhWGkcSKpswaDoT+MsTCMNCHNwoShDIa+McbCMNKEPIuUYahP3fY4/ubbB4d0RAbDxsQYC8NI47q9C9zXPzCLr913fFiHZDBsSIyxMIw0oQrulJpFy/FMyMpgiGCMhWGkCWdDpTMALddDyxgLgyGEMRaGkaafbKi266HlGGNhMKgYY2EYafrJhmo7zIShDIYIxlgYRhrHY7AouJ2GluuhaTwLgyGEMRaGkcb1GApiiEVab8EI3AZDJ8ZYGEYaRzEWaTWLltEsDIYOjLEwjDSu5yGfscTt9AK3x9I/3mA4EzDGwjDSOK4ShkqbOiu8CuNdGAwBxlgYRhrXY75n0UvqLABTa2EwKBhjYRhpnB4FbsaYX+ltPAuDIcAYC8NIw7OhhGeRQoNQvQnjWRgMAcZYGEaacDZU98Vf7R/VNp6FweBjjIVhpHE9D4WMDEOl8Cwc41kYDDqMsTCMNI7HkLEJtkWpGgmquobRLAyGAGMsDCON6zFkLELGolTZUMazMBj0GGNhGGkcl8G2LGRtK10YSjEQRrMwGAKMsTCMNL5nYacLQxnPwmDQY4yFYaRxPAbbJmQsK1XqrNEsDAY9xlgYRhrX8xTNojeB23SeNRgCjLEwjDSOx2DLMFQKzUKdY2FmWhg2Ap7HTkrTy6EZCyLaTUQ3EtGDRHQ/Eb1dbH8PET1FRPeIn59SnvMuInqEiB4molcp259DRPeJ+z5ERDSs4zaMFlKzyNoW2qnCUEx722A4XfnozY/hFe+/aeivkxnivh0A72CM/ZCIygDuIqLrxX0fYIz9pfpgIroYwDUAngZgB4BvEdH5jDEXwEcAvBHA9wF8DcBVAL4+xGM3jAjcs7BSh6FCArfxLAwbgBsfmsPhpfrQX2dongVj7Bhj7IfidgXAgwB2JjzlNQCuY4w1GWOHADwC4HIi2g5ggjF2G2OMAfgUgKuHddyG0SLIhkqXOms0C8NGwnE93HvkBJyTEIo6KZoFEe0F8CwAt4tNbyGie4noH4loSmzbCeCw8rQjYttOcTu6Xfc6bySiO4nozvn5+QGegWEjwhj/AtkWIdtP6qzxLAynOQ/PVrDWdgEM//M6dGNBROMA/g3A7zLGVsFDSucCuBTAMQB/JR+qeTpL2N65kbGPMsYuY4xdNjMzs+5jNwyfudUG7j96Yij7lqmyPVVwm66zhg3EPYdX/Nsb2lgQURbcUHyGMfZ5AGCMzTLGXMaYB+BjAC4XDz8CYLfy9F0AjortuzTbDSPA39z4CH7r2juHsm/pltu2DEOZ3lBp8DyGv73xEazUW6f6UAxduPvJwFg0HXeorzXMbCgC8HEADzLG3q9s36487OcA/Fjc/jKAa4goT0T7AOwHcAdj7BiAChE9T+zzdQC+NKzjNpxcVtfaWKwNZ1FSPQsehjK9odLw2EINf/HNh3HDg3On+lAMXbj7yWX/9rBTvYeZDfVCAL8K4D4iukds+wMAv0JEl4KHkh4H8NsAwBi7n4g+B+AB8EyqN4tMKAB4E4BPAiiCZ0GZTKgRoel4aDoeWo6HXGaw1y6uK42FxSu4Xafrc9qmNxQaIgYuY+GG05MT9TYena/h/G3jODBb3bjGgjF2C/R6w9cSnvNeAO/VbL8TwNMHd3SG0wX5Aa81HeQyuYHuWwraGZt7Fr3MsxjL2WesZyHPu2GMxWnNj47wENQV+zbjwGx1Y2sWBkM3ZJy10uh+1d8rvmZh8d5QaVILW8KglPKZMzZ1ttnm520q2E9v7n5yBUTAZXt5QumwL26MsTCcUuTCVGm2B75vVbOwbUI7ZepszraQs60zdrGUBtx4Fqc3dx9exv6t49gyngcANIf8fhljYTilyAW5OlTPwkI2Zeps2/WQtQn5TLoivlFEvifGWJy+MMZwz+EVPGv3lK/1Gc/CMNLIBWkYYahQnYVtpe46m8vwYUmtIacinq4ExuLM9Kw2Ao8v1rFSb+NZeyaRs4Wx2KgCt8GQBt+zaA7Ds+D7lhXcaRoJthwPWdtC7kz2LNomDHW6I1NmL90z6W8bdtjUeBaGU4ovcA/BWIQruNN5Fi3fs6AztijP9yzO0PPfCNx75ATGcjb2by2fNM/CGAvDKUUuTJXGEARuV8mGSjnPwhe4M5YxFsazOG1ZqDaxbaIA2yJfs9iwFdwGQxpkNtQwBW5eZ2GlyobiArfQLM7U1FmTDXXaU2s6GMtzFSGfsQEYz8IwwjDG/IVpGJqFo2RDpW4kKCrJ82eyZyHrLIzAfdpSa7oo5biRCDwLYywMI4rjMUjNeZhFeX42lMfAR6LE03YZsjYJgfvMXCz9Cu4zNBtsI1BrORj3PQtjLAwjjvrhHk7qrJINZZHYlmwsWmrq7BlqLKRH0UsY6o5DS3hkrjKsQzJEqDUdlISxMAK3YeRRK06rQ6jgjnoWALqGovzUWds6YxsJBppF+vN/5+fvxfuvPzCsQzJEqLVcjOd5GMoSqeHGszCMLMP3LIJsqKwtPYvkL1Tb9ZDPWMhmzmDPoo9sqFrTwexqc1iHZIhQazoo5YIyuXzGNp6FYXSRi5JFQyrKC7UoF8aiB8/izO0N1buxaLQ9zFeMsTgZeB5DveX62VAAF7lb7nA1JlPBbThlyHDH9FhuKKmzqmdhizBUt/RZmTp7JgvcfgV3D8ay6biYr3hgjIHPKDMMi7p4f8ZENhTARe5hZ68Zz8JwypAx8c1j+eFmQ9mKwJ3Cs8hluGdxxqbOivNuOR68FC1SGGNotD2stV3UWiaDatjUhRfe6VkYY2EYUeQV7ObxHFquN/AKVDUbKrXA7TK/KM9jSDUDY9RQ34c0oTj1MSYUNXxkyHZcNRYn4eLGGAvDKUMuMrIf/6BDUW5kBjeQLgyVz1hB2+cz0LtQF/80uoUa/lioGmMxbOrCeyupYajs8DU2YywMpwz54d48zsepDjoU5UQm5QFpBW46aTMCTkfUxT9NYZ7qiRjPYvic9p4FERWJ6IJhHozhzEIuMr5nMeCMqMCzsJCRnkWXxV/Os8iJx5+JnoVqINPUWqiPMcZi+NTE96QU0SxOi0aCRPRqAPcA+Ib4+1Ii+vIwD8yQHs9jeODoKo6faJzqQ+kJeQW75SR4FkGdRbxn4XkMjsf8bCigu3EZRZqOi2KWhzjShKEaxrM4qcgkAlmUB5ycOou0qbPvAXA5gO8AAGPsHiLaO5QjMqTmuwfm8Znbn8Dth5awUm/jin3T+Jfffv6pPqzU+GGoMe5ZDLpNuSsW+kwoDBX/hZJX1FLgBs5Mz6LZ9rCpmMVa201nLNrGWJxMfM8iF/UsTo8wlMMYOzHUIzH0zF9882Hc9ugiXnnRNjx958SG+6JKt1lqFoMOQ/mehU1KGCres5DGIiRw9+hZzK028K7P3zf0kMAwaTrcWADpwlChbCgjcA+dmiZ19mR0SU5rLH5MRK8FYBPRfiL6awDfG+JxGVJQazp4yfkz+ItfvASX7JrEibXB91caJh3ZUEPTLMj3FJLafcheUGk8i289MItrPnpbRx3C9x5dxGfveBIHjlfXffyniqbjKsYivWcxns9suAuWjUit2VmUdzp5Fm8F8DQATQD/DOAEgN8d1kEZ0lFvBT3tJ4pZrDbaXVtwn04EmoUMQw0zG6q7ZiG9iFwKz+K2xxbx/ceWOu6XHsVyvbW+gz9F8BkjHiZ6Mhb8f7BrqpjaWCzXWnjg6Gr/B3oGU285yGcsv3YIEBXcp9pYEJEN4MuMsXczxp4rfv6QMbax1NQRpN4KmolNFLJou6ynTqGnmqbjImsTijkbOdsauLFQs6GyKYry2g6/T/aG4tv0/0+5KEYXU/mF3ajGou0yMAZMFPnnqpfU2V1TJSzWmqmqvj9682P4L//w/fUd7BlKVZmSJ+EC9ynOhmKMuQDqRLRpqEdi6JlG20NReBYybLA6hFnWw6LR9vyRkOVCZuBtyqWYbRH3LtRtOnrxLKSxiF7NSW9ppb5x3gcVufD3olnIx+yeLqLtslTh0JV6GytrG8sTPl3gTQTt0LaT0e4jbTZUA8B9RHQ9gJrcyBh721COytAVx/XQcj2UsjIMxd/K1bU2tk0UTuWhpabpuP6Ur/FCZihhqIxFIFIruBPCUGLhz9kUeBZxxkIIudHmbRs9DCWNXz+axe6pEgD+v5kay3V9DmP89QpZO/GxhjDVpoOxXNSz4GGoYTZyTGssvip+DKcJsvOk9CwmChvPs2g6XmAs8pmhtPuQHkWa1Nl2D6mzsq1FNOtJLrYb17OIGos0noUwFtPCWFSaOH9bOfE5a6JWYK3lGmPRI/VWZxgqZ1tgDKJO6BQaC8bYtUSUA3C+2PQwY2xjfhtGBPllKyoCN4B1Z0Qt1Vr4628fxO+/6oJQHvcwaDoe8tkgDFUZQuqsFLZl6mySZqEPQ3U+vum4vjHoCENtcM2i1YdnIc9511QRQLpaC6mF1Nsupvo60jOXajPIVpOovcyy9nC6OKWt4H4pgIMA/hbAhwEcIKKXdHnObiK6kYgeJKL7iejtYvs0EV1PRAfF7ynlOe8iokeI6GEiepWy/TlEdJ+470NkGuZ3NBObKMgw1PoW3H+4+TF84tbHcdcTy+s7wBQ020oYKp8disAtPYtsinkWaups0lzjxWpgCDo8i7YMQ63/WooxdtJj+vJ8ilkbuYyVTuBuuyACdkymNxaqZ2HojVrTCaXNAvC/R8PMiEprgv4KwE8yxn6CMfYSAK8C8IEuz3EAvIMxdhGA5wF4MxFdDOCdAG5gjO0HcIP4G+K+a8BTdK8C8GGRiQUAHwHwRgD7xc9VKY97ZPE9iyw3EoMQuNdaLj57x5MATk73UDUMNRSB2/P89MI0k/KaOs9C8+VTF8NomCYIQ63fs/j5j3wPH7zhYF/PrTUdPDrfe62H1GDyWQuFlAN1GuJ9nChkkM9YqQrzpMfSyzQ+A6euyYbKiUSRYRbmpTUWWcbYw/IPxtgBANmEx4Mxdowx9kNxuwLgQQA7AbwGwLXiYdcCuFrcfg2A6xhjTcbYIQCPALiciLYDmGCM3cb4ZdanlOecsay1+VW4DEOVpWaxjjDUF+95yr8iXqgMP4zCBW4lG2qYmkUXwRoIPIucbQWCuObxqrGI0ywGEYY6tFDD4wu17g/U8PFbDuHqv7m1Z89EHn8+Y6OQtVML3PmMDSLCTDmfzrMQ+60bz6JnqhrPIud7FsP7f6Y1FncS0ceJ6KXi52MA7kr7IqKP1LMA3A5gG2PsGMANCoCt4mE7ARxWnnZEbNspbke3617njUR0JxHdOT8/n/bwNiTRMFQuY6GYtbHa54LLGMMnbj2Ei7dPIGdbWKidJM8iGwjclYYz0LCL4zJ/Ql6aRoKyFUhXz0K5co5eecvFdaW2fi+pKabP9cPRlTVUmk7PdTdysclnrNTGotn2UBDvY6/Got/zO1NhrHP+NhCEoU4Hz+JNAO4H8DYAbwfwAIDfSfNEIhoH8G8AfpcxllSyqdMhWML2zo2MfZQxdhlj7LKZmZk0h7dhqbeC2LJkopjBiT5j5bc+sogDs1X8xov2Yct47uR4FkqdxXghA8djA425uh6DbafPhpID70PZUF09C30YqtJ01tWxljGGhuNirc8iS+nZVHoM7Unjl8tYKGStdNlQTpDRNDOeTxXCXGt54rcxFr3QdDw4HtOEoU4fzSID4IOMsZ9njP0cgA8B6JrvRkRZcEPxGcbY58XmWRFagvg9J7YfAbBbefouAEfF9l2a7Wc08opPnZY1Ucj2rVl84tZD2DKew6sv2Y7NKb/w66XpuL5nIcNogxS5eTYU3382RSPBoIKbEgXu5DBU8Pd6MtNargfGgEafi+my8Gx6/X92hKFShDUabRcFYfTTehZN37MY/Oz1UUZeJJ7OAvcNAIrK30UA30p6gshY+jiABxlj71fu+jKA14vbrwfwJWX7NUSUJ6J94EL2HSJUVSGi54l9vk55zhlLEIYKrjBkf6heeXyhhhsemsNrrzgb+YzNPYuTLXCLK6VBtilXNQsigm1R4kxtVeC2xAyMOM1isyg6i6vgBtYncssr+n7DNEvitXvVgUJhqExazSIIJ86U81iqt7p6VX4YqrVx2tOcDugGHwE4KWOA0xqLAmPMT60Qt0tdnvNCAL8K4OVEdI/4+SkAfwbglUR0EMArxd9gjN0P4HPgIa5vAHizaDUC8DDYP4CL3o8C+HrK4x5ZdGGoTcVsX6mzMk32Zy/ZDoA39jt5xkKEocSHf5CdZx3P87OgAJ4RlSZ1VnoV2ZhRlQvVpl9T0FnB7fnPX0/6bHOdMf3lmjAWPf4/fc8iayGfMgzVdMKeBWO8XieOtuv52pHRLHqj1uocqQoomsUQW36kNRY1Inq2/IOILgOwlvQExtgtjDFijD2TMXap+PkaY2yRMXYlY2y/+L2kPOe9jLFzGWMXMMa+rmy/kzH2dHHfW5hpKIO1VjgbCuC1Fv14FnJBmSrxq+Ut5TwWq62h5/g3lDqLsqgTGWRGlOpZANxYpC3Kk7+1nkW1iV2itUVnI0EX2zbxLrrLCQtmN+Si3U9M3/MYVtb6DEO1pWfRSzaU4lmIDsJJoSjVQMjPsY57j6zgsj+9HnOrpmepJBh8FA1D8b+bQzS+aY3F7wL4VyK6mYi+C+A6AG8Z2lGNGC3Hw5fueWqgi2+95SJjkb+wATwM1U+cXIZ+xsWCvWU8D8dL1xBuPYSyoWRR4cA1C8VY2FZyuw+lKE/+jhO4z9pUgEV6gfss0ZtrPS0/1lOHUGk4fritV89CHQBVyNqpYuCNtiJwl7sbC1WHSfIsDs5WsVBt4d4j/c1du/ngPI6dSLym3XDIWRZRz6LfYV29kGgsiOi5RHQWY+wHAC4E8C/gxXbfAHBoaEc1Ynz7oVm8/bp78C6ND9EAACAASURBVMCxwfXvX2u7Ia8CEAJ3H508K00HOdvyr07kTOxhhqIYY2gpYahyngvcgwxDRT2LrE2JjQTbrgeioIAvZ3fOCKg1HdRbLmbKebGYRiu4Pb+R43pqLdajWSwpr1vt0dP0i/IyvCgvjbFqKdpTGmMR9iziFzfZ/+xQH7Um1aaDX/vED/DJWx/v+bmnM7qRqoAicA9xREE3z+LvAchP3vMB/AF4y49lAB8d2lGNGPKL0++VuuN6HTMC1pTBR5KJYgYeCwa6p6XacPwwEBAMI5ofYvpskHUTDUMNzptx3CAbCuDps0meRdPlfXVkNxkehgr/3+V7OTOe1w6caToupko5ZG1al2Yhs5DW2m7Pxl81Uv1oFrZFyNjp6yxUz8L/7CRcaKg6SFI2lAxRPbbQeyX6nY8vwfXYwPuNnWrk+3naeRYAbEVT+GUAH2WM/Rtj7L8DOG9oRzViLIk0RulC9spVH7wZH7v5sdC2essNiduA0nm2R6NUbTp+GAgIvvDD9CyixkK+/iBTZzs0CztZs2g7zBenAe5ZRAfKyEVwppxHPmNrBe5C1sJkKbfObCj+urKNdy+oWkmvi6XaNj59nUVQlFfI2igXkserhj2L+O+ETOJ4bL53z+KOQ0td978R8bMgo/MsunRJHgRdjQURyVXkSgDfVu4bbkvSEWJJVEPX+rjKYYzh0EKto89PveWiGHFF++0PVW04oSsVGYZaHKqxEEKqMHhZmxeBDTwbylbDUFbyPAvXDWlA2QzFexblPPJZS9vuI5+xMVXKrisMpRqhXnULNROpnzqLwFjwOotuno1s9yGZKecTPQt1AU9q9yEf91gfYajbhbGoJwjoG5E4z0J+j4bZ7qPbgv9ZADcR0QJ49tPNAEBE54HP4TakYEmEI/pZCJuOx93pyJd+re1owlDSs+jtdSrNsLGYKuVgEbBQHWIYSiyGBWVxHs9nBxo20GdDJQnc4VkAOU3qbMhYRMJQbZe/V/kM9ywGEYYC0s2UUJHC+pbxXO91Fm3PN5iFrA3GeGhDNQYdz1E8CwDYMpbHQpLALYyfRcmajDQk85UmKo22X7jZjbWWi3uPrPDbG2jMcBrqLQe2Rb5Bl5xyz4Ix9l4A7wDwSQAvUlJWLQBvHdpRjRjr8SzkF6bDWOg0i0J/My2imoVlEabHhltrEeTzB+dQHvC0PF02VFIFd8v1Qp6FblTlQrUJ2yJMlXLIR4rW1BqFqVJ2IEV5QO8i91K9hYxF2DZR6EOzCLwEuSAlGStpIAuKMZksZRMzweT5TJVyiV6T6nUkidxzlUbI+/nhk8tou9zwJ6XmbkRqTf69j05pkBc5p7SCmzH2fcbYFxhj6jjVA7KjrKE7UrPox7OQBiZa2azVLJTRqr1QjXgWAIZexa1WCkt459nhVHAD/AvlJBTltdzw4BhdUZ6s3rYtQiEb9izUGoWp9XoWKeP6OpZrLUyN5frq5BsNQwHJufvyONVpd/zc4w2lPJ+psVxyGKrt+ItgnG6xXGvhhX/2bfyjkvV0+6ElWAQ8a8/UyHW1rWm+qwDvUJDP6ItIB8VwRioZQkjPoi9j0ZLGIhqG0qfOAr1rFpVGOyRwAzLufPKyoQAxWnWgmkU0G6qbwO2FBG7dl2++0vTTQ/OZcB2Cek5S4O63tkbdb6+exXK9helSDuVC72E9tfZFGoAkz6KhzL+QTI5xzyLu3GWIbbqU6xqGOndmHBbF6xZPrayh7TJ85DuP+Ebo9scW8bQdm7C1nB+5CvFaqzP8LMlpsvMGiTEWQ4Yx5jd16ycMJTOoosVqdU0YqtzHtDzGGKpNpyMevGU8P1yB28/nD85BtikfFJ3ZUFZXzyIkcNudFdzzVdVYhAXuaBiq7bKe05glqmfRq8C9XGtjspRFOd/7QCk1DCV1iKQFV56/GoaaKuXQcr3Yq3q5qE+P5RIbJdZbfHzorqkSHosZ5CS934VqC5+940k02i7uPryCK/ZNo5i1+86G+saPj+E9X76/r+cOk1rT1XoWQOfFy6AxxmLIVJuOH/fuJ3VWZnNEv/RrLdefkifJ2BbG8721/Gg6Htouiw1DDavlR5ANpYahBjtaNdobKtstddYNexY6zWK+0vRTi/PZ8CQ5deGUrVP6bfnRXEcYaqnewvRYDuN9hKHUAjtpAJKMlc6zmCrxC4+4UJTc39RY1i+80yF1uX1bxmI1Cznids90CX9306P4weNLaDkeLt83jVLO1hqsN3/mh/iTrzwQ+7oAcOND8/i3u44kPuZUUGs6HQV5EhOG2uAsK0Nw+tMsZNsHz7/KZYxhrd3pWQC8P1QvArc8pnIkDLV5PI9G2+v7yrgbjXZnGIqPVh2gZ+GGPQvb6pI663RqFm3ly+d5DAvVhDCUsnBOigWz35YfjXWEoVbqXLPoZ6CUTrNINhaBTiOZFIYy7tzX2i5sizBRyHaps+AL4zkz3FjozmNRhHjf/dMXYa7SxB996X4QAZfvm0Yxl9H+7x48toofH01O5lxru6j3URA5bGqawUcS3cXNIDHGYsgsKhPn1iNwA4Fu0RIZKFHNAhBtynsxFg193rZfmJdiNkE/BAJ3NAzVe7uSOByPhessuqTOtlyGbEI21Im1Ntou85vl5SPtMNRZEFOihXm/tRYhgbsHY+F5DMv1NqZK2b4GSqkDqWQYqpHwfN+bCnkWXYxFy0Mxa6OY48Y22p0geBzX5c7ZMoZ6y8VxTUPBxWoLuYyFn7x4Gy47ewqHFmq4YFsZk6UcilkbLZF6rlJrOV0z1eotF67Hhrr49kOt6WAsr9cs8hnrtGgkaOgTuVhsLef7TJ1VjQX/8smrsWg2FND7AKS4Ih+/MG9I41V1Ane5wNuVDEqU7LWCuxURuKN1Fmr1tjz2sMAdZHh1C8V0o9n2/EygXjQL2URwqpRTZoSk/9ypA6nSeBZ+vUwoGyr53NdEexD5+Y17v+vCez5nZhwAcEiTETVfbWJmPA8iwluv3A8AuGLfNICgM2u0MK/edLtmqslzPt0qwLmxMJ7FSKLGVPvLhgo+rPJLH52/rTJRzPQkcMt9RrOhht0fShWDJYNu+dGRDWVbyfMsXA+5jFKUF/nyqQV5ADoaCaqifbdQTDcajuvvo5cFSy7QUrMAevNow2EoWWeREIbyPQtdGEr/2Wm2XRRzlu8ZxxoL6VnMjAEAHtXoFovVFjaLC5uX7N+CP/7Zp+ENLzoHALT7Z4z5nkWSBysNzOmWeltrOR1T8iTcszDGYsMiv7x7pkv9eRbKc6TH4A8+0moWvXkW0luRXV8lckEcVq2FdJcLoaK8wY5W7aiz6JY6GxW4I0V8CzGehVx0VAM4WVynZtF2/X304mnJjrNTpRzGZSffnjyLICMsmJGQInVW8RAnfc8iXrMoqp6FZkF2Pd6VuJTNYFu5gGLW1noWi7VgaiER4fUv2Is9m/msEd3+G20PHkPXTDVZ+X06GQvH9dBoe8azGFUWay3kbAtbJwp9ZUNVm52eRTB/u/ND0+tMiziBe3psuG3KtWGoAY9W7ZiU12WehU7gdj3mx7yjnkVetMOQBiUQey1kbAvlQmYdmoWHUs5GPmP1ZCxk9pUsygOASg/ps822mjorwlAJ/YaaGs8ia1so5+PP3Q9DJXgW8sq+lLNhWYR9W8a03WcXKi3fC44ShKGC/deUkFRSptrpGIaSmWNjMdlQuvY0g8QYiyHDq2mzGM/baLlez42+wppF2DXWahbFLKpNJ1Y0jOJrFhFjkbV5Rs+wjYV6JV8ecBiqn3kW0XYfQNBvZ77SRC5j+UbNnyEg3lNV4Ab41X2/LT9kc75izk6sRYgir+anS7lgVG2PnkVPYShfswgvJbIwT8daK6JZaM5vLeI9y4woFcYY9yxijIXOGNWVi68kry8IQ50+7UJkZCLOs+DZeUbg3rAs1VqYHsv7X9xevYtay/UFw4ofhuocqSqZKGTAWPrW1JWYbChAFuYNS7PgrbDVHjf9xNiT6OgN1W2eRYdnwZ8rXfu5ShNby3n/mANj4Ynf4RYmvPNsf16SrKQuZOy+PIvJsWwwIyTl/9MRs7E7PIvEMFRnUR4ATBbjW340ZBgq0bMI63LnbBnD4aV6aDFcbThou8xPxoiiM0bq/yJNS5KkOpCTjVw74rKhcqbOYmPDjUXWvxroVbeoNx1/8ppc2NcSBe7eZlpUm7z/TrSLJTDc/lA8RTP8moFmsf4wlOcxMMZrKyRd51lEPIu8xrOQISh+fzhbKCrar2emRUMJ1fTSdVY2ESznM/4FQFpPzR+pmg3GymYs6rkoD+C6xXo0iw5jMTMOjwFPLtb9x8gOA/FhqExoX/x2OmPhTyo8jcJQvmcRF4YyxmJjE/User1qrjYdTBSzKGZtxbNIMBY99oeSsyyiXSwB/iUcVptyfuUcPv5eF7ckZNZT5zyLZM0iF9EsAPjFkHOVBraqxiIb8SwiLUySFsxu8LbfNgrZ3jwLWZBHRD17ai2NjsSn5aWos4h4FkkhuEbbQzGX7FnICXpyZsveLTwj6nHFWMjP5uY4z0Kzf1XUjgtDOa7nG87TSeCWekt8GMr0htrQLNVamC4FnkWvxqLecjGWs0Ptu+WHX1+U11t/qOiUPJUt48lzCdaDOpFNMkhjIUXp6DyLaIGW+niPIRSG0mkWOs9CGomm4yJrk/+a3bqvJtFouyhkLBSznXOwf/9ff4Tf+5d7tM9bqrX8sGU+YyNnW6n/n1HNBRDT8hLi4I02N7CWFb7YmCplYwVkKXCXRLuaNJ7F2dM8w+mJxUC3kJ7F5rEumoXiTdRShKHCk/xOJ83i1IahzLS7IdJ2Paw2HEyP5fs2FrWWgz35UthYJAjcclpe2oyoSsPxUyyjbBnPodJ0QjOWB4UuDGVbNLDOs44wCrp5FoyxDk9KfsmijQQB/j62HA/L9Ta2lgv+/YFnEYSh8pG5DpWGA8f1kLF7uy5rtHlxXDHX2Qzv4dlKbDrrcq3tV1ADXAdK20ywqUmDjc7s0B6nJoQ5WcphNebcGy0XhayFQo5v1+kC0SQO2Rjx8JLiWQhjtKWs9yxKWU02lPLZSmpHEj2O04F6V8/CNBLcsAQFUoHY2Ltm4WI8l0FZqZ8Irro0qbM9hqH4BLJ4zwLg6b+DRu1uqiJbfqwX1+30LLLits67kGGH0KQ8RcCO1lgAeoFbXTj9thc9zheR+yxkeFw/GqZZXWv79RRRlkUTQUkvMy10zR0L2eRCL17x3fk+Su9Gd9ES1Sx02V5RXY6IsGdzCU+oxkJ4vdOl9GEo+d0ZT0rtTTn29WRTTaNZuN7Q+lkZYzFE5Cxk1bPo1VjUWg5K+XAYqt52kMtYoYVQ0o/AXY65Uhlmfyh1boLKoJoJ6jwLWxgCR2MspC6R16TOtl0Pc+J/sFUXhlI0C11xWq8iN2PM9+Z0msVqw8FyTV+BvFxv+RXUQG8zQvRhqGTPotn2OtJmASi9scKfw7bIuAoJ3InZUMFn8+zNpbDAXWtiqpSN9dp4tl148Zdx/11TxVSexek0D6PeJQzlJ2QMqTDPGIshsuQXSGUxnpNhqPQfPsYY7wWTy2CikA31hoobgFLOZ0DUOf8ijkTNoiw9iyEYC00YCuBhk8FqFkpYyQoL1ioyDJWNVHDL+6IFeYA6dlQJQylX2TKW3muSQNvl+kkha6GYDddZMMZQabTheKwjPVo2EZweC8KKvcwIkZ5FLipwJ2kWjj5EGdfyQ9XbMraFnG1pr9516eG7p0s4srzmv7eL1fiCPIB7I6Ws3RGGssXI2TgjvhaTPXWyeGSuguMnOpsmSqOf1KIcGN5oVWMshohsT755LO9fDfRaIOUxdHgWa5qRqhJLxP1TexYN/ZhGgNdsAL0NU0pLM2aRGdRMCznkKBNpJAhAmz7bdjXGQrlSm6vwL6+qWRQi2VDR+L3saXRwTj+4Jw6131IxF/YseKt6fvxLESOkNhGU9DLXXKdZFLJW10l5OqM/FdPyIzqGtaAR8AF9evjZ02NouZ7ffXah2ozNhJJE25TLGdZJNTBJYaijK2v4xK2Hhhbqabservno9/G+rz/YcV+t6aCYtbURBaAzIWPQGGMxROQ41akx7ioXslao3UA3ZMhqPJ+JhKE6R6qqTBTStymvJHgWg6x7iKJWCodec1CahS4bSgrWmvTZbgL3fKUJonCaZpANpQrcwfO3byqgXMjgoWOrPR272jYkqlmoWlRUt1hW+kJJ+gtDKcaii8AdZ/T94U+RY2y0+GvIi51SLqPPhmrzzDLVeO+JZETxJoLxngUAFHNWh6cwlstgMiFTLZwNFT62f7/3KP74Kw/grieWE1+3X245uICFaguzmnbsfJZF/PfeeBYbmCXhWcgvTq+ZPmrctlzIYq3tou16iWEogGdEpRG4m46LluPFahb+mNYBTq8LXtvTCty9XAkn4WsWdqfArfMsWjrPIhKGmi7lQvd31FlERHsiwkVnTeDh45Wejj0YomT7dQ6yfYt6ERBNTV1SOs5KxnvQgHQzRrppFo0YzULqNSciV+9rEc+imLO12VA67/ls0SBQZkQtVJvYMpbsWZSymVAoqdZyUcrboUy1jtf2ezB1TtqTXvYX73kq8XX7Re5XHZomSWpPDhjPYkOzVGtiopDxF5ixfKYngTvIfrCD1g0Nh08Qy8Z/aNK2KZd523FhqEK2tzz9XmjGpFz2YlA9j+Hf7z2q/cK7vsAdblEOxBgLzVW1bFfechnmIjUW/LERgVsj2l9wVhkPHa/0OK0uHIZSX0M13EsRY6E2EZSM57M9ZEN1VmPnu4ah4rPaMhZ1XL0HmkUwM0PnWejGh27fVEDGIjyxWEfL4WnpSZoFfx3b7yAr9zuezyRmqkkDMT2e69As5Gfzq/ceW/eifOPDc5hTPIha08F/3D8LoNNrlK8dlwkFADmbvw8bzlgQ0T8S0RwR/VjZ9h4ieoqI7hE/P6Xc9y4ieoSIHiaiVynbn0NE94n7PkS6UuPTlKV6O3SVN5brzVj4nTfzmVD7bjlBLI60bcr99uQFfZ0Fv28wYaEo8dlQWdRbbmIPJ8n1D87iLf98N24+uNBxn6NLnRVehi4MJXWAsGcRfPmiBXmAppGgJn5/4fYyqk0HR5bXup6PxG/OJ8JQQLDIqu9rdCGWMXipFwD8/UvbwFKvWSQ3p+NZW53vIxGJUE/n7Hi5X4BrErJaW0UOPlLJ2BZ2ThXx5FLdT7roGobK2qHCurrQLJIy1aQntXks3+lZiP//cr2N7x6YT3ztJDyP4beuvRNv/Ke7/Aub/3jgONbaLi7fO63NdluqtRI1mujncdAM07P4JICrNNs/wBi7VPx8DQCI6GIA1wB4mnjOh4lIflI+AuCNAPaLH90+T0uWas1wSKCHzBRAvfK3lZBQ289Tj2Nzyp5OcYOPVAYVFooSF4Ya9+tRun/gbxJf1sPL9Y77XF1RnhXvWUiBO6RZCM9CahaxxqKtD0MBwIVnTQBAT6EoVQSWC7FvLJQr4aVIqELnWageaTeafvqwEobKdGv34XW0+pBMlrIdi7E8N/n5LcZ4FnEXRHumS9xYdGn1ISlFQkk1oVkEmoqmDqQljUWu49iqDQfnbR3HVCm7rlBUreXA8RjuObyCT9x6CADwxbuPYudkEa+8eBscj3WEf9XZHTo2bBiKMfZdAEspH/4aANcxxpqMsUMAHgFwORFtBzDBGLuNcTP7KQBXD+eIB89Srd0RP+5F4A56+mdC7bvrXTSL7ZuKWKi2uo7j9GdZJMRBy0rK7iDRtfvgrxcYxSQYY7jpYW4snlrpvGqX2VC23ZkNlZw6qxTl2dIYuFpjQUTIZYJ2GHFhKAB46Hh6kVsdKCSvwOWiJQ13xiKtZiGbCEp66UkmhfpoUV43zUJXlAfIrrsxxiIXdLZd0xijesvRfsb3TJfwxGLdvxhKF4YKZzeVlDCUriWJNC5TY7kOz6LScDBVyuJnnrkD1z8w2/d3Q14MFbM2/vI/HsZdTyzjlkcW8JpLd/gGMHpsi1XeZy6ODWssEngLEd0rwlRTYttOAIeVxxwR23aK29HtWojojUR0JxHdOT/fv4s4KKKeBdcs0ruIsiZD1lkAPHTULQy1Y7IIANpc7dD+T5Fn4XoMbZfpBe6Ui9uj8zXfSDylCfHoPAtpCJIruDtTZxeqLbRcL5Q2Kykooyx13tJ4PoPd00U81INnEdIsInOwpRHdPV3qiGsvVYMmgurrA+n6bWmzobI2HI/FhgXjtCdAdt3VC9xFNQyluYDiSRydn8uzN5dwYq2Nx8TUvLj25JJSpF1KtelgPK+GoToXe5kCPZ7PdGgWlWYb5UIWVz9rB5qOh28KjaFXZAuW333FfmQtC6//xzvgegxXP2un7xmq7+9ay0W95aYMQ42GsfgIgHMBXArgGIC/Ett1OgRL2K6FMfZRxthljLHLZmZm1nus64Ixxvv0hMJQdo/ZUFKzsHvyLHZs4ovaUc0Vt0pVSc2NYxjGQtdWIni9dKNVZbz47M0l7Xk62kaCIgyVkDqb16TOSqMU9Sz4OQT9eOIWzgu2TfRkLIKBQoHA7RuLNQc528JZE4WOK89jqw1s3xQ2aL3MNdcNpPIHIMUsQHFFeYDes+jIhorpqhv3Gd8zzWtXfvgkT11No1mEWpQL4TyoMO/0LNaEXhL1SoCgLunZe6awe7qIL/UZipIXgvu3jeMPfvoiVJsOLto+gfO3lf32Jer7KzWaJOOYGyVjwRibZYy5jDEPwMcAXC7uOgJgt/LQXQCOiu27NNtPe6pNBy3XC8UYexW41WylstLzaa3t+q2bdUjP4mgXz0JWACd7FoMPQ+mE1OD1pGeR/Jo3HZjHOTNjeO7eaRxd6TxPfTaUDEOlLMqTxkJ4Llt1xiJjhRsJagzgRdvLOLRQiw3nrDbaIW8n0Cw6BW7Zy2t6PNfhWRxbWcNZE2FjIWerpwpDOS5ykYFU0TCYivQQdQI3ILvutkNCbVTg1jVKBLixiNMsAODuJ1dQyFoYS7ho4vsPivI8j6He5l2cx3I2sjZpNYu6SNstZW20XRYKW1YaDsoF3tL/6kt34tZHFjqy0tKgzqa45rm78Rsv3If/65XnAwhSn9X9+hpNQhgqyM7beAJ3B0KDkPwcAJkp9WUA1xBRnoj2gQvZdzDGjgGoENHzRBbU6wB86WQec78sR2osAB6Gqrfc2DbZUeotBxbxBUkuorLtRJLAfVZaz6IhNYtu2VCD9iyCK+coaa6EG20X339sET9x/gx2ThYxW2l0xGkTPYuE1FlV4LYsQsaiZM9CzBBgjMWK9heeNQHXY3hEU8ndaLt40Z99G/92VxBtVSu4o4v1aoPPN5ku5To9ixMN/0JBMp7S+AL6bK5CZMBT6PGaugyVyVIOLceLVKBHBG7N1TsQXN1H2SNqLZ5aWcPmsbx2DotKKWej5XhwPYaG44Ixnl0os7V02VBrbRcFZd6G6pmoRayX7p6ExxDqhJsWPy1eHMsfvfpivPLibQCg9XqC7K/uYagNp1kQ0WcB3AbgAiI6QkRvAPDnIg32XgAvA/B7AMAYux/A5wA8AOAbAN7MGJPv0JsA/AO46P0ogK8P65gHie7N9TvPphS5ZV41Ea9kLWQtv6FdUhiqkLWxZTyHYye6haHayFgUe2XIjzmLaiv9TO80RMePhl+vu7G4/dASmo7nGwvG0FHx6ia0+9CnznZ6FgA3HrK9hN6zsNFse9p4vyQQuTtDUYeX6lhtODikzGlQBe5o59TVtTYmCjyMsrIWeCSVRhvVptMZhuphDrfO2EXbsKvEzd+W6Fp+rLVd2Bb5+lFRc/UOSIG70+Mdz2d8b72bXiH3L/enLtDy+HRhqIYIgcnXl4ZaFrFK/VCK6/N9NNqsJYSAx3K8vknNdpP9xZIEfbU9zTAYZjbUrzDGtjPGsoyxXYyxjzPGfpUx9gzG2DMZYz8rPAf5+Pcyxs5ljF3AGPu6sv1OxtjTxX1vYcNqyiJwXK/nzrA6dK0Xeu08W2/yalNJuZD1F8UkgRvgGVFPacIzKpUGv0pKujor5/lM7+oAG6rpupsGr9dds/jugXnkMhau2LcZO6f4lXS0jkFbZ5HkWYhtuchin7UtuB4Ptei+2PksD0MlGYu9m0vIZyw8rMmIksettvJOErh5GCqL6VIWjAXPOyZCjmdFjIVvfMVn7uHjFfzmtXfGegodnoUyh9txPbzts3fjFlHXEu3zFGVSE3tvtD0Us7b/mYueH8DDRfJxOqR30S0TCgi3Kfe7tubkjIzOOhBACUPlAkMDKJ64+J9KT3O+j9HDUcOlQkSYGgsPj5JhqOmE1NloKvegMRXcEV75ge/iXZ+/b9370b25vRqLWitc3l8uZDC32t2zAIAdkwUcSxGGShK35WsCg5leJ0nSLApZPvc5SSe56cA8rtg3jWLODvSZyLm6mnYfQSPBYEyqfJ2WRtwFAuOxtVzQGtW8yIYKRPvO9yVjWzh/W1nrWRwRNSKqsQh5FtowVCDQyri2PP9oGCqfsZC1yV/oPnP7E/jWg7M4MNt5LDrNpaAs5l+65yi+/KOj+Ob9x/3H88ckexYrEc9CNS7BNLvOtuBxn3E5Na9bjYW6j7WW63v00mOYLGY72pHI1y/mMh1hKL8uSXxn5Ov341n4aesxeuFUKaxJLdWaKGStxO/9hvUsNiqbx3J9vflR5jXDcsZl59mU6bN8pKpiLPIZzIrup92MxfZNRRxdWUtsM1FppjEWg28mmJQNJWdHxwmyT62s4ZG5Kn7ifJ7ttj1Gn9HNswgquPm0vF/8u9vw37/IZbMgDBU2CNJ46PQKIKhwTjKAQND2I8ph6Vkoi5bMqiIi5cpYtPtYa2OikPUvQqQHK9Oko2EoomD6IGMMNzw4B0CvZ3HNIvy5KojzqbVc/O2NjwAAnhQx+qDhYUw2lCb23mi5fqsPANqZ7ARmJQAAIABJREFUFkkz5oFA5O6WCaXuvy5ST4FgHkTc2NtG20VRWZjlsQULfDC2drKU7TsMZVsU+3mZHst1eBbdNBq1l9kwMMYiwkw535dbGWVutYnxfCYUd5ULf9pePdVmuDCpXMj6V2ndxpzunCyi1nITmwBWRWZHEkPxLBLCUPI1417vcz/g5Tgvv3ArAKnP5DsK83TzLAKB28OhhRqeWKzjpgPz8DyGluPBInQM0gk8C/3CJAXupDAUAFx4VhnzlWZHZb3eswiuvuX+1HYf5UJQVOZ7FicaIAK2TXTWgsgZIQ8dr/j/J137kZarEbjFcXzhh0fw2EINU6WsXzGvZm3p0LXUWGu7oYpv3TQ7f2xwTMbfns08fbbXMFQ09DM5xr9P0QuqzjBUuMZFvcCaGc8ndktoux7e+9UHOjS1WpNnZcUt/tNjYc9iodbqqtFkbD4QbSSyoTYCM+X8QDyLuUqjY4EJMlNSahaaMJQkbgCKZPtk94yoairPQhqLeM+i0Xa7NsrjaZZBWwwgfmEdz+tnWlQabXzi1kP4yYu34ZyZcX/7zslCh7HQz+AOus5+79FFAFx8feDYKtqu1yFuA909Czn3uFtmUFzbj8NLOs0iWLSJiA9AanNxtdH2wp6FMBbHVtYwM57XnoP8f97w4Kx/Trp0Y12diDQWX/rRUezfOo5feM4uHFleg+exIAwVlw1V7GypsRZpr6/LOKq3ZbgoJgzlaxZpwlCBSF1XilwB7lm0XK+jStsPQ2Xlc/WaBdB9vbj3yAl87OZDuPGhudD2bt+9Ts+imcqTytmW8SxOFjPjeZxYa6/bOs+tdraHGO9D4I43Ft00Cx67TsqI4lPy4tNm+WsmC87LtRZe9D9vxD/e+njift523d1482d+CEBtwa3/+MU1L/zUbU9gteHgrS/fH9q+c6qo8SxEu49QGCqYZ/G9RxewSYyg/d6jC2g6Xoe4DQT9oRI9i7bbNX4vM6KixqKbZwEEtQjyfzJRzAaehQxDrTawPaJXSMr5DKrNNq5/cA6X7J7Ens0lPLXSme4ZnfSnng9jwFtefh72bB5Dy+FjZv0wVIyXm8vwOojlSCVy6Nw0c7jrvmeh3++zdk/i9191ge9dJqGGoQLNQoahZLZWdOaG3rOoxBmLBM9CakPR9jXVRnK78alSONttqdZK7Asl4QkXxlicFOQCv9jjKMwoc5VmR0jAF7hTZhbxpmfhMJQkqc4CAHZs4gtHUkZUJUUYyp+WF2MsPnjDQSxUm9oaApUHj67ixofnUGs63cNQmjbltaaDf7j5Mbzsghk8Y9em0H07NPqM1rMQt1uOh9seXcQrLtqGc2fGcOsji2i7Xoe4DaTwLMSXM9As9Oe0ZTyH6bEcDs4FxqLadLBcb6OQtbDaaPvpydEZEbLKeVVZrIo5niklp+UdXVnDdk0ICuAe7eMLdfzo8ApeceFW7Jgs6j0LzUAqubCfs2UMP/PMHb5ecHi5HhLi44i2/Gg44SwnnWbhT8mL+YxnbAtvftl5id2S/f2HsqEiYSh/9GtwfIwxMVzM6jAWUc0C4BeXSZ6FNBYnIq3Qa634oWMA9ywY4yE8xhjvC5XCkzKexUnET4dbRyiKMaYPQ/XQ1A2Q7ZT1nkW31NmZch4ZixIzoiqNdmITQf6a8QL3Y/NVfPr7TwAIpgLqYIzh2IkG2i7DbY8udg1D6TSLT3//CSzX23jrlfs7Hr9zqohG2wuFO5Im5d331Aks19t44Xmb8cLztuCOQ0uot1y9Z2EH2VA68mKSXJJoD/Bw0v6t4yHPQnoVF22fAGPBlWu0hUY+a2GtrXgW4j2RcW35/5WhxyjlQsavFXnFxduwc7KoF7idzv/BVCmHi7dP4J3/6ULYFmG3SFV+crEeSvGNY2os3HlWXrVLoguyertbqDUNQTaUg5pG4AbCnkXbZXA9hpKSDRU0cdRoFmXexjwuWuB7FpH5Mt3CUGpyQEV0g9iSUL0tyWWMsThpDMJYVJoOGm0PWyc6W1rbFqUSuBljInVW71l0C0PZFuGsTYVYzaIlRNlumkWQytp5zO/7+kPIZyxcsK2c2PJgteH4V47fPTgf6n2ko1zIhgzqWsvFx25+DC/evwXP3jPV8XgZclMbCspaCrXdh8x0+u4BXifwwvO24AXnbsFa28Udh5b0mkWmWzZUOoEb4KGog7NV3wM6IvSKp+3geoa8+mxEReCsjUbL9ReciWJgLJZrLayKfmHSm4wi3+Odk0VceFYZOycLWKy1Otps6Cq4cxkLX3v7i/GTTzuL72OqCCLuWTS7FOUBIgW0Fha41QudgjYbip9ntwuiNITCUE0HGYt8bzGuaFAelzRWahgqn7FCBrVbYd7Dx7nHHQ1D1boMMpr2ExjaqduxA0HCxTAwxiLCegptJLIWIno1KtMY02gWjbYHjyFWs4gTFVV2bCrG9ofyK0i7hKGISKshfP+xRVz/wCz+28vOw3lbx7GYYCxkJkjOtnDTgfnuArd4PbmofuP+Y1iotvDml52nffxOaSwUw+h7FnZnu4+FahPnzoxh20QBzz9nMyziz9V5FmkEbsdj/gIXF4YCgP3byqg0Hb+ATmYVPX0HD6utrPH/YbTeIQhDyWFVQqAdy2Gp3vZ1qTjPQr7HV160FUTkFzIejehZce1Koud71kQBTy7V/bYkSc/ZNVXyU20BWWehnFukUSKghKEGYSzUMJSozJYZSEEYKqypAPx/blu8Bb0U3CvNzrBt0nqxVGv5mVIdYaiIHhllaizr72Oxmm7QEwDkMrYxFicL2ahrPZ7FXCW+PQTPee8unktdQ9UspH5QzNqwrOSeOAAvzIvzLNJ0nJXwZoKBgWOM4b1ffRA7J4t4w4v28XBIgrGQNQCvfNo2PLFY96+2ksJQbTfItnnwWAW5jIXn7p3WPl5nLJI0C4B7FQCwqZTF03fyxTrOsyBCrLgoz0Fe9Sd6FtuEyC1CE0eW11DM2n5mV+BZhBftYo6HulSBGwCmS7zK99iKvsZCIkONV17Eew/5etZy1FjEtxtX2T1VwpGlta6pswBw7swYlutt//PRiAjcyWGo9RuLfMaCRaIoLzLDWqb2qvOuowWBaotzrvGFdZKkSIQMQeVsKzS0iu+r7ddd6VDraOSFWCqBW2lsOWiMsYiQy1h9F9pI5HOjYSiAx0vTeBYyzS+sWWTFtnRfou2TRcyuNrSNC3WZHXFENYT5ahP3PXUCv/aCvShkbUyPcREzbuaBjJf/8mW8sfAND83CtqijpsF/vcgMhoOzFZw7Mx7SH1QmS1kUs3bIMOqyoSyLIP98wblb/O3yds7u3H8uY2HzWC72WANjwReDOM0CAM7fxo3CgePSWNSxa6roZ2VJY9GMXH3LAUF+GErxLJZrLd9T2R4Thrp832b8xPkzeN453Nj6nsWKxrNIOH7J7ulSSOBO0izO3crP+dF5foEQnfIoPWRdBfcgwlAy9VhmQ6nfnaxtoZzPdGRrAcrYV6XFebXR7ri4SmMsnrFrU8iz4CFmN9GrV+toFlP0hZIYzeIk0y3DoRsyDDWjEUXHNJk+OoICIlWz4B+ubgV5kh2TRbRdpi0aCjyL7hkl0TDU7Am+P9mjx5/spWmdwB/PF7PL903j7M0lrNTbiVewUVH94FwV+7eOxz5ehlaOajwLO1L0lLH5lebzz9nsb3vBufy2Lgz12sv34P+56sLY15ZpozJElBSSmSzlsLWcx4FZvnAeXlrDrqlixyCejtRZUWex2miDKKgTmC7lUGk6eGKpBovi03sv3zeNa3/jcv/Ytk0U/NCbhDFemNgtDAUAu6eLOL7KW6XwpoDx7+V5wmt6ZK6KtuvB8VjIWFiiirkR0SxsRVtYL7JNea3pdiz2kxEBXs4Dl4aq2OFZhJ8/VcrBtkj7HTswW8FEIYP9W8dD2YRN0QU3KQxVEKm7y0oYSoamkshnLNPu42Sy3iruuUoD+YzlXwGqjKc0FvVIHxugd88iaQiSbFmdzrMIh6GkpyBnJ+j676scX21gqpRFIWv7bTqSjIWaNVZvOXhqZQ3nJRgLgBvGqGZhETrCdVmL8PSdm7CpFHzxnrt3Gjnb0i56V5yzGb902e6O7ZJewlAAF7kPzAaexe7pUodn0XA0qbMtly9W+Yx/TjJj5oGjq9haLsR6P1GytoVtE+FCxpbbXaCX7JkugTE+rbDb43dOFpHPWHh0rtoxUlUSnZNdb7koZeOrm3tFhpJ0nWwni+Fmgmstz38O/x1My6tqNAvbotgWQQeOV3HBWWVsKmZDnkXaELDsD7VYa6FcyKQy5LJX2TAwxkLDequ45ypNbJ3Q93FJK3AHaX6dAndqY+E32esUuf2maH2EoY4LYVR2OJXGYjEmfXZ2teHXnLxkvzQW8eegthh5bL4GxpDoWQDoSAd1PBbKhJI8Y9cmXH1peDJvMWfjp5+53c9K6gV5HnIx6LZ4nr+tjINzFZyot7HacLBrqohC1kYuE8S1eSV1pCiv7fK+UMXAyE0rxiJO3I4j+v9Kk80l2S1qLQ7OVbp6uZZFOGdmHI/OVzum5Emi0/K6jQ3uFR6GcoSoHN7v1Fi4P1R07GtRMWSVhqP1xHXrBWMMD89WsH9bGRPFrKi+5/tRBx8lIbPdFqrNVCEoQIShhuRZrD+ReQSRYSjGWF9XN7OrDWyLycsfS2ks6glhqLRfJClk6jyLaAfNJCYK2VDq3/HVBmyL/A+wTApI8iykYXn+uZuRtSkxNq4OQJLJAvu3dTMWBSxUW34Ix3E9rcZx3Rufr33+B3750sT9xyE9gNVGu2PKnI7zt42j0eYV5ADPFgJEB9QYz6KgZENNKAKrjGsv1lp4nhJWS8OOySLuPrzs/x1U1acIQ4ljPrIcXwiocu7MGO49cgKNll7jKEQGIHUbG9wr3Nh6QrOIaA7jeTyidOCNpu2Wcrb/uZZTCqPoIhHzlSZOrLVxwbay7wmurrVRyNr+dy8pDAUE2W5Nx0slbgP84sVoFieRmXKexzg14x7TID0LHWnDUFXN1Uc+w69A0xYrTRQzGMvZHSmSQLCwT5bSaRbVZjAA6fiJJmbG8/5i3DUMdaLph6zG8hlcsW9zaNHrOG5Fszg4W0XGIpwtmsfFERVtuWcxmDBGEtIDWG20/Q6tSZwvMqJuEL2C5MK7qcib2rVdHs+O1lm0HA8r9fBipba/j86x6MbOqSKOnwiSH7qlM6tsLeeRy1hgLJ1xOXdmHIeX635qcLT7gJpxBMiRqoO7juX7d7TpqlvKOSxUW36adnSSnwyRMca0YShAr3HKjLf928b9MKO84EoafKQis90Wq61UNRYAz7wy2VAnEZnhsNBnKGp+tRlb8TuWt/120UnEpQ9OFDJdW31IiAjbY6p15ytNTJayqeKg5QIfgCTTeWcVTwEIipt0xqLleFiohluf/OUvXoIPXhN/Ja9qFgfnqti3ZSxRRAVUL4p7Iq7HQjUWw0J6SKtrTqqFc78wFt95mBuLXcLIybi2bqCQbOk9V2mGwlCq4BmXNhuHTH6Qi1wvYSjLIv+40zz+3K3jYAx48Bgf/qS2KAcCTUay1nYG61mIjKZ6pH0OwBf6lhtkmtVbkTBUNiP0Dhce02t8W8q886w6TVJW6l+wrexrl9JzlN+jbiHg6bE8Nxa1dE0EAZMNddJZT2HeWstFpenEFnGN57PwWDDgJg6/ziJy9fHyC7fiinP09QY6dkwW/dRKlfkK9w7SEG0meHy14XsKAM8w2lTMao2FDCOpxuWsTYVQ19goahjq0blqV3EbUPSZEyfbswjCUGkWzvF8Bjsni1iotjCWs33PbrIkjUVnVbRcuGZXG9owFNA59KgbuyK1Kd3mcUSRPaLSZOadO8O9wvuPrmqfU8gOPwwl51mU4lJfxXc9mrbLPQtHCdtqNIvxPNouC4nYB2er2DKew+bxfOBZrEmh3BX7Sj7H6bEsKk0HiymbCAKmgvuks56WH0kFeYA6ACk5FFVvutrhKH/+C5fgdc/fm/p4dsS0/FiodnbFjSM602L2RKMj7LF5LKet4pbV272ESeS88aVaC48v1rqK20Dne+a6LLYuY5D4Yai1dMYCCDrQ7p4u+RrHhPAsdBP35OLadLzQlW3Wtvy/ew1D7YgYC1+gT+m1yvBZUkGe5Jwt/P378VMnAHQPQ61F+ketl1LO9tNPo56F1N1k6muj5YIoMJoyDFVpxGcP6i4uH56tYP9W/j5PRLLdfIE7hWYB8I6/aY2F8SxOMusZxD7nF+TFC9xA9zblcvDRetMHz9rEhd/oB2i+J2MRaAi1poNK0+noqDs9lvM7oKocFzUZZ6UQQqOv+aMjK/AYcJ4I3SRRyNqYKGQwJ4xTXDbUoJGLiseSM7xUpFgvQzmAGobqvMJXr8TVMBQQ6BZxfaHi2BGZd/KFu4+gmLXxrN2TqZ4vPYs051zM2dg5WcQDfhgqORtq0J5FKZfx6xw6NIvId10OPvJnhOd4+wy50OtCR9GwNWMMB2cr/kVBVLOophS4pxXPsZcwlOMxbSHuejHGQoMstOnLWPh9ofRv7pgSj0+Cx1fXL/LJRTo6qWu+kj4dT/Us/BqLTeHnxrX8iNZkpKVcyOD+p/jiksazALiBlsba9fTZUIMm2h02DbLth8yEAni+f7Xp+BcRupkPADpqd+RnNa3hl5QLWUwUMji6sobFahNfvOcofv7ZO/1+Sd3YPV0Ux5nunM/bOh6E2CIGRk1PBQYvcKv/y2jqrL/QK2Eo1VDJ2/JzpaudinoWT62sodZy/YsCGTqUo3N1ySs6psZUY5E+GwoYzmhVkzqrQVdoIwXpblf63cJQspXFb157pxjAnsGf/8Iz/f5EklqrMye8H7ZtCoyFzI+vNXmX0rQLTDDTou33eYp6FpvHc/jhkysdz51dbfgtVHqhnM+g5fJRp/u2JGdCSbaW8/6X+mRrFtHbSZzvGwvVs+D/Y3n80eFHkmgW2fRYDtvK+b4M447JIp5aXsM/3/4kWo6HX3/h3tTP3TWVXrMAeEbUTQfmAeg8i0ykkeBgBe7w4h8tysuGLgzXOgZP8cfLi624Ogsg8E7keV4qvLRcxkIxa4eyoUo5u+t7pma7pb2w+7UX7MVrL9+T2oj3gjEWMURzp//gCz/GkeU6/ukNVyQ+b67SRMaikPiocsnuSbz2ij3+FeQtBxfw7i/+GF940wtC1cb1ZvIkrbTIK/rjimchP9T9CNyy9XfUU5gWxU2ex0LncfwEF8N7DafJ19wzXUq9IG0t53HXk7x2wPVOkmaRVY1FuuO8aPsE3n7lfrz6kh3+NllRLhelQmwYKvyZ+M0X78NCn4O6dk0VcWihhnufOoGXnD+D87Z2D/dJZKuXNN2PAeDcrYHB7yjKy/F5HfKCrN4edBhK8SwixsISF4a+ZxHRS8YinoVOsyjnM8hnLP979aW7j+LcmTFcvD0o8pwoZnyBu9ZK991W15C0mkUxZw+0oFHFGIsY1KpMx/Xw1XuPotp0OgqjosytNrG1nI/tCjuWz+D//7ln+H//652H8fv/+1585d6jeI1SWVxrDuYLI1MqjysZUdII9iNwy9htVFCdHsvD9RhWG+1QKCOaOZUWmT7bywK2daKA2VVeTOmcJGOh9i9K61nYFuH3Xnl+aJuMa0vNJT4MFf7sqQ0Re2XHZBHfepCn8P7FL+zt6bkThSx2TRWxLaaeKMq5SvZbVLzeVMzC9RjmKk1sKmbB2GCaCEqSwlAA/x5IgxsXhvI9C42xICJ/vTiyXMcdjy/hHa88P3SBNFEIii6rmh5VOqQ3ToTU4cFhYjSLGNRCmx8dWcFqw4HHgLueWE583lylgZkeFsf//OxduHj7BP78Gw+HXPHagDSLTcUs8hkrpFn4nkVKYyF7+1cabZG+melw5zePBdXEKrOrDT8U1gvSQP2f9s49OK7yOuC/o5VWK2v1QJZk+Y2NDTYY24BjILYJBRoMTjADeIAphdJmaDpuIZlkEqDpEDKlTZukSdomNJmEhDQZKJNmjEsCIXUINC2PEHDMK4BjMLb8jh+SbVmypNM/7v12r1a72l3tS7t7fjMa7X67e/c70u4997zTVW4H6WyqZ2DQy5kfGta0tRn5oDZUE3N3ZZpJlIyWBu/vt9ePedUnmfkAIwdg5Ypr7T63ozHWhiUbHvurlay/JPmMkUScsvAaD45U4pcs8Fqn/9dvdsXri/KcDeVIdkXfHviuj5oR7n/O9/f2IwLRFN9J54nY+JtdACMu/MD7HgbdUJm4mOtCXn+5Nj8uVWpMWaSgI1Bo8/RbB6gRbx7C89sOjvk6Z1lkSk2N8Jk1C+k+3Md3/vfd2PrxgbGHo2SKiDcxb09P3KV2IEvLIj4AadBzKyU5+Ser4lZV3w2VXfAV4ldwmQa3IS7Pvt4TRbMsIG5RZGpZJMNZFnt7nRsqhWXRkD9ngKt6v3XFnIzmoyTSOimcseutPRqOFZQmuiTndUZZNL2ZRzfvStpAM1eSWQoj91Y/IsDdkMKyiIZrU/6dOqL17OvpZ8PL3Zw3+5SYm87RHGjncvRE5heCbY3hjIPbhcaURQo6muoZHFYO953k6bf2s3RmK0tmtvL8O78f83XJZm+n4/3z2rlsYSdfe2prbOpZplcfmTClORJrEw7eVVJojLhKMlyb8mBTwCCxZoIB/7lXNzBMV5Zpnd77eSfPTAryHK5qfl9vP0PDw0UJcEPcosglqBhTFj1JAtxjuKFy4ZIFndx95QLWnTcjb8dMhYhwWmc05d/o6qXTeaX7CK92J0+vzYURbqgkJ2l3Yaiq9CWk7bq//b7e/jErrtub6tm6/yhv7T3K1UunjXo8aFmkahuSjKktDSnnlBQbUxYpcFepb+3tZcvOw1x0egfL57Txys4jsaufRAYGhzl0/GTKVh9jcdeVCxkYGubSLz3NPz7xW3pPjG56Nl66miOjAtyTG7MzbZvq62Kps8liEO7qJ2hZuMrx8cQs5rRPonVSXXbKojlgWRSpKA/iwehMr7KTEVcWLmYRCHAH2mNk0iU4UyaFa7ntotMyTiDIlWWzT4ll5CXy4SXTEIGHXnjP31t+6ywcyd1Q4VgFdmI2lNtHYl+uRDqiXsyutkZYs3i0smiO1MZSZzMNcAN8Yd1i/v6as9M/sQhYgDsFLlVtw8vdqMIHTu/gSN9J7v/F73hp+2FWzh8dWHSB41RNBMfitI4oP7l9FV/d9Db3P/07VEdXm46XrpYIe147Eeuim02NhaMpUsvhvpPs7+1P6oaKT/aKu7tS1WRkwtVLp3PFoqlZncicxbOvp5+hYc247iFXnGWRixvKaxAZ73AalDvsD2yK1IWKEocpFJ9evYBUtWJTmiOsOK2dZ95Onl6bC+6EXxeSpAOugrUWiZZFUNGMFZR2x7jo9I4RKa+OlgavdcfwsI4a7zoWwVqcUlO+n7wC4/75j23ZTeukOhbPaGXZqW3UCCldUS6TJVs3lGNeZ5R/ufEcHr9jFTdfOJsrzp46vs0nMKU5ErN6ILvqbUdTpI5t+48yrKNrLMA7kTWGQxwMzDPem6ImIxNEJOsr3mh9LZPCIfb19vsxiyIpizxYFhC3LmBklpUbDZpPF1QpqA3VJD1ZO9YunYbrr5nPmEVsRGqKY8aruAdGjX3NNLnAfcbXJnFBgRezUIXe/kGO9g9mlA010SjYt0lEHhCRfSLyamCtTUR+JiJv+79PCTx2l4hsFZE3ReTywPp5IvKK/9g/S77GZ6XBnUyP9g+ycl47oRohWl/LouktKYPcsVYf43BDBVnQ1czn1i5i4dTsh/EkI1Zr4Z+89/dmryyaI7UxZZPKrdQWDSe1LHL9e2SDK8wbKlJRHgSURY6WjFMW4dqaUYHUhnAoYz93ubJ6UdeInkz5wh0rlaUerMBOVBbBfYzlAvzA6R184brFrElxgefatBw6NsCJk8N5yXQsNoW89PousDph7U5gk6rOBzb59xGRM4EbgLP813xdRNx/6X7gNmC+/5N4zILgCm2A2ChQgPPntLF5x+ERaa4Dg8O8+O5BHtuyGxifG6qQODfQ3p4TDA9rVk0EHcETVaqmdW2N9SNSZ/f2nKA9Gh7zajLfdDZF2NdT7Gyo3N1QEFcWyeZiROpCo/pCVRpNkTouW+il0ea7kSCk7sXkLIvuQ31+jcfIZo0u1TdZqw9HuLaGdctmphxt66xC1xU5n7GnYlGwb7GqPgMkXoKvBR70bz8IXB1Yf1hV+1X1HWArsFxEpgLNqvqseuWd3wu8pqC4QhtIVBaTGRgaZvOOwwwODfPFn77J0s89yXX/9iyPbdnFhXMnZx0PKDQuG2lPzwmO9J3k5JBmXL3tCJrgqZTF5IT+UHuOJM+cKiQdzfUlyIbKrxsqmfutwW+UWOncdtFcLl3QmdfPTcwNlUJZuJYf7x08DkBDgoXoFFcuriOX8uzmraRrTz4RKfanb4qq7gZQ1d0i0umvTweeCzxvp7920r+duF4UprU00BSpG9FB9n2ntiECP96ym6/891s8t+0gH14yjTVnd3H+nMkjmn9NFDqb6hHxTt7Z1lg4nGVRF5IR3TCDtDWGYwNuALYfPM7cDPs65YvOpnp+4RcClptl4Sp2kymLT3zwjBExjUplycxWvv0n78vrMetrvQSBVG6omhqhPRpmh1MWCc9zXWtzKYh0/7vdfpfffNRQFZuJsuNk32odYz35QURuw3NZMWvWrJw39XfXnE1ihKRlUh0Lupr59+e2E6mr4UvrlnBtEfLUc6EuVMPkxnr29pzIunrb4b4onU2RlIVJbqaFqvLW3qNs23+MW7KYvZEPOpsiHBsYoqdvsPiWRZ5iFsmUzupFXTkdu5oRESaFR3cdCNIerWfHIacsRj7PubFysiwS3FDlqCyKnQ2113ct4f/e56/vBGYGnjcD2OWvz0iynhRV/aaqLlPVZR1eckP5AAAKQklEQVQd2bcvSGReZ3RETxvHtedOZ8mMFjasXzHhFYWjq6WePT0nsu4L5chkyE5bY5iBwWGODQyxYXM3oRphzeL8ZHRlSmcgDbJcs6GKVfdQTUTqQmO6ftqj9XQf8k7kifESZ2nkkmDgGkV2x9xQpizSsRG4xb99C/BoYP0GEakXkTl4gewXfJdVr4hc4GdB3Rx4Tcn4yKq5PPqXK1nQlZ9spWLQ1Rxhz5G4ZTGeOgt3nFTEq7j72bh5F6vmtxc9fhNMLiheNlSeAty+e68Q7aWrnVtXnMpVKdJaId6xAZJP8oPclEU0XItIwA1VhtlQBduxiDwEXAy0i8hO4B7g88AjIvJnwHvAOgBVfU1EHgFeBwaB9arq0o3+Ai+zqgF43P8xsmRKc4Rfbz/E/t5+wrU1WQdLnRtqrMCjq+L+6Wt76D7cx6dWnzH+DY+TYJpuKFTc1NlcLQKzLArH+j8Yu+Fh8KJm1LwN/8SeS8yipkZojtTFJhOWYxp0wXasqjemeOjSFM+/D7gvyfqLwKI8bq0q6WqOcOj4SXYcOk5HtD7r+RLNMTdUakuhrdF77MH/286kcIg/PHPK+Dc8ToIFkcXPhspXzMKURbFpDzTrG2VZ1OVuWYCXEbXjoMUsjAmOaxP+2q6erOMV4LUdWD6nbcz5Ca5NeffhPj545pS8VuFmSuukulj1c9GzofIV4DY3VNEJfidGZ0PlHuCGkRX6+WoSWkzKT70Z48INQdr+++OxsZ7Z0BAO8cifXzjmc4Jpw2vPKVqG8whcfUz34b6iWRaRPNVZtMaK8srvRFLuBOuOEqvH4wHu3FKXXUZUXUjK0nq0S5gqIRiYHo9lkQmN4RDh2homN4ZZNW/8E9xyxclXvGyoPFdwm2VRdNoD34nEmFE+AtwQ//+WowsKzLKoGoLT6rKt3s4UEeGcma2cP3dyyrYHxcDFLYplWZw+JcqMUxqymg+SjGYLcJeM4HciMWaxcGozC7qacr4YcJZFOabNgimLqqHJ78h6fGCoYJYFwH+kcVUVA5c+W6yYxar5Hfzy05fkfJxQjXDTBbNGtJcxikNLQ13s4iKxl9k1587gmnNzr6dyLT9MWRgTGhGhqznCtgPHJlzvqnzj0meLZVnkk7+9emIMuqk2amqEydEwx/uH0j95nJS7G8qco1WEq5EopGUxEXBuqGLVWRiVQUdTfV6HLiXSbMrCKBdcq47xDmcqF5wbqhwtC6N0tEcLqyycZVGOHWfB3FBVhUufrRY3VLGyoYzK4Mbls2IV1oXAAtxG2fDHF87mrGktBb16mghMb22gtkaqYv6DkT8uP6uwnX3L3Q1Vnrs2xsXUlgbWLG4o9TYKzimNYX5yxypmT544w+4No8WyoQxj4jGeKnXDKCTlblmYU9cwDKMIdETr+fhlp3PlouLOeMkX5aniDMMwygwR4Y7L5pd6G+PGLAvDMAwjLaYsDMMwjLSYsjAMwzDSYsrCMAzDSIspC8MwDCMtpiwMwzCMtJiyMAzDMNJiysIwDMNIi6hqqfdQEERkP7B9nC9vBw7kcTvlQDXKDNUpdzXKDNUp93hknq2qo8Y1VqyyyAUReVFVl5V6H8WkGmWG6pS7GmWG6pQ7nzKbG8owDMNIiykLwzAMIy2mLJLzzVJvoARUo8xQnXJXo8xQnXLnTWaLWRiGYRhpMcvCMAzDSIspC8MwDCMtpiwCiMhqEXlTRLaKyJ2l3k+hEJGZIvKUiLwhIq+JyB3+epuI/ExE3vZ/n1LqveYbEQmJyMsi8ph/vxpkbhWRH4rIb/3/+YWVLreIfNz/bL8qIg+JSKQSZRaRB0Rkn4i8GlhLKaeI3OWf394UkcuzeS9TFj4iEgK+BlwBnAncKCJnlnZXBWMQ+ISqLgQuANb7st4JbFLV+cAm/36lcQfwRuB+Ncj8VeAJVV0ALMGTv2LlFpHpwO3AMlVdBISAG6hMmb8LrE5YSyqn/x2/ATjLf83X/fNeRpiyiLMc2Kqq21R1AHgYWFviPRUEVd2tqi/5t3vxTh7T8eR90H/ag8DVpdlhYRCRGcAa4FuB5UqXuRm4CPg2gKoOqOphKlxuvJHRDSJSC0wCdlGBMqvqM8DBhOVUcq4FHlbVflV9B9iKd97LCFMWcaYDOwL3d/prFY2InAqcAzwPTFHV3eApFKCzdDsrCF8BPgUMB9YqXea5wH7gO7777Vsi0kgFy62q3cAXgfeA3cARVX2SCpY5gVRy5nSOM2URR5KsVXResYhEgf8EPqaqPaXeTyERkQ8B+1T116XeS5GpBc4F7lfVc4BjVIb7JSW+j34tMAeYBjSKyE2l3dWEIKdznCmLODuBmYH7M/BM14pEROrwFMUPVPVH/vJeEZnqPz4V2Feq/RWAFcBVIvIunovxEhH5PpUtM3if652q+rx//4d4yqOS5b4MeEdV96vqSeBHwPupbJmDpJIzp3OcKYs4vwLmi8gcEQnjBYI2lnhPBUFEBM+H/Yaq/lPgoY3ALf7tW4BHi723QqGqd6nqDFU9Fe9/+3NVvYkKlhlAVfcAO0TkDH/pUuB1Klvu94ALRGSS/1m/FC8uV8kyB0kl50bgBhGpF5E5wHzghUwPahXcAUTkSjy/dgh4QFXvK/GWCoKIrAT+B3iFuP/+bry4xSPALLwv3DpVTQyelT0icjHwSVX9kIhMpsJlFpGleEH9MLANuBXvQrFi5RaRe4Hr8TL/XgY+AkSpMJlF5CHgYrxW5HuBe4ANpJBTRP4a+FO8v8vHVPXxjN/LlIVhGIaRDnNDGYZhGGkxZWEYhmGkxZSFYRiGkRZTFoZhGEZaTFkYhmEYaTFlYRgZIiJDIrI58DNmJbSIfFREbs7D+74rIu25HscwcsFSZw0jQ0TkqKpGS/C+7+J1UD1Q7Pc2DIdZFoaRI/6V/z+IyAv+zzx//bMi8kn/9u0i8rqIbBGRh/21NhHZ4K89JyKL/fXJIvKk3/jvGwR6+ojITf57bBaRb2TTYtowcsGUhWFkTkOCG+r6wGM9qroc+Fe8LgCJ3Amco6qLgY/6a/cCL/trdwPf89fvAX7pN/7biFeJi4gsxKtKXqGqS4Eh4I/yK6JhJKe21BswjDKizz9JJ+OhwO8vJ3l8C/ADEdmA144BYCVwLYCq/ty3KFrw5k9c46//WEQO+c+/FDgP+JXX8ogGKrcZnjHBMGVhGPlBU9x2rMFTAlcBfyMiZzF2y+hkxxDgQVW9K5eNGsZ4MDeUYeSH6wO/nw0+ICI1wExVfQpv+FIrXlO7Z/DdSH5zwwP+XJHg+hWAm6G8CbhORDr9x9pEZHYBZTKMGGZZGEbmNIjI5sD9J1TVpc/Wi8jzeBdgNya8LgR833cxCfBlVT0sIp/Fm2C3BThOvK30vcBDIvIS8DRe51BU9XUR+QzwpK+ATgLrge35FtQwErHUWcPIEUttNaoBc0MZhmEYaTHLwjAMw0iLWRaGYRhGWkxZGIZhGGkxZWEYhmGkxZSFYRiGkRZTFoZhGEZa/h/wBrSVmO+V9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  1467.0\n",
      "Standard Deviation:  477.4373934312903\n",
      "Average Steps Taken Per Episode:  1112.65\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\n",
    "#Testing Plot\n",
    "plt.plot(history2.history['episode_reward'])\n",
    "plt.title('DQN Gameplay Performance')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Score: \", statistics.mean(history2.history['episode_reward']))\n",
    "print(\"Standard Deviation: \", statistics.stdev(history2.history['episode_reward']))\n",
    "print(\"Average Steps Taken Per Episode: \", statistics.mean(history2.history['nb_steps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
